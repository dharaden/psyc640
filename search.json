[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "üîóGetting Started with R\n\n\nüîóIntro to Data Wrangling\n\n\nüîóLibrary Tracking",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "class-activities/wk4_beg-inf.html",
    "href": "class-activities/wk4_beg-inf.html",
    "title": "Week 4 Exercises - Intro to Inference",
    "section": "",
    "text": "Following Along with Professor\nDownload Week 4 Follow Along Data (.csv)\nDownload the data and move it to the correct folder so that you can access it in this activity.\nWe‚Äôve been hired as consultants for the university‚Äôs graduate school. They are concerned about student burnout and have given us some anonymous pilot data to explore potential factors. Our job is to be the data detectives.\nImport the data into your R file. I would suggest putting this line within the code chunk that you have your libraries in.\nFocus on having reproducible code! You may need to share your file with someone else. They should be able to run it.\n\n\n\nOn Your Own\nGoal: Work individually or in small groups to apply the concepts from today‚Äôs lecture and demo to a new dataset.\n\nObjectives:\n\nIdentify predictor and outcome variables from a research question.\nUse the ‚Äúdecision tree‚Äù to select the correct family of statistical models.\nCreate an appropriate visualization (ggplot).\nRun the correct statistical test (t.test or cor.test).\nWrite a one-sentence conclusion synthesizing the results.\n\n\n\nThe Scenario & Dataset\nA developmental psychology lab is exploring factors related to children‚Äôs well-being. They have collected pilot data from 100 children.\nDownload Child Well-Being Data (.csv)\nPlease download the child_wellbeing.csv file (above). It contains the following variables:\n\nchild_id: A unique identifier for each child.\nparenting_style: The primary parenting style observed in the home (Categorical: ‚ÄúAuthoritative‚Äù or ‚ÄúPermissive‚Äù).\nsleep_hours: The average number of hours the child sleeps per night (Continuous).\nanxiety_score: A score from 0-50 on a parent-report measure of the child‚Äôs anxiety (Continuous).\n\n\n\nInstructions:\n\nCreate a new R Markdown file titled week4_inclass.Rmd.\nLoad the appropriate libraries.\nLoad the child_wellbeing.csv dataset.\nFor each task below, write the R code and answer the questions.\n\n\n\nTask 1: Parenting Style and Anxiety\nThe Research Question: ‚ÄúDo children raised in homes with an authoritative parenting style have different anxiety levels than children in homes with a permissive style?‚Äù\nYour Steps:\n\nIdentify: What is the predictor (IV)? What is the outcome (DV)? Are they categorical or continuous?\nModel: Based on your answer, what is the correct model family (t-test/ANOVA or Correlation/Regression)? Write out the specific model using R formula syntax (outcome ~ predictor).\nVisualize: Create a boxplot to visualize the relationship between parenting_style and anxiety_score.\nAnalyze: Run the appropriate statistical test in R to test your model.\nConclude: Look at the p-value and the group means from your analysis. Write one clear sentence summarizing your finding (e.g., ‚ÄúWe found that children with authoritative parents had significantly higher/lower anxiety scores than children with permissive parents, p = ‚Ä¶‚Äù).\n\n\n\nTask 2: Sleep and Anxiety\nThe Research Question: ‚ÄúIs there an association between the average number of hours a child sleeps per night and their anxiety level?‚Äù\nYour Steps:\n\nIdentify: What is the predictor (IV)? What is the outcome (DV)? Are they categorical or continuous?\nModel: What is the correct model family? Write out the specific model using R formula syntax.\nVisualize: Create a scatterplot to visualize the relationship between sleep_hours and anxiety_score. Add a line of best fit.\nAnalyze: Run the appropriate statistical test in R.\nConclude: Look at the p-value and the correlation coefficient (r). Write one clear sentence summarizing your finding (e.g., ‚ÄúWe found a significant positive/negative association between hours of sleep and anxiety scores, r = ‚Ä¶, p = ‚Ä¶‚Äù).\n\n\n\nü§î Challenge Question (If you finish early)\nBased on the design of this study (it is observational), can the researcher conclude that permissive parenting causes higher anxiety? In one or two sentences, explain why or why not, and propose one possible confounding variable that could be influencing both parenting style and a child‚Äôs anxiety\n\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk6_means.html",
    "href": "class-activities/wk6_means.html",
    "title": "Week 6 Exercises - Comparing Means",
    "section": "",
    "text": "Goal: Work individually or in small groups to apply the concepts from today‚Äôs lecture to a new dataset. There will be breaks throughout the lecture today where you will be able to try out each of these tests!\n\n\nFor this activity, we are going to be using data that has stats for the majority of Pokemon (8 generations). We want to look at the differences among these various Pokemon. We want to be the very best. Like no one ever was.\nPlease download the data file:\nDownload Week 6 Class Activity (.csv)"
  },
  {
    "objectID": "class-activities/wk6_means.html#the-scenario-dataset",
    "href": "class-activities/wk6_means.html#the-scenario-dataset",
    "title": "Week 6 Exercises - Comparing Means",
    "section": "",
    "text": "For this activity, we are going to be using data that has stats for the majority of Pokemon (8 generations). We want to look at the differences among these various Pokemon. We want to be the very best. Like no one ever was.\nPlease download the data file:\nDownload Week 6 Class Activity (.csv)"
  },
  {
    "objectID": "class-activities/wk6_means.html#steps",
    "href": "class-activities/wk6_means.html#steps",
    "title": "Week 6 Exercises - Comparing Means",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nVisualize the Data (select 1 pairing of personality variables)\nTest the Relationship\nCreate Correlation Matrix\nCheck Group Differences\n\n\nItems in the Data:\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nWednesdays 9 - 11am or By Appointment\n\n\nClass Times\nMondays 8:00 - 10:50am\n\n\nClass Location\nWallace - 4640\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course is the introduction to statistics for graduate students. The goal of the course is to provide a grounding in statistical concepts, methods and application to research. I aim to increase student‚Äôs confidence in using these techniques and introducing them to R. Topics will range from including mathematical conceptualizations to practical application with various techniques ranging from descriptive statistics to regression.\n\n\n\n\nWe will be using R for all data wrangling, visualization, and analysis. You may use another statistical program in this course, but I will only be providing examples in R. Students must have the latest version of R and it is strongly recommended that students also download the RStudio GUI, both can be found here. Both types of software are free.\nWe will primarily be referring to chapters in the following textbooks:\n\nIntroduction to Modern Statistics (2e) (Cetinkaya-Rundel & Hardin, 2024)\nLearning Statistics with R (Navarro)\nR for Data Science (2e) (Wickham, √áetinkaya-Rundel, & Grolemund, 2023)\nModern Statistics with R (2e) (Thullin, 2025)\nStatistical Thinking (Poldrack, 2024)\nAn Introduction to Statistical Learning (2e) (James, Witten, Hastie & Tibshirani, 2023)\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) (Judd, McClelland, & Ryan, 2017)\n\nThese textbooks are available for free online and able to be downloaded. You may choose to purchase a paper copy if you wish, but it is not required.\nAll additional readings will be provided by the instructor.\n\n\n\n\n\n\nImportant\n\n\n\nNote: Readings on the schedule will need to be completed prior to the course they are listed for. We will build on the concepts you read about in that specific class period, so it is important that you have read.\n\n\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\nEvaluation and Grading\nYour grade is a reflection of your consistent effort, active engagement with the material, and ability to apply new concepts. The components are designed to build on one another, leading to a comprehensive understanding of data analysis.\n\n\n\n\n\n\n\nComponent\nWeight\n\n\nWeekly Labs\n30%\n\n\nJournal Entries\n10%\n\n\nParticipation & Engagement\n15%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n25%\n\n\n\nWeekly Labs\nThese are hands-on R assignments that directly reinforce the concepts from the week‚Äôs class. They are your primary opportunity to practice coding, build models, and interpret results. Labs will be submitted as R Markdown files, and your lowest score will be dropped. Labs will be due the Sunday night (11:59pm) before the next class.\nJournal Entries\nEach week, you will submit a short, reflective journal entry. This is a space for metacognition‚Äîthinking about your own learning. Prompts will include questions like, ‚ÄúWhat was the clearest concept this week, and why did it click?‚Äù or ‚ÄúWhat was the ‚Äòmuddiest‚Äô point for you, and what question would you ask about it?‚Äù. They can also take the form of just a general reflection. I want to get to know you and your learning throughout this process. This can also include anything related to your personal life or mental health that you would like for me to know, such as whether you are struggling to balance classes and research, having trouble creating a workspace at home, or whether you can balance time spent on campus and off. This can also be completely random things, like a news article you can‚Äôt stop thinking about, or a favorite TV show, movie or book that you just love (especially if it is LOTR or Cosmere related). The content of what you write has no impact on your grade. In addition, what you write will be kept confidential.\nThe purpose of this ‚Äúassignment‚Äù is to help facilitate communication between you and me. I have found other instructors using this and I would like to be able to develop supportive relationships with students, so I decided to implement this. Other instructors reported that they found that many students were more comfortable discussing questions and concerns in their journal assignments rather than through email.\nIn-Class Engagement & Activities\nOur class is a workshop, and your active participation is key. This portion of your grade is earned by being present and engaged. This includes participating in group discussions, engaging with the readings, working with peers on problems, and completing the small, hands-on coding exercises we‚Äôll do together or in small groups in class. This is a low-stress grade based on your consistent effort and collaboration during our classes.\nMidterm Project\nThis is a comprehensive analysis of a dataset I will provide. You will be asked to clean and visualize the data, formulate a research question, build an appropriate regression model, check its assumptions, and write a concise report of your findings. This project assesses your mastery of the first half of the course and will be due before the first class after Fall Break.\nFinal Project\nFor your final project, you will choose a dataset (either your own research data or from a list of options), develop your own research questions, and conduct a full analysis from start to finish. You will present your work in a short, manuscript-style report and a brief ‚Äúlightning talk‚Äù to the class in our final meeting. This is your capstone assignment to demonstrate your independent data analysis skills.\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. There will be a 15% deduction on the first day. And a 5% increase for each day beyond the deadline. Work will not be accepted beyond 5 days after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nYou may use generative AI tools (such as ChatGPT, Grammarly, or CoPilot) as a support for your work in this course. However:\n\nYou must personally review, edit, and take ownership of all submitted work.\nAny use of AI must be acknowledged in a brief note at the end of the assignment (e.g., ‚ÄúI used ChatGPT to generate initial bullet points for my resume, which I then revised and expanded.‚Äù) as well as being properly cited (RIT Library Citation Infoguide)\nAI tools may not be used to generate entire assignments without your input or to misrepresent your work. Submitting unedited or minimally edited AI output as your own is considered academic dishonesty.\nIn professional contexts, you will be expected to present work that is authentically your own ‚Äî this course is practice for that.\n\nIf I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment. Your information may also be submitted to the university as a Breach of Academic Integrity.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#psyc-640-graduate-statistics",
    "href": "syllabus.html#psyc-640-graduate-statistics",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nWednesdays 9 - 11am or By Appointment\n\n\nClass Times\nMondays 8:00 - 10:50am\n\n\nClass Location\nWallace - 4640\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course is the introduction to statistics for graduate students. The goal of the course is to provide a grounding in statistical concepts, methods and application to research. I aim to increase student‚Äôs confidence in using these techniques and introducing them to R. Topics will range from including mathematical conceptualizations to practical application with various techniques ranging from descriptive statistics to regression.\n\n\n\n\nWe will be using R for all data wrangling, visualization, and analysis. You may use another statistical program in this course, but I will only be providing examples in R. Students must have the latest version of R and it is strongly recommended that students also download the RStudio GUI, both can be found here. Both types of software are free.\nWe will primarily be referring to chapters in the following textbooks:\n\nIntroduction to Modern Statistics (2e) (Cetinkaya-Rundel & Hardin, 2024)\nLearning Statistics with R (Navarro)\nR for Data Science (2e) (Wickham, √áetinkaya-Rundel, & Grolemund, 2023)\nModern Statistics with R (2e) (Thullin, 2025)\nStatistical Thinking (Poldrack, 2024)\nAn Introduction to Statistical Learning (2e) (James, Witten, Hastie & Tibshirani, 2023)\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) (Judd, McClelland, & Ryan, 2017)\n\nThese textbooks are available for free online and able to be downloaded. You may choose to purchase a paper copy if you wish, but it is not required.\nAll additional readings will be provided by the instructor.\n\n\n\n\n\n\nImportant\n\n\n\nNote: Readings on the schedule will need to be completed prior to the course they are listed for. We will build on the concepts you read about in that specific class period, so it is important that you have read.\n\n\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\nEvaluation and Grading\nYour grade is a reflection of your consistent effort, active engagement with the material, and ability to apply new concepts. The components are designed to build on one another, leading to a comprehensive understanding of data analysis.\n\n\n\n\n\n\n\nComponent\nWeight\n\n\nWeekly Labs\n30%\n\n\nJournal Entries\n10%\n\n\nParticipation & Engagement\n15%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n25%\n\n\n\nWeekly Labs\nThese are hands-on R assignments that directly reinforce the concepts from the week‚Äôs class. They are your primary opportunity to practice coding, build models, and interpret results. Labs will be submitted as R Markdown files, and your lowest score will be dropped. Labs will be due the Sunday night (11:59pm) before the next class.\nJournal Entries\nEach week, you will submit a short, reflective journal entry. This is a space for metacognition‚Äîthinking about your own learning. Prompts will include questions like, ‚ÄúWhat was the clearest concept this week, and why did it click?‚Äù or ‚ÄúWhat was the ‚Äòmuddiest‚Äô point for you, and what question would you ask about it?‚Äù. They can also take the form of just a general reflection. I want to get to know you and your learning throughout this process. This can also include anything related to your personal life or mental health that you would like for me to know, such as whether you are struggling to balance classes and research, having trouble creating a workspace at home, or whether you can balance time spent on campus and off. This can also be completely random things, like a news article you can‚Äôt stop thinking about, or a favorite TV show, movie or book that you just love (especially if it is LOTR or Cosmere related). The content of what you write has no impact on your grade. In addition, what you write will be kept confidential.\nThe purpose of this ‚Äúassignment‚Äù is to help facilitate communication between you and me. I have found other instructors using this and I would like to be able to develop supportive relationships with students, so I decided to implement this. Other instructors reported that they found that many students were more comfortable discussing questions and concerns in their journal assignments rather than through email.\nIn-Class Engagement & Activities\nOur class is a workshop, and your active participation is key. This portion of your grade is earned by being present and engaged. This includes participating in group discussions, engaging with the readings, working with peers on problems, and completing the small, hands-on coding exercises we‚Äôll do together or in small groups in class. This is a low-stress grade based on your consistent effort and collaboration during our classes.\nMidterm Project\nThis is a comprehensive analysis of a dataset I will provide. You will be asked to clean and visualize the data, formulate a research question, build an appropriate regression model, check its assumptions, and write a concise report of your findings. This project assesses your mastery of the first half of the course and will be due before the first class after Fall Break.\nFinal Project\nFor your final project, you will choose a dataset (either your own research data or from a list of options), develop your own research questions, and conduct a full analysis from start to finish. You will present your work in a short, manuscript-style report and a brief ‚Äúlightning talk‚Äù to the class in our final meeting. This is your capstone assignment to demonstrate your independent data analysis skills.\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. There will be a 15% deduction on the first day. And a 5% increase for each day beyond the deadline. Work will not be accepted beyond 5 days after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nYou may use generative AI tools (such as ChatGPT, Grammarly, or CoPilot) as a support for your work in this course. However:\n\nYou must personally review, edit, and take ownership of all submitted work.\nAny use of AI must be acknowledged in a brief note at the end of the assignment (e.g., ‚ÄúI used ChatGPT to generate initial bullet points for my resume, which I then revised and expanded.‚Äù) as well as being properly cited (RIT Library Citation Infoguide)\nAI tools may not be used to generate entire assignments without your input or to misrepresent your work. Submitting unedited or minimally edited AI output as your own is considered academic dishonesty.\nIn professional contexts, you will be expected to present work that is authentically your own ‚Äî this course is practice for that.\n\nIf I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment. Your information may also be submitted to the university as a Breach of Academic Integrity.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-plan",
    "href": "syllabus.html#course-plan",
    "title": "Syllabus",
    "section": "Course Plan",
    "text": "Course Plan\nThis is subject to change and instructor will inform the students as soon as possible.\n\nWeek 1 ‚Äî Getting Started with R & Tidy Data\n\nWe‚Äôll dive right into our primary tool, R. This session covers installing R and RStudio, navigating the interface, understanding R projects, and learning the foundational syntax of the R language and the tidyverse, including data types and basic functions.\n\nWeek 2 ‚Äî LABOR DAY (NO CLASS)\n\nContinue to develop skills and comfort in R. You will be provided with readings and other practice problems, and maybe a video lecture.\n\nWeek 3 ‚Äî Describing, Visualizing & Communicating\n\nWhat is in our data? We‚Äôll learn how to calculate descriptive statistics (e.g., mean, median, standard deviation) and master the ‚Äúgrammar of graphics‚Äù to create compelling, publication-quality plots with ggplot2. We will also introduce R Markdown for creating reproducible reports.\n\nWeek 4 ‚Äî Designing Studies & Sampling\n\nThis is a conceptual week focusing on the foundations of research. We‚Äôll discuss different research designs (experimental, correlational), sampling methods, the distinction between a sample and a population, and the fundamental logic of null hypothesis significance testing (NHST).\n\nWeek 5 ‚Äî Correlations & Effect Sizes\n\nWe‚Äôll quantify the relationship between two continuous variables using covariance and correlation. We will also introduce the concept of effect sizes as a standardized way to describe the magnitude of a relationship, moving beyond a simple ‚Äúyes/no‚Äù significance test. ‚ÄúHow strong is the association?‚Äù\n\nWeek 6 ‚Äî Comparing Groups\n\nWe‚Äôll explore classic methods for comparing group means, including independent and paired-samples t-tests. We‚Äôll conduct these tests in R and learn how to interpret their output. This will serve as our first formal hypothesis-testing tool.\n\nWeek 7 ‚Äî Building to Regression: Variability & Model Fit\n\nWe‚Äôll introduce the core logic of the General Linear Model by partitioning variance. Concepts like sums of squares will be introduced to help us understand how a model ‚Äúexplains‚Äù variance in an outcome variable. We will introduce R2 as a fundamental measure of model fit. ‚ÄúHow much of the outcome can we explain?‚Äù\n\n\n\n\nWeek 8 ‚Äî FALL BREAK (NO CLASS) üçÇ\n\n\n\nWeek 9 ‚Äî Simple Linear Regression\n\nThe formal introduction to the regression model: Yi‚Äã=Œ≤0‚Äã+Œ≤1‚ÄãXi‚Äã+œµi‚Äã. We will learn how to estimate the model‚Äôs parameters (intercept and slope), interpret their meaning, and assess overall model fit using the lm() function in R. ‚ÄúWhat is the exact formula for prediction?‚Äù\n\n\n\n\nWeek 10 ‚Äî Multiple Regression I: Adding Predictors\n\nWe‚Äôll expand our model to include multiple continuous predictors. Key topics include interpreting partial slopes (the effect of one predictor while controlling for others), understanding adjusted R2, and identifying issues like multicollinearity.\n\n\n\n\nWeek 11 ‚Äî Multiple Regression II: Categorical Predictors\n\nHow do we include groups (e.g., experimental conditions) in our regression model? We‚Äôll learn about dummy coding and indicator variables. This is where we will explicitly demonstrate that t-tests and ANOVA are simply special cases of regression.\n\n\n\n\nWeek 12 ‚Äî Assumptions + Model Diagnostics\n\nIs our model trustworthy? We will learn how to check the assumptions of ordinary least squares (OLS) regression, including linearity, normality of residuals, and homoscedasticity. We will use graphical methods in R to diagnose problems and discuss potential remedies.\n\n\n\n\nWeek 13 ‚Äî Expanding Regression\n\nTopics: We will explore ways to capture more complex relationships in our data. The primary focus will be on adding interaction terms to the model to test for moderation, but we may also touch on including non-linear relationships (e.g., quadratic terms) or talk about some mediation!\n\n\n\n\nWeek 14 ‚Äî Model Building + Comparison\n\nHow do we choose the best model? We will discuss practical strategies for building models, such as hierarchical regression, and learn how to use information criteria (like AIC and BIC) to compare different competing models.\n\n\n\n\nWeek 15 ‚Äî Making R work for you\n\nWe‚Äôve worked a whole lot with R, but what are some of the cool things that it can do. We will explore and organize what we have learned so far to solidify the use of R for reproducible workflows!\n\n\n\n\nWeek 16 ‚Äî Wrapping Up + Workshop\n\nThis final session will serve two purposes. First, it will be a dedicated workshop for you to get help and ask questions about your final projects. Second, we will have a course wrap-up, reviewing the major themes and discussing next steps for your statistical journey.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "previous-years.html",
    "href": "previous-years.html",
    "title": "Previous Years",
    "section": "",
    "text": "This course has been taught for a number of years, but this instructor has only started teaching it in Fall 2023. Below are previous iterations of the course in case you would like to check out how it has progressed!",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "previous-years.html#overview",
    "href": "previous-years.html#overview",
    "title": "Previous Years",
    "section": "",
    "text": "This course has been taught for a number of years, but this instructor has only started teaching it in Fall 2023. Below are previous iterations of the course in case you would like to check out how it has progressed!",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "previous-years.html#fall-2023",
    "href": "previous-years.html#fall-2023",
    "title": "Previous Years",
    "section": "Fall 2023",
    "text": "Fall 2023\nWebsite",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "previous-years.html#fall-2024",
    "href": "previous-years.html#fall-2024",
    "title": "Previous Years",
    "section": "Fall 2024",
    "text": "Fall 2024\nWebsite",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-1",
    "href": "slides/lec-1_background.html#replication-reproducibility-1",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üç∞",
    "text": "Replication & Reproducibility üç∞\nI want to bake a cake!\n\nFind a recipe online (try ignoring their life story narrative)\nGet ingredients (Wegmans if you üí∞)\nFollow recipe and bake üßë‚Äçüç≥\nEnjoy the delicious cake üçΩÔ∏è\n\n\nReplication"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-2",
    "href": "slides/lec-1_background.html#replication-reproducibility-2",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üç∞",
    "text": "Replication & Reproducibility üç∞\nI want to bake a cake!\nReproduction\n\nFind a recipe online ‚Äì&gt; Find their kitchen\nGet ingredients ‚Äì&gt; Use their ingredients\nFollow recipe and bake ‚Äì&gt; Watch what they do and follow\nEnjoy the delicious cake ‚Äì&gt; Enjoy cake (and jail for B&E)"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-3",
    "href": "slides/lec-1_background.html#replication-reproducibility-3",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üìä",
    "text": "Replication & Reproducibility üìä\n\n\n\n\n\n\n\n\nReplication\nReproducibility\n\n\n\n\nHave a similar research question\nUse the same research question\n\n\nCollect your own data\nUse their data\n\n\nFollow their steps with your resources\nFollow their steps with their resources\n\n\nOutcome: Similar results (depends on other factors)\nOutcome: Identical results"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-4",
    "href": "slides/lec-1_background.html#replication-reproducibility-4",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üìä",
    "text": "Replication & Reproducibility üìä\nGoals of Science\nImportant: We want to replicate other researchers work\nMOST Important: Be able to reproduce all of our results\nYou are your own worst collaborator!"
  },
  {
    "objectID": "slides/lec-1_background.html#garden-of-forking-paths",
    "href": "slides/lec-1_background.html#garden-of-forking-paths",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Garden of Forking Paths",
    "text": "Garden of Forking Paths"
  },
  {
    "objectID": "slides/lec-1_background.html#installing-and-using-r",
    "href": "slides/lec-1_background.html#installing-and-using-r",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Installing and Using R",
    "text": "Installing and Using R\nFrom the course website\nModern Statistics Using R"
  },
  {
    "objectID": "slides/lec-1_background.html#working-with-r-studio",
    "href": "slides/lec-1_background.html#working-with-r-studio",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Working with R-Studio",
    "text": "Working with R-Studio\nR-Studio is just like a kitchen üßë‚Äçüç≥\nThe Environment pane is the pantry/fridge\nThe Console is like the oven/stove\nThe Markdown document is the recipe\nThe bottom right sometimes acts as the little window on the oven where you can see things baking\nCreating a Project puts these things in their place"
  },
  {
    "objectID": "slides/lec-1_background.html#next-steps",
    "href": "slides/lec-1_background.html#next-steps",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Next Steps",
    "text": "Next Steps\n\nCreate a project\nSet up a Markdown Document\nRun and Knit the document\nLive Example"
  },
  {
    "objectID": "slides/lec-5_correlation.html#today",
    "href": "slides/lec-5_correlation.html#today",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nExplore hypotheses, correlations and effect sizes\n\n# File management\nlibrary(here)\n# for dplyr, ggplot2\nlibrary(tidyverse)\n# Loading data\nlibrary(rio)\n# Pretty tables\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(ggstatsplot)\n\n#Remove Scientific Notation \noptions(scipen=999)"
  },
  {
    "objectID": "slides/lec-5_correlation.html#todays-roadmap",
    "href": "slides/lec-5_correlation.html#todays-roadmap",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Today‚Äôs Roadmap üó∫Ô∏è",
    "text": "Today‚Äôs Roadmap üó∫Ô∏è\n\nExplain the counterintuitive logic of Null Hypothesis Significance Testing (NHST)\nDefine and correctly interpret a p-value\nDistinguish what a p-value is from what it is not\nApply the steps of NHST to a research question"
  },
  {
    "objectID": "slides/lec-5_correlation.html#setting",
    "href": "slides/lec-5_correlation.html#setting",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Setting:",
    "text": "Setting:\nIn 1925, during a summer afternoon on campus, a lady, Dr.¬†Muriel Bristol (who has an algae species named after her), was handed a cup of tea by Ronald Fisher. She declined saying:\n‚ÄúI prefer the flavor when the milk is poured first. I can tell when there is a difference‚Äù\nFisher, being a statistician and a white man:\n‚ÄúProve it‚Äù\n\n\n\n\n\n\nNote\n\n\nSometimes, groundbreaking insights arise from everyday claims!"
  },
  {
    "objectID": "slides/lec-5_correlation.html#designing-the-test",
    "href": "slides/lec-5_correlation.html#designing-the-test",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Designing the Test:",
    "text": "Designing the Test:\nFisher prepared 8 cups of tea; 4 with milk first & 4 with tea first\nDr.¬†Muriel Bristol correctly identified 3 out of 4 of each! (some reports claim she identified all correctly)\nWas it just chance or genuine ability?\n\n\n\n\n\n\nNote\n\n\nAlways consider both outcomes. In hypothesis testing, this means setting up null and alternative hypotheses."
  },
  {
    "objectID": "slides/lec-5_correlation.html#birth-of-hypothesis-testing",
    "href": "slides/lec-5_correlation.html#birth-of-hypothesis-testing",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Birth of Hypothesis Testing:",
    "text": "Birth of Hypothesis Testing:\nFisher framed it as a combinatorial problem\nIf it was mere luck/chance, the probability of getting all 8 correct was low\nThis way of thinking is the groundwork for the concept of the p-value\n\n\n\n\n\n\nImportant\n\n\nThe p-value gives the probability of observing data (or something more extreme) given that the null hypothesis is true."
  },
  {
    "objectID": "slides/lec-5_correlation.html#the-tortured-logic-of-nhst",
    "href": "slides/lec-5_correlation.html#the-tortured-logic-of-nhst",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "The Tortured Logic of NHST",
    "text": "The Tortured Logic of NHST\nWe create two hypotheses, \\(H_0\\) and \\(H_1\\). Usually, we care about \\(H_1\\), not \\(H_0\\). In fact, what we really want to know is how likely \\(H_1\\), given our data.\n\\[P(H_1|Data)\\] Instead, we‚Äôre going to test our null hypothesis. Well, not really. We‚Äôre going to assume our null hypothesis is true, and test how likely we would be to get these data.\n\\[P(Data|H_0)\\]"
  },
  {
    "objectID": "slides/lec-5_correlation.html#nhst-analogy-the-legal-system",
    "href": "slides/lec-5_correlation.html#nhst-analogy-the-legal-system",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "NHST Analogy: The Legal System",
    "text": "NHST Analogy: The Legal System\n\nThe Null Hypothesis ( \\(H_0\\) ) is the starting assumption: ‚Äúpresumed innocent.‚Äù In research, this means assuming there is no effect, no relationship, or no difference.\nYou, the researcher, are the prosecution, gathering evidence (data) to challenge this presumption.\nYour p-value reflects the strength of your evidence. A small p-value likely means your evidence is strong.\nRejecting the null is like a ‚Äúguilty‚Äù verdict. You have enough evidence to say the initial presumption of innocence (no effect) is unlikely to be true."
  },
  {
    "objectID": "slides/lec-5_correlation.html#p-value-formal-definition",
    "href": "slides/lec-5_correlation.html#p-value-formal-definition",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "p-value: Formal Definition",
    "text": "p-value: Formal Definition\nThis is one of the most important‚Äîand misunderstood‚Äîconcepts in statistics.\nThe p-value is:\n\nThe probability of observing a result as extreme as, or more extreme than, the one we actually observed, assuming the null hypothesis is true."
  },
  {
    "objectID": "slides/lec-5_correlation.html#p-value-formal-definition-1",
    "href": "slides/lec-5_correlation.html#p-value-formal-definition-1",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "p-value: Formal Definition",
    "text": "p-value: Formal Definition\nThis is one of the most important‚Äîand misunderstood‚Äîconcepts in statistics.\nIt is NOT:\n\nThe probability that the null hypothesis is true\nThe probability that our research hypothesis is true\nA measure of the size or importance of an effect"
  },
  {
    "objectID": "slides/lec-5_correlation.html#what-are-the-steps-of-nhst",
    "href": "slides/lec-5_correlation.html#what-are-the-steps-of-nhst",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "What are the steps of NHST?",
    "text": "What are the steps of NHST?\n\n\n\nDefine null and alternative hypothesis.\nSet and justify alpha level (usually \\(\\alpha\\) = .05)\nDetermine which sampling distribution ( \\(z\\), \\(t\\), or \\(\\chi^2\\) for now)\nCalculate parameters of your sampling distribution under the null.\n\n\nIf \\(z\\), calculate \\(\\mu\\) and \\(\\sigma_M\\)\n\n\n\nCalculate test statistic under the null.\n\n\nIf \\(z\\), \\(\\frac{\\bar{X} - \\mu}{\\sigma_M}\\)\n\n\nCalculate probability of that test statistic or more extreme under the null, and compare to alpha."
  },
  {
    "objectID": "slides/lec-5_correlation.html#think-about",
    "href": "slides/lec-5_correlation.html#think-about",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "üß† Think about‚Ä¶",
    "text": "üß† Think about‚Ä¶\n\nYou run a correlational analysis to see if levels of anxiety are related to caffeine consumption. You get a correlation of 0.38 and a p-value of p = .045.\n\nTurn to someone next to you and in your own words, explain what the p-value is telling you.\n\nLooking at the p-value, what can you conclude?\nLooking at the p-value, what can‚Äôt you conclude?"
  },
  {
    "objectID": "slides/lec-5_correlation.html#more-thinking",
    "href": "slides/lec-5_correlation.html#more-thinking",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "üß†More thinking‚Ä¶",
    "text": "üß†More thinking‚Ä¶\nWhat if you ran the same study and analyses, but found that your p-value was p = .052?"
  },
  {
    "objectID": "slides/lec-5_correlation.html#what-is-a-correlation",
    "href": "slides/lec-5_correlation.html#what-is-a-correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "What is a Correlation?",
    "text": "What is a Correlation?\nA statistical expression that quantifies the extent to which two continuous variables are linearly related\nAssociation - Correlation\nWill tell us 2 key pieces of information about the relationship:\n\nDirection (Positive vs.¬†Negative)\nStrength (Magnitude from 0 to 1)"
  },
  {
    "objectID": "slides/lec-5_correlation.html#example-candy-of-houses",
    "href": "slides/lec-5_correlation.html#example-candy-of-houses",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Example: Candy & # of Houses",
    "text": "Example: Candy & # of Houses\nResearch Question: Is there a relationship between the amount of candy we receive on Halloween and the # of houses that we go to?\n\nVariables:\n\nhouse_n: Number of houses approached\ncandy: Amount of candy (# of pieces)\n\nHypothesis \\(H_A\\) : There will be a positive correlation. As a trick-or-treater goes to more houses, their amount of candy will increase ( \\(r \\neq 0\\) .\nNull Hypothesis \\(H_0\\): There is no correlation ( \\(r = 0\\) )."
  },
  {
    "objectID": "slides/lec-5_correlation.html#association---covariance",
    "href": "slides/lec-5_correlation.html#association---covariance",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Association - Covariance",
    "text": "Association - Covariance\nBefore we talk about correlation, we need to take a look at covariance\n\\[\ncov_{xy} = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{N-1}\n\\]\n\nCovariance can be thought of as the ‚Äúaverage cross product‚Äù between two variables\nIt captures the raw/unstandardized relationship between two variables\nCovariance matrix is the basis for many statistical analyses"
  },
  {
    "objectID": "slides/lec-5_correlation.html#covariance-to-correlation",
    "href": "slides/lec-5_correlation.html#covariance-to-correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Covariance to Correlation",
    "text": "Covariance to Correlation\nThe Pearson correlation coefficient \\(r\\) addresses this by standardizing the covariance\nIt is done in the same way that we would create a \\(z-score\\)‚Ä¶by dividing by the standard deviation\n\\[\nr_{xy} = \\frac{Cov(x,y)}{sd_x sd_y}\n\\]"
  },
  {
    "objectID": "slides/lec-5_correlation.html#pearsons-r",
    "href": "slides/lec-5_correlation.html#pearsons-r",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Pearson‚Äôs \\(r\\)",
    "text": "Pearson‚Äôs \\(r\\)\nRange: Varies from -1 (perfect negative correlation) and +1 (perfect positive correlation)\nAssumptions:\n\nContinuous Variables: Both variables are measured on an interval or ratio scale.\nLinearity: The relationship between the variables is linear. (This is why you must visualize your data!)\nBivariate Normality: Data points are normally distributed for both variables. (Pearson‚Äôs \\(r\\) is fairly robust to minor violations)."
  },
  {
    "objectID": "slides/lec-5_correlation.html#calculating-correlation-in-r",
    "href": "slides/lec-5_correlation.html#calculating-correlation-in-r",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Calculating Correlation in R",
    "text": "Calculating Correlation in R\nNow how do we get a correlation value in R?\n\ncor(corr_data$house_n, corr_data$candy)\n\n[1] 0.8929946\n\n\nThat will give us the correlation, but we also want to know how to get our p-value"
  },
  {
    "objectID": "slides/lec-5_correlation.html#significance",
    "href": "slides/lec-5_correlation.html#significance",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Significance",
    "text": "Significance\nThe \\(p-value\\) gives us the statistical significance. It will tell us that the effect we identified is likely not to be 0\nIt does not tell us anything about how large or meaningful the effect actually is. This is where the effect size comes in!\n\n\n\n\n\n\nImportant\n\n\nWith a large enough sample size, even a tiny, trivial correlation (e.g., r &lt; 0.1) can become statistically significant. Think about what happens to sampling distribution when sample size increases.\n\n\n\nStatistical Significance \\(\\neq\\) Practical Significance"
  },
  {
    "objectID": "slides/lec-5_correlation.html#effect-sizes-correlation",
    "href": "slides/lec-5_correlation.html#effect-sizes-correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Effect Sizes: Correlation",
    "text": "Effect Sizes: Correlation\nFor correlation, we have two related measures of effect size:\n\nPearson‚Äôs \\(r\\): The correlation coefficient itself. A standardized measure of the strength and direction of the linear association.\n\nCohen‚Äôs Conventions (a rough guide): Small (‚à£.10‚à£), Medium (‚à£.30‚à£), Large (‚à£.50‚à£).\nOur finding of \\(r = 0.89\\) is a large effect.\n\nCoefficient of Determination (\\(R^2\\)): This is simply r squared. It represents the proportion of variance in one variable that is ‚Äúexplained‚Äù or ‚Äúaccounted for‚Äù by the other."
  },
  {
    "objectID": "slides/lec-5_correlation.html#age-x-ess_total-visualize",
    "href": "slides/lec-5_correlation.html#age-x-ess_total-visualize",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Age x ESS_total: Visualize",
    "text": "Age x ESS_total: Visualize\nLet‚Äôs examine the overall correlation between Age and overall sleepiness\nFirst: Visualize\n\n\nCode\nsleep_data %&gt;% \n  ggplot(aes(age, ess_tot)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE)\n\n\n\nIt doesn‚Äôt seem like there is much of a relationship here‚Ä¶"
  },
  {
    "objectID": "slides/lec-5_correlation.html#age-x-ess_total-test",
    "href": "slides/lec-5_correlation.html#age-x-ess_total-test",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Age x ESS_total: Test",
    "text": "Age x ESS_total: Test\nLet‚Äôs check the overall correlation just to see what we are finding\n\ncor.test(sleep_data$age, sleep_data$ess_tot)\n\n\n    Pearson's product-moment correlation\n\ndata:  sleep_data$age and sleep_data$ess_tot\nt = -2.2489, df = 1450, p-value = 0.02467\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.110064846 -0.007534546\nsample estimates:\n        cor \n-0.05895518"
  },
  {
    "objectID": "slides/lec-5_correlation.html#writing-up-example",
    "href": "slides/lec-5_correlation.html#writing-up-example",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Writing up: Example",
    "text": "Writing up: Example\nWe have all of the pieces for writing up our correlation between age and sleepiness.\nTemplate: r(degress of freedom) = the r statistic, p = p value.\n\nAmong the students in the sample, age was negatively related to overall levels of sleepiness (r(1450) = -0.06, p = .024).\n\nWhat about our \\(R^2\\) value?\n\\(R^2 = -0.06^2 = 0.0034\\). Therefore, approximately 0.34% of the variability in the sleepiness scale (ess_tot) is explained by age. Is this meaningful?"
  },
  {
    "objectID": "slides/lec-5_correlation.html#handling-missing---correlation",
    "href": "slides/lec-5_correlation.html#handling-missing---correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Handling Missing - Correlation",
    "text": "Handling Missing - Correlation\n\nListwise Deletion (complete cases)\n\nRemoves participants completely if they are missing a value being compared\nSmaller Sample Sizes\nDoesn‚Äôt bias correlation estimate\n\nPairwise Deletion\n\nRemoves participants for that single pair, but leaves information in when there are complete information\nLarger Sample Sizes\nCould bias estimates if there is a systematic reason things are missing"
  },
  {
    "objectID": "slides/lec-5_correlation.html#spearmans-rank-correlation-1",
    "href": "slides/lec-5_correlation.html#spearmans-rank-correlation-1",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Spearman‚Äôs Rank Correlation",
    "text": "Spearman‚Äôs Rank Correlation\nWe need to be able to capture this different (ordinal) ‚Äúrelationship‚Äù\n\nIf student 1 works more hours than student 2, then we can guarantee that student 1 will get a better grade\n\nInstead of using the amount given by the variables (‚Äúhours studied‚Äù), we rank the variables based on least (rank = 1) to most (rank = 10)\nThen we correlate the rankings with one another"
  },
  {
    "objectID": "slides/lec-5_correlation.html#statistics-and-eugenics",
    "href": "slides/lec-5_correlation.html#statistics-and-eugenics",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Statistics and Eugenics",
    "text": "Statistics and Eugenics\nThe concept of the correlation is primarily attributed to Sir Frances Galton\n\nHe was also the founder of the concept of eugenics\n\nThe correlation coefficient was developed by his student, Karl Pearson, and adapted into the ANOVA framework by Sir Ronald Fisher\n\nBoth were prominent advocates for the eugenics movement"
  },
  {
    "objectID": "slides/lec-5_correlation.html#what-do-we-do-with-this-info",
    "href": "slides/lec-5_correlation.html#what-do-we-do-with-this-info",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "What do we do with this info?",
    "text": "What do we do with this info?\n\nNever use the correlation or the later techniques developed on it? Of course not.\nAcknowledge this history? Certainly.\nUnderstand how the perspectives of Galton, Fisher, Pearson and others shaped our practices? We must! ‚Äì these are not set in stone, nor are they necessarily the best way to move forward."
  },
  {
    "objectID": "slides/lec-5_correlation.html#be-aware-of-the-assumptions",
    "href": "slides/lec-5_correlation.html#be-aware-of-the-assumptions",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Be aware of the assumptions",
    "text": "Be aware of the assumptions\n\nStatistics are often thought of as being absent of bias‚Ä¶they are just numbers\nStatistical significance was a way to avoid talking about nuance or degree.\n‚ÄúCorrelation does not imply causation‚Äù was a refutation of work demonstrating associations between environment and poverty.\nNeed to be particularly mindful of our goals as scientists and how they can influence the way we interpret the findings"
  },
  {
    "objectID": "slides/lec-5_correlation.html#correlation-tables",
    "href": "slides/lec-5_correlation.html#correlation-tables",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Correlation Tables",
    "text": "Correlation Tables\nBefore we used the cor() function to create a correlation matrix of our variables\nBut what is missing?\n\nsleep_data %&gt;% \n  select(age, ESS1:ESS8, ess_tot) %&gt;% \n  cor(use = \"complete\") %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nESS1\nESS2\nESS3\nESS4\nESS5\nESS6\nESS7\nESS8\ness_tot\n\n\n\n\nage\n1.0000000\n-0.0057641\n0.0039691\n-0.0421214\n-0.1059506\n-0.0871016\n0.0484763\n0.0057761\n-0.0206676\n-0.0594733\n\n\nESS1\n-0.0057641\n1.0000000\n0.3303236\n0.2784836\n0.1455593\n0.2295289\n0.1422071\n0.2206383\n0.0984444\n0.5981508\n\n\nESS2\n0.0039691\n0.3303236\n1.0000000\n0.1976108\n0.1387409\n0.2190331\n0.1748049\n0.2134999\n0.1010883\n0.5565852\n\n\nESS3\n-0.0421214\n0.2784836\n0.1976108\n1.0000000\n0.2920448\n0.1948408\n0.2888370\n0.2778982\n0.2178073\n0.6121220\n\n\nESS4\n-0.1059506\n0.1455593\n0.1387409\n0.2920448\n1.0000000\n0.2579808\n0.0897873\n0.2589136\n0.2409171\n0.5936136\n\n\nESS5\n-0.0871016\n0.2295289\n0.2190331\n0.1948408\n0.2579808\n1.0000000\n0.0704590\n0.2821851\n0.0629151\n0.5718083\n\n\nESS6\n0.0484763\n0.1422071\n0.1748049\n0.2888370\n0.0897873\n0.0704590\n1.0000000\n0.2833070\n0.3493524\n0.4143559\n\n\nESS7\n0.0057761\n0.2206383\n0.2134999\n0.2778982\n0.2589136\n0.2821851\n0.2833070\n1.0000000\n0.2356524\n0.6088579\n\n\nESS8\n-0.0206676\n0.0984444\n0.1010883\n0.2178073\n0.2409171\n0.0629151\n0.3493524\n0.2356524\n1.0000000\n0.4293874\n\n\ness_tot\n-0.0594733\n0.5981508\n0.5565852\n0.6121220\n0.5936136\n0.5718083\n0.4143559\n0.6088579\n0.4293874\n1.0000000"
  },
  {
    "objectID": "slides/lec-5_correlation.html#correlation-tables---sjplot",
    "href": "slides/lec-5_correlation.html#correlation-tables---sjplot",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Correlation Tables - sjPlot",
    "text": "Correlation Tables - sjPlot\n\nsleep_data %&gt;% \n  select(ESS1:ESS8) %&gt;% \n  tab_corr(na.deletion = \"listwise\", triangle = \"lower\")\n\n\n\n\n¬†\nESS1\nESS2\nESS3\nESS4\nESS5\nESS6\nESS7\nESS8\n\n\nESS1\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS2\n0.330***\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS3\n0.278***\n0.198***\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS4\n0.146***\n0.139***\n0.292***\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS5\n0.230***\n0.219***\n0.195***\n0.258***\n¬†\n¬†\n¬†\n¬†\n\n\nESS6\n0.142***\n0.175***\n0.289***\n0.090***\n0.070**\n¬†\n¬†\n¬†\n\n\nESS7\n0.221***\n0.213***\n0.278***\n0.259***\n0.282***\n0.283***\n¬†\n¬†\n\n\nESS8\n0.098***\n0.101***\n0.218***\n0.241***\n0.063*\n0.349***\n0.236***\n¬†\n\n\nComputed correlation used pearson-method with listwise-deletion."
  },
  {
    "objectID": "slides/lec-5_correlation.html#correlation-tables---sjplot-1",
    "href": "slides/lec-5_correlation.html#correlation-tables---sjplot-1",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Correlation Tables - sjPlot",
    "text": "Correlation Tables - sjPlot\nSo many different cusomizations for this type of plot\nCan add titles, indicate what missingness and method\nSaves you a TON of time when putting it into a manuscript"
  },
  {
    "objectID": "slides/lec-5_correlation.html#scatterplot",
    "href": "slides/lec-5_correlation.html#scatterplot",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Scatterplot",
    "text": "Scatterplot\nBefore we had a scatterplot that looked like this:\n\nsleep_data %&gt;% \n  ggplot(aes(age, ess_tot)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) + \n  labs(\n    x = \"Age\", \n    y = \"ESS Total\", \n    title = \"Relationship between Age and Sleepiness\" \n  )"
  },
  {
    "objectID": "slides/lec-5_correlation.html#fancier-scatterplot",
    "href": "slides/lec-5_correlation.html#fancier-scatterplot",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Fancier Scatterplot",
    "text": "Fancier Scatterplot\nTake a look at ggstatsplot https://indrajeetpatil.github.io/ggstatsplot/\n\nggscatterstats(\n  data = sleep_data, \n  x = age, \n  y = ess_tot, \n  xlab = \"Age\", \n  ylab = \"ESS Total\", \n  title = \"Relationship between Age and Sleepiness\"\n)"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#some-terminology",
    "href": "slides/lec-3_desc-viz.html#some-terminology",
    "title": "Week 03: Describe & Vizualize",
    "section": "Some Terminology",
    "text": "Some Terminology\n\n\n\n\n\n\n\nPopulation\nSample\n\n\n\n\n\\(\\mu\\) (mu) = Population Mean\n\\(\\bar{X}\\) (x bar) = Sample Mean\n\n\n\\(\\sigma\\) (sigma) = Population Standard Deviation\n\\(s\\) = \\(\\hat{\\sigma}\\) = Sample Standard Deviation\n\n\n\\(\\sigma^2\\) (sigma squared) = Population Variance\n\\(s^2\\) = \\(\\hat{\\sigma^2}\\) = Sample Variance"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#measures-of-central-tendency",
    "href": "slides/lec-3_desc-viz.html#measures-of-central-tendency",
    "title": "Week 03: Describe & Vizualize",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nFor a given set of observations, measures of central tendency allow us to get the ‚Äúgist‚Äù of the data.\nThey tell us about where the ‚Äúaverage‚Äù or the ‚Äúmid-point‚Äù of the data lies or how much deviation there is from a central point.\nLet‚Äôs take a look at the data that we have already loaded in, and complete some of these tasks."
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#measures-of-variability",
    "href": "slides/lec-3_desc-viz.html#measures-of-variability",
    "title": "Week 03: Describe & Vizualize",
    "section": "Measures of Variability",
    "text": "Measures of Variability\nThe overall spread of the data; How far from the middle?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#variance",
    "href": "slides/lec-3_desc-viz.html#variance",
    "title": "Week 03: Describe & Vizualize",
    "section": "Variance",
    "text": "Variance\nThe sum of squared deviations\n\\[\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^N(X-\\bar{X})^2\\]\n\\[\\hat{\\sigma}^2 = s^2 = \\frac{1}{N-1}\\sum_{i=1}^N(X-\\bar{X})^2\\]"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#in-class-activity-variance",
    "href": "slides/lec-3_desc-viz.html#in-class-activity-variance",
    "title": "Week 03: Describe & Vizualize",
    "section": "In-Class Activity: Variance",
    "text": "In-Class Activity: Variance\nOpen up Instagram (that is still a thing right?)\nIdentify a celebrity and look at their most recent Instagram posts.\nLet‚Äôs calculate the variance of their likes.\nGoogle Form"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#variance-in-r",
    "href": "slides/lec-3_desc-viz.html#variance-in-r",
    "title": "Week 03: Describe & Vizualize",
    "section": "Variance in R",
    "text": "Variance in R\nTo find the variance and standard deviation, we use var() and sd(), respectively. Find the variance and standard deviation of the age variable.\n\nvar(tipi$age)\n\n[1] 3.399093\n\nsd(tipi$age)\n\n[1] 1.843663"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#describe",
    "href": "slides/lec-3_desc-viz.html#describe",
    "title": "Week 03: Describe & Vizualize",
    "section": "describe()",
    "text": "describe()\nThis function automatically calculates all of the descriptives we reviewed above (and more!). Use the describe() function from the psych package on the entire sleep_data dataset.\nNotes: If you load a library at the beginning, you can directly call any function from it. Instead, you can call a function by library_name::function_name without loading the entire library.\n\npsych::describe(tipi)\n\n                    vars  n    mean       sd median trimmed    mad    min\nid                     1 99 1058.12    31.05 1059.0 1057.93  38.55 1006.0\nprogress               2 99  100.00     0.00  100.0  100.00   0.00  100.0\nduration_in_seconds    3 99 7197.29 34904.64 1461.0 1527.88 486.29  623.0\nconsent                4 99    1.00     0.00    1.0    1.00   0.00    1.0\ngenderid               5 99    4.46     0.82    4.0    4.47   1.48    1.0\ngenderid_7_text*       6 99    1.03     0.22    1.0    1.00   0.00    1.0\nsex                    7 99    1.51     0.50    2.0    1.51   0.00    1.0\nage                    8 99   19.78     1.84   20.0   19.53   1.48   17.0\nyear_school            9 99    2.18     1.22    2.0    2.04   1.48    1.0\nq85                   10 99    1.64     1.32    1.0    1.32   0.00    1.0\nq85_6_text*           11 99    1.03     0.22    1.0    1.00   0.00    1.0\ntipi_1                12 99    3.99     1.90    4.0    3.99   2.97    1.0\ntipi_2                13 99    4.15     1.53    4.0    4.23   1.48    1.0\ntipi_3                14 99    5.38     1.26    6.0    5.51   1.48    1.0\ntipi_4                15 99    4.29     1.69    5.0    4.31   1.48    1.0\ntipi_5                16 99    5.38     1.28    6.0    5.52   1.48    1.0\ntipi_6                17 99    4.76     1.64    5.0    4.84   1.48    1.0\ntipi_7                18 99    5.45     1.24    6.0    5.57   1.48    2.0\ntipi_8                19 99    3.17     1.70    3.0    3.09   1.48    1.0\ntipi_9                20 99    5.01     1.35    5.0    5.05   1.48    2.0\ntipi_10               21 99    3.10     1.48    3.0    3.04   1.48    1.0\nsleep_quality         22 99    2.56     1.15    2.0    2.46   1.48    1.0\nhours_of_sleep        23 99    6.51     1.04    7.0    6.63   0.00    1.0\ntipi_2r               24 99    3.85     1.53    4.0    3.77   1.48    1.0\ntipi_4r               25 99    3.71     1.69    3.0    3.69   1.48    1.0\ntipi_6r               26 99    3.24     1.64    3.0    3.16   1.48    1.0\ntipi_8r               27 99    4.83     1.70    5.0    4.91   1.48    1.0\ntipi_10r              28 99    4.90     1.48    5.0    4.96   1.48    1.0\nextra                 29 99    3.62     1.60    3.5    3.56   2.22    1.0\nagree                 30 99    4.65     1.08    4.5    4.63   0.74    2.0\nconsc                 31 99    5.11     1.22    5.5    5.15   1.48    2.0\nemo                   32 99    4.36     1.29    4.5    4.37   1.48    1.5\nopen                  33 99    5.14     1.04    5.0    5.19   0.74    2.5\n                       max    range  skew kurtosis      se\nid                    1112    106.0  0.03    -1.21    3.12\nprogress               100      0.0   NaN      NaN    0.00\nduration_in_seconds 252521 251898.0  6.57    42.24 3508.05\nconsent                  1      0.0   NaN      NaN    0.00\ngenderid                 7      6.0 -0.81     5.57    0.08\ngenderid_7_text*         3      2.0  7.70    61.15    0.02\nsex                      2      1.0 -0.02    -2.02    0.05\nage                     31     14.0  2.67    12.52    0.19\nyear_school              5      4.0  0.73    -0.44    0.12\nq85                      7      6.0  2.18     4.14    0.13\nq85_6_text*              3      2.0  7.70    61.15    0.02\ntipi_1                   7      6.0  0.01    -1.34    0.19\ntipi_2                   7      6.0 -0.46    -0.58    0.15\ntipi_3                   7      6.0 -0.86     0.58    0.13\ntipi_4                   7      6.0 -0.17    -0.95    0.17\ntipi_5                   7      6.0 -0.94     0.86    0.13\ntipi_6                   7      6.0 -0.46    -0.86    0.17\ntipi_7                   7      5.0 -0.65    -0.08    0.12\ntipi_8                   7      6.0  0.37    -1.12    0.17\ntipi_9                   7      5.0 -0.29    -0.81    0.14\ntipi_10                  7      6.0  0.35    -0.71    0.15\nsleep_quality            5      4.0  0.87     0.14    0.12\nhours_of_sleep           8      7.0 -2.01     5.99    0.10\ntipi_2r                  7      6.0  0.46    -0.58    0.15\ntipi_4r                  7      6.0  0.17    -0.95    0.17\ntipi_6r                  7      6.0  0.46    -0.86    0.17\ntipi_8r                  7      6.0 -0.37    -1.12    0.17\ntipi_10r                 7      6.0 -0.35    -0.71    0.15\nextra                    7      6.0  0.18    -0.98    0.16\nagree                    7      5.0  0.11     0.04    0.11\nconsc                    7      5.0 -0.32    -0.70    0.12\nemo                      7      5.5 -0.10    -0.54    0.13\nopen                     7      4.5 -0.48     0.13    0.10\n\n# or if you have already loaded the library\n\ndescribe(tipi)\n\n                    vars  n    mean       sd median trimmed    mad    min\nid                     1 99 1058.12    31.05 1059.0 1057.93  38.55 1006.0\nprogress               2 99  100.00     0.00  100.0  100.00   0.00  100.0\nduration_in_seconds    3 99 7197.29 34904.64 1461.0 1527.88 486.29  623.0\nconsent                4 99    1.00     0.00    1.0    1.00   0.00    1.0\ngenderid               5 99    4.46     0.82    4.0    4.47   1.48    1.0\ngenderid_7_text*       6 99    1.03     0.22    1.0    1.00   0.00    1.0\nsex                    7 99    1.51     0.50    2.0    1.51   0.00    1.0\nage                    8 99   19.78     1.84   20.0   19.53   1.48   17.0\nyear_school            9 99    2.18     1.22    2.0    2.04   1.48    1.0\nq85                   10 99    1.64     1.32    1.0    1.32   0.00    1.0\nq85_6_text*           11 99    1.03     0.22    1.0    1.00   0.00    1.0\ntipi_1                12 99    3.99     1.90    4.0    3.99   2.97    1.0\ntipi_2                13 99    4.15     1.53    4.0    4.23   1.48    1.0\ntipi_3                14 99    5.38     1.26    6.0    5.51   1.48    1.0\ntipi_4                15 99    4.29     1.69    5.0    4.31   1.48    1.0\ntipi_5                16 99    5.38     1.28    6.0    5.52   1.48    1.0\ntipi_6                17 99    4.76     1.64    5.0    4.84   1.48    1.0\ntipi_7                18 99    5.45     1.24    6.0    5.57   1.48    2.0\ntipi_8                19 99    3.17     1.70    3.0    3.09   1.48    1.0\ntipi_9                20 99    5.01     1.35    5.0    5.05   1.48    2.0\ntipi_10               21 99    3.10     1.48    3.0    3.04   1.48    1.0\nsleep_quality         22 99    2.56     1.15    2.0    2.46   1.48    1.0\nhours_of_sleep        23 99    6.51     1.04    7.0    6.63   0.00    1.0\ntipi_2r               24 99    3.85     1.53    4.0    3.77   1.48    1.0\ntipi_4r               25 99    3.71     1.69    3.0    3.69   1.48    1.0\ntipi_6r               26 99    3.24     1.64    3.0    3.16   1.48    1.0\ntipi_8r               27 99    4.83     1.70    5.0    4.91   1.48    1.0\ntipi_10r              28 99    4.90     1.48    5.0    4.96   1.48    1.0\nextra                 29 99    3.62     1.60    3.5    3.56   2.22    1.0\nagree                 30 99    4.65     1.08    4.5    4.63   0.74    2.0\nconsc                 31 99    5.11     1.22    5.5    5.15   1.48    2.0\nemo                   32 99    4.36     1.29    4.5    4.37   1.48    1.5\nopen                  33 99    5.14     1.04    5.0    5.19   0.74    2.5\n                       max    range  skew kurtosis      se\nid                    1112    106.0  0.03    -1.21    3.12\nprogress               100      0.0   NaN      NaN    0.00\nduration_in_seconds 252521 251898.0  6.57    42.24 3508.05\nconsent                  1      0.0   NaN      NaN    0.00\ngenderid                 7      6.0 -0.81     5.57    0.08\ngenderid_7_text*         3      2.0  7.70    61.15    0.02\nsex                      2      1.0 -0.02    -2.02    0.05\nage                     31     14.0  2.67    12.52    0.19\nyear_school              5      4.0  0.73    -0.44    0.12\nq85                      7      6.0  2.18     4.14    0.13\nq85_6_text*              3      2.0  7.70    61.15    0.02\ntipi_1                   7      6.0  0.01    -1.34    0.19\ntipi_2                   7      6.0 -0.46    -0.58    0.15\ntipi_3                   7      6.0 -0.86     0.58    0.13\ntipi_4                   7      6.0 -0.17    -0.95    0.17\ntipi_5                   7      6.0 -0.94     0.86    0.13\ntipi_6                   7      6.0 -0.46    -0.86    0.17\ntipi_7                   7      5.0 -0.65    -0.08    0.12\ntipi_8                   7      6.0  0.37    -1.12    0.17\ntipi_9                   7      5.0 -0.29    -0.81    0.14\ntipi_10                  7      6.0  0.35    -0.71    0.15\nsleep_quality            5      4.0  0.87     0.14    0.12\nhours_of_sleep           8      7.0 -2.01     5.99    0.10\ntipi_2r                  7      6.0  0.46    -0.58    0.15\ntipi_4r                  7      6.0  0.17    -0.95    0.17\ntipi_6r                  7      6.0  0.46    -0.86    0.17\ntipi_8r                  7      6.0 -0.37    -1.12    0.17\ntipi_10r                 7      6.0 -0.35    -0.71    0.15\nextra                    7      6.0  0.18    -0.98    0.16\nagree                    7      5.0  0.11     0.04    0.11\nconsc                    7      5.0 -0.32    -0.70    0.12\nemo                      7      5.5 -0.10    -0.54    0.13\nopen                     7      4.5 -0.48     0.13    0.10\n\n\nNOTE: Some variables are not numeric and are categorical variables of type character. By default, the describe() function forces non-numeric variables to be numeric and attempts to calculate descriptives for them. These variables are marked with an asterisk (*). In this case, it doesn‚Äôt make sense to calculate descriptive statistics for these variables, so we get a warning message and a bunch of NaN‚Äôs and NA‚Äôs for these variables.\nA better approach would be to remove non-numeric variables before you attempt to run numerical calculations on your dataset."
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#make-it-pretty",
    "href": "slides/lec-3_desc-viz.html#make-it-pretty",
    "title": "Week 03: Describe & Vizualize",
    "section": "Make it Pretty",
    "text": "Make it Pretty\nUsing sjPlot (https://strengejacke.github.io/sjPlot/index.html) we can make things a little more publishable! You can use select() to also keep particular variables (maybe you don‚Äôt care about the skew)\n\ntipi %&gt;% \n  psych::describe() %&gt;% \n  sjPlot::tab_df()\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n1\n99\n1058.12\n31.05\n1059.00\n1057.93\n38.55\n1006.00\n1112\n106.00\n0.03\n-1.21\n3.12\n\n\n2\n99\n100.00\n0.00\n100.00\n100.00\n0.00\n100.00\n100\n0.00\nNaN\nNaN\n0.00\n\n\n3\n99\n7197.29\n34904.64\n1461.00\n1527.88\n486.29\n623.00\n252521\n251898.00\n6.57\n42.24\n3508.05\n\n\n4\n99\n1.00\n0.00\n1.00\n1.00\n0.00\n1.00\n1\n0.00\nNaN\nNaN\n0.00\n\n\n5\n99\n4.46\n0.82\n4.00\n4.47\n1.48\n1.00\n7\n6.00\n-0.81\n5.57\n0.08\n\n\n6\n99\n1.03\n0.22\n1.00\n1.00\n0.00\n1.00\n3\n2.00\n7.70\n61.15\n0.02\n\n\n7\n99\n1.51\n0.50\n2.00\n1.51\n0.00\n1.00\n2\n1.00\n-0.02\n-2.02\n0.05\n\n\n8\n99\n19.78\n1.84\n20.00\n19.53\n1.48\n17.00\n31\n14.00\n2.67\n12.52\n0.19\n\n\n9\n99\n2.18\n1.22\n2.00\n2.04\n1.48\n1.00\n5\n4.00\n0.73\n-0.44\n0.12\n\n\n10\n99\n1.64\n1.32\n1.00\n1.32\n0.00\n1.00\n7\n6.00\n2.18\n4.14\n0.13\n\n\n11\n99\n1.03\n0.22\n1.00\n1.00\n0.00\n1.00\n3\n2.00\n7.70\n61.15\n0.02\n\n\n12\n99\n3.99\n1.90\n4.00\n3.99\n2.97\n1.00\n7\n6.00\n0.01\n-1.34\n0.19\n\n\n13\n99\n4.15\n1.53\n4.00\n4.23\n1.48\n1.00\n7\n6.00\n-0.46\n-0.58\n0.15\n\n\n14\n99\n5.38\n1.26\n6.00\n5.51\n1.48\n1.00\n7\n6.00\n-0.86\n0.58\n0.13\n\n\n15\n99\n4.29\n1.69\n5.00\n4.31\n1.48\n1.00\n7\n6.00\n-0.17\n-0.95\n0.17\n\n\n16\n99\n5.38\n1.28\n6.00\n5.52\n1.48\n1.00\n7\n6.00\n-0.94\n0.86\n0.13\n\n\n17\n99\n4.76\n1.64\n5.00\n4.84\n1.48\n1.00\n7\n6.00\n-0.46\n-0.86\n0.17\n\n\n18\n99\n5.45\n1.24\n6.00\n5.57\n1.48\n2.00\n7\n5.00\n-0.65\n-0.08\n0.12\n\n\n19\n99\n3.17\n1.70\n3.00\n3.09\n1.48\n1.00\n7\n6.00\n0.37\n-1.12\n0.17\n\n\n20\n99\n5.01\n1.35\n5.00\n5.05\n1.48\n2.00\n7\n5.00\n-0.29\n-0.81\n0.14\n\n\n21\n99\n3.10\n1.48\n3.00\n3.04\n1.48\n1.00\n7\n6.00\n0.35\n-0.71\n0.15\n\n\n22\n99\n2.56\n1.15\n2.00\n2.46\n1.48\n1.00\n5\n4.00\n0.87\n0.14\n0.12\n\n\n23\n99\n6.51\n1.04\n7.00\n6.63\n0.00\n1.00\n8\n7.00\n-2.01\n5.99\n0.10\n\n\n24\n99\n3.85\n1.53\n4.00\n3.77\n1.48\n1.00\n7\n6.00\n0.46\n-0.58\n0.15\n\n\n25\n99\n3.71\n1.69\n3.00\n3.69\n1.48\n1.00\n7\n6.00\n0.17\n-0.95\n0.17\n\n\n26\n99\n3.24\n1.64\n3.00\n3.16\n1.48\n1.00\n7\n6.00\n0.46\n-0.86\n0.17\n\n\n27\n99\n4.83\n1.70\n5.00\n4.91\n1.48\n1.00\n7\n6.00\n-0.37\n-1.12\n0.17\n\n\n28\n99\n4.90\n1.48\n5.00\n4.96\n1.48\n1.00\n7\n6.00\n-0.35\n-0.71\n0.15\n\n\n29\n99\n3.62\n1.60\n3.50\n3.56\n2.22\n1.00\n7\n6.00\n0.18\n-0.98\n0.16\n\n\n30\n99\n4.65\n1.08\n4.50\n4.63\n0.74\n2.00\n7\n5.00\n0.11\n0.04\n0.11\n\n\n31\n99\n5.11\n1.22\n5.50\n5.15\n1.48\n2.00\n7\n5.00\n-0.32\n-0.70\n0.12\n\n\n32\n99\n4.36\n1.29\n4.50\n4.37\n1.48\n1.50\n7\n5.50\n-0.10\n-0.54\n0.13\n\n\n33\n99\n5.14\n1.04\n5.00\n5.19\n0.74\n2.50\n7\n4.50\n-0.48\n0.13\n0.10"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#ggplot2-from-the-tidyverse",
    "href": "slides/lec-3_desc-viz.html#ggplot2-from-the-tidyverse",
    "title": "Week 03: Describe & Vizualize",
    "section": "ggplot2 from the tidyverse",
    "text": "ggplot2 from the tidyverse\nSince we have already installed and loaded the library, we don‚Äôt have to do anything else at this point!\nggplot2 follows the ‚Äúgrammar of graphics‚Äù\n\nTheoretical framework for creating data visualizations\nBreaks the process down into separate components:\n\n\n\nData\nAesthetics (aes)\nGeometric Objects (geoms)\n\nFaceting\nThemes"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#grammar-of-graphics",
    "href": "slides/lec-3_desc-viz.html#grammar-of-graphics",
    "title": "Week 03: Describe & Vizualize",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#ggplot2-syntax",
    "href": "slides/lec-3_desc-viz.html#ggplot2-syntax",
    "title": "Week 03: Describe & Vizualize",
    "section": "ggplot2 syntax",
    "text": "ggplot2 syntax\nThere is a basic structure to create a plot within ggplot2, and consists of at least these three things:\n\nA Data Set\nCoordinate System\nGeoms - visual marks to represent the data points\n\nIn R it looks like this:\n\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;))\n\n#or how I like to do it\n&lt;DATA&gt; %&gt;% \n  ggplot(aes(&lt;MAPPINGS&gt;)) + \n  &lt;GEOM_FUNCTION&gt;()"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#ggplot2-syntax-1",
    "href": "slides/lec-3_desc-viz.html#ggplot2-syntax-1",
    "title": "Week 03: Describe & Vizualize",
    "section": "ggplot2 syntax",
    "text": "ggplot2 syntax\nLet‚Äôs start with a basic figure with our TIPI data\nFirst we will define the data that we are using and the variables we are visualizing\n\n#the dataset is called penguins\n\ntipi %&gt;% \n  #including the variables we want to visualize\n  ggplot(aes(x = emo, \n             y = extra))\n\nWhat happens?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#adding-in-color",
    "href": "slides/lec-3_desc-viz.html#adding-in-color",
    "title": "Week 03: Describe & Vizualize",
    "section": "Adding in Color",
    "text": "Adding in Color\nMaybe we would like to have each of the points colored by their respective sex\nThis information will be added to the aes() within the geom_point() layer\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex))"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#including-a-fit-line",
    "href": "slides/lec-3_desc-viz.html#including-a-fit-line",
    "title": "Week 03: Describe & Vizualize",
    "section": "Including a fit line",
    "text": "Including a fit line\nWhy don‚Äôt we put in a line that represents the relationship between these variables?\nWe will want to add another layer/geom\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth()\n\n\nThat looks a little wonky‚Ä¶why is that? Did you get a note in the console?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#including-a-fit-line-1",
    "href": "slides/lec-3_desc-viz.html#including-a-fit-line-1",
    "title": "Week 03: Describe & Vizualize",
    "section": "Including a fit line",
    "text": "Including a fit line\nThe geom_smooth() defaults to using a loess line to fit to the data\nIn order to update that, we need to change some of the defaults for that layer and specify that we want a ‚Äúlinear model‚Äù or lm function to the data\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm')\n\n\nDid that look a little better?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#individual-fit-lines",
    "href": "slides/lec-3_desc-viz.html#individual-fit-lines",
    "title": "Week 03: Describe & Vizualize",
    "section": "Individual fit lines",
    "text": "Individual fit lines\nIt might make more sense to have individual lines for each of the species instead of something that is across all\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra, \n             color = sex)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm')\n\n\nWhat did we move around from the last set of code?\nWhat was the error you got?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#data-types",
    "href": "slides/lec-3_desc-viz.html#data-types",
    "title": "Week 03: Describe & Vizualize",
    "section": "Data Types",
    "text": "Data Types\nIt looks like R is looking at our binary variable as a continuous number\nWe want to be able to tell our code that these are categories/factors\nIf we want to change or compute a new variable, what do we use?\n\n\ntipi &lt;- tipi %&gt;% \n  mutate(sex = as.factor(sex))"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#updating-labelstitle",
    "href": "slides/lec-3_desc-viz.html#updating-labelstitle",
    "title": "Week 03: Describe & Vizualize",
    "section": "Updating Labels/Title",
    "text": "Updating Labels/Title\nIt will default to including the variable names as the x and y labels, but that isn‚Äôt something that makes sense. Also would be good to have a title!\nWe add on another layer called labs() for our labels (link)\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra, \n             color = sex)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm') + \n  labs(\n    title = \"TIPI Data\",\n    subtitle = \"Extraversion by Emotional Stability\", \n    x = \"motional Stability\", \n    y = \"Extraversion\", \n    color = \"Sex at Birth\"\n  )"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#other-graphs",
    "href": "slides/lec-3_desc-viz.html#other-graphs",
    "title": "Week 03: Describe & Vizualize",
    "section": "Other Graphs",
    "text": "Other Graphs\nTake another look at the ggplot cheatsheet\nWhat else is a useful chart?"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#naming-conventions",
    "href": "slides/lec-3_wrangle.html#naming-conventions",
    "title": "Week 03: Wrangling",
    "section": "Naming Conventions",
    "text": "Naming Conventions\nRemember in the lab when things were named all funky? We used the rename() function to do that last time. This can be helpful if you want to change it to something specific, but we may just want to make these names a little cleaner.\nIntroducing janitor https://sfirke.github.io/janitor/index.html\n\n#same code as before\ntipi &lt;- import(here(\"files\", \"data\", \"TIPI_Data.csv\")) %&gt;% \n  # from the janitor package\n  janitor::clean_names()\nnames(tipi)\n\n [1] \"id\"                  \"progress\"            \"duration_in_seconds\"\n [4] \"consent\"             \"genderid\"            \"genderid_7_text\"    \n [7] \"sex\"                 \"age\"                 \"year_school\"        \n[10] \"q85\"                 \"q85_6_text\"          \"tipi_1\"             \n[13] \"tipi_2\"              \"tipi_3\"              \"tipi_4\"             \n[16] \"tipi_5\"              \"tipi_6\"              \"tipi_7\"             \n[19] \"tipi_8\"              \"tipi_9\"              \"tipi_10\"            \n[22] \"sleep_quality\"       \"hours_of_sleep\""
  },
  {
    "objectID": "slides/lec-3_wrangle.html#using-select",
    "href": "slides/lec-3_wrangle.html#using-select",
    "title": "Week 03: Wrangling",
    "section": "Using select()",
    "text": "Using select()\nYou used this in lab, so you are all experts. Let‚Äôs review by looking at the cheatsheet for dplyr.\nThe dplyr package makes data wrangling and transformation much easier. select() allows you to‚Ä¶well‚Ä¶select the columns that you want to keep.\n\nCreate a dataset that only includes: id, progress, duration, TIPI items"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#using-select-1",
    "href": "slides/lec-3_wrangle.html#using-select-1",
    "title": "Week 03: Wrangling",
    "section": "Using select()",
    "text": "Using select()\n\ntipi &lt;- tipi %&gt;% \n  select(c(id, progress, duration_in_seconds, tipi_1, \n           tipi_2, tipi_3, tipi_4, tipi_5, tipi_6, tipi_7, \n           tipi_8, tipi_9, tipi_10))\n\ntipi &lt;- tipi %&gt;% \n  select(c(id:duration_in_seconds, contains(\"tipi_\")))\n\n## OR\n\ntipi &lt;- tipi %&gt;% \n  select(-c(consent:q85_6_text, sleep_quality, hours_of_sleep))"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#extract-rows",
    "href": "slides/lec-3_wrangle.html#extract-rows",
    "title": "Week 03: Wrangling",
    "section": "Extract Rows",
    "text": "Extract Rows\nThe ‚Äòfilter()‚Äô function is used to subset observations based on their values.\nThe result of filtering is a data frame with the same number of columns as before but fewer rows.\nThe first argument is data and subsequent arguments are logical expressions that tell you which observations to retain in the data frame.\nNote: You are stating which types of rows you want to keep. If a variable can answer TRUE to your condition, then it will stay in the data.\n\nfilter(starwars, hair_color == \"none\")\n\n# A tibble: 38 √ó 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Darth V‚Ä¶    202   136 none       white      yellow          41.9 male  mascu‚Ä¶\n 2 IG-88       200   140 none       metal      red             15   none  mascu‚Ä¶\n 3 Bossk       190   113 none       green      red             53   male  mascu‚Ä¶\n 4 Lobot       175    79 none       light      blue            37   male  mascu‚Ä¶\n 5 Ackbar      180    83 none       brown mot‚Ä¶ orange          41   male  mascu‚Ä¶\n 6 Nien Nu‚Ä¶    160    68 none       grey       black           NA   male  mascu‚Ä¶\n 7 Nute Gu‚Ä¶    191    90 none       mottled g‚Ä¶ red             NA   male  mascu‚Ä¶\n 8 Jar Jar‚Ä¶    196    66 none       orange     orange          52   male  mascu‚Ä¶\n 9 Roos Ta‚Ä¶    224    82 none       grey       orange          NA   male  mascu‚Ä¶\n10 Rugor N‚Ä¶    206    NA none       green      orange          NA   male  mascu‚Ä¶\n# ‚Ñπ 28 more rows\n# ‚Ñπ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#filter-observations",
    "href": "slides/lec-3_wrangle.html#filter-observations",
    "title": "Week 03: Wrangling",
    "section": "Filter Observations",
    "text": "Filter Observations\nWe can now generate a subset of observations based on a particular value\nThere may be some data checks that you perform when wrangling data. One that I would suggest is to look at the overall completion percentages and the amount of time that it took for participants to complete the questionnaire.\nThis is exactly what filter() is set to do.\n\n# Assigning it to a new variable\nclean_tipi_data &lt;- tipi %&gt;% \n  filter(progress == 100 & \n         duration_in_seconds &gt; 600)"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#compute-new-variable",
    "href": "slides/lec-3_wrangle.html#compute-new-variable",
    "title": "Week 03: Wrangling",
    "section": "Compute new variable",
    "text": "Compute new variable\nWe often need to make a sum/mean score for a variable of interest, or transform it in some way.\nThe mutate() function is most commonly used to add new columns to your data frame that are functions of existing columns.\nmutate() requires data as its first argument, followed by a set of expressions defining new columns.\n\nNote: New variables are automatically added at the end of the data frame (scroll to the right to see them)\n\nFor example, in the lab, we had the Ten Item Personality Inventory\nTake a look at the scoring of the TIPI and compute the necessary variables for all subscales"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#sum-scores",
    "href": "slides/lec-3_wrangle.html#sum-scores",
    "title": "Week 03: Wrangling",
    "section": "Sum Scores",
    "text": "Sum Scores\nAnd finally, we can use mutate() to create total scores (or really any type of computation)\nFor the TIPI data, we need to compute each of the 5 pieces of the Big Five (Extraversion, Agreeableness, Conscientiousness, Emotional Stability and Openness to Experience)\n\nfinal_tipi &lt;- wizard_tipi_data %&gt;% \n  mutate(\n    extra = (tipi_1 + tipi_6r)/2,\n    agree = (tipi_2r + tipi_7)/2,\n    consc = (tipi_3 + tipi_8r)/2,\n    emo = (tipi_4r + tipi_9)/2,\n    open = (tipi_5 + tipi_10r)/2\n  )"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#export",
    "href": "slides/lec-3_wrangle.html#export",
    "title": "Week 03: Wrangling",
    "section": "export()",
    "text": "export()\nNow that we have a scored dataset, we will want to save that.\nYou can do this by re-running all of your steps above, or by exporting your dataset.\nexport(final_tipi, here(\"files\", \"data\", \"final_tipi.csv\"))\n\n\n\n\n\n\nNote\n\n\nBe careful when exporting and knitting docs. Each time you knit, it will run the export code. After I export, I usually will comment out that line of code."
  },
  {
    "objectID": "resources/startingwithR.html",
    "href": "resources/startingwithR.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "To get started with using the statistical software, we first must install it! Here is a guide that was put together to help with the installation process. Throughout this guide, you will install R followed by R-Studio (a program to make R more user friendly).¬†\nWe will go over this during the first day of class, so this guide is just to use as reference.¬†\nThings needed:\n\nComputer\nInternet Connection\nA coffee or preferred beverage usually helps!\n\n\n\nInformation taken from ‚ÄúHands-On Programming with R‚Äù\nR is maintained by an international team of developers who make the language available through the web page ofThe Comprehensive R Archive Network. The top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows or Mac.\n\n\nTo install R on Windows, click the ‚ÄúDownload R for Windows‚Äù link.Then click the ‚Äúbase‚Äù link. Next, click the first link at the top of the new page. This link should say something like ‚ÄúDownload R 4.3.1 for Windows,‚Äù except the 4.3.1 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you‚Äôll need to have all of the appropriate administration privileges to install new software on your machine.\n\n\n\nTo install R on a Mac, click the ‚ÄúDownload R for Mac‚Äô‚Äô link. Next, click on the ‚ÄúR-4.3.1-arm64.pkg‚Äù package link (or the package link for the most current release of R that is appropriate for your computer). An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I‚Äôve never found a reason to change them. If your computer requires a password before installing new programs, you‚Äôll need it here.\n\n\n\n\nR isn‚Äôt a program that you can open and start using, like Microsoft Word or Internet Explorer. Instead, R is a computer language, like C, C++, or UNIX. You use R by writing commands in the R language and asking your computer to interpret them. In the old days, people ran R code in a UNIX terminal window‚Äîas if they were hackers in a movie from the 1980s. Now almost everyone uses R with an application called RStudio, and I recommend that you do, too.\nGo ahead and try to open R without using R-Studio. You will get something like this:"
  },
  {
    "objectID": "resources/startingwithR.html#installing-r-r-studio",
    "href": "resources/startingwithR.html#installing-r-r-studio",
    "title": "Getting Started with R",
    "section": "",
    "text": "To get started with using the statistical software, we first must install it! Here is a guide that was put together to help with the installation process. Throughout this guide, you will install R followed by R-Studio (a program to make R more user friendly).¬†\nWe will go over this during the first day of class, so this guide is just to use as reference.¬†\nThings needed:\n\nComputer\nInternet Connection\nA coffee or preferred beverage usually helps!\n\n\n\nInformation taken from ‚ÄúHands-On Programming with R‚Äù\nR is maintained by an international team of developers who make the language available through the web page ofThe Comprehensive R Archive Network. The top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows or Mac.\n\n\nTo install R on Windows, click the ‚ÄúDownload R for Windows‚Äù link.Then click the ‚Äúbase‚Äù link. Next, click the first link at the top of the new page. This link should say something like ‚ÄúDownload R 4.3.1 for Windows,‚Äù except the 4.3.1 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you‚Äôll need to have all of the appropriate administration privileges to install new software on your machine.\n\n\n\nTo install R on a Mac, click the ‚ÄúDownload R for Mac‚Äô‚Äô link. Next, click on the ‚ÄúR-4.3.1-arm64.pkg‚Äù package link (or the package link for the most current release of R that is appropriate for your computer). An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I‚Äôve never found a reason to change them. If your computer requires a password before installing new programs, you‚Äôll need it here.\n\n\n\n\nR isn‚Äôt a program that you can open and start using, like Microsoft Word or Internet Explorer. Instead, R is a computer language, like C, C++, or UNIX. You use R by writing commands in the R language and asking your computer to interpret them. In the old days, people ran R code in a UNIX terminal window‚Äîas if they were hackers in a movie from the 1980s. Now almost everyone uses R with an application called RStudio, and I recommend that you do, too.\nGo ahead and try to open R without using R-Studio. You will get something like this:"
  },
  {
    "objectID": "resources/startingwithR.html#r-studio-download-and-install",
    "href": "resources/startingwithR.html#r-studio-download-and-install",
    "title": "Getting Started with R",
    "section": "R-Studio: Download and Install",
    "text": "R-Studio: Download and Install\nRStudio is an application like Microsoft Word‚Äîexcept that instead of helping you write in English, RStudio helps you write in R. We will use RStudio throughout because it makes working with R SO much easier. Plus there are a lot of additional functionalities that RStudio has that will expand what you can do (e.g., RMarkdown). Also, the RStudio interface looks the same for the various operating systems which will make teaching and your experience with the material a lot easier.\nRStudio (the company) has recently changed their name to Posit. To download RStudio, you can navigate to the Posit download page for ‚ÄúRStudio Desktop‚Äù. We have already completed Step 1 (you could have just come here to download it, but it is helpful to know where to get the latest versions and materials)! All you have to do is select the box under ‚Äú2: Install RStudio‚Äù to download. It should recognize the operating system that you are using, but if it does not, you will just need to scroll down the page to identify the appropriate installer.\nNow you are all set and ready to go! Nice job following the instructions and getting R and RStudio on your computer. Next you can begin to customize and get used to using RStudio. Remember, this is not something that is scary or a thing you can ‚Äúbreak‚Äù. When in doubt, check out Google or reach out to the professor!"
  },
  {
    "objectID": "resources/startingwithR.html#setting-things-up",
    "href": "resources/startingwithR.html#setting-things-up",
    "title": "Getting Started with R",
    "section": "Setting things up",
    "text": "Setting things up\nHere are some things that I am going to suggest to make your experience with R as good as we possibly can. Some of the suggestions here are related to your workflow while others are direct settings within R‚Ä¶and some are both. We are all complex creatures.¬†\nA lot of my suggestions will come from ‚ÄúWhat They Forgot to Teach You About R‚Äù. As I use other sites or things, I will do my best to have links to the original.\nThis list will continue to develop and expand. It is a work in progress (just like most of us)\n\nStart R with a blank slate each time Link\nNavigate to Tools &gt; Global Options\nBy default, R Studio saves all of the objects in your environment. In general, this is not ideal, because it means that you may have taken steps interactively that are not documented in your code.\n\nThis would be like when you are baking, and you follow the recipe, but then you add in some cinnamon and nutmeg which the recipe doesn‚Äôt call for. You also measure out some extra chocolate chips and brown sugar, but you end up not using that. The cookies come out fantastic and you want to make them again. You open up your kitchen and the cinnamon, nutmeg, chocolate chips and brown sugar are all there, but nothing says that you need them in your recipe. We don‚Äôt want to keep all the old information. We only want what is in the recipe (after we update it to include the extra spices).\n\n\nDecorate\nNavigate to Tools &gt; Global Options &gt; Appearance\nThis is all yours! Take ownership and find a cool theme that you like. Make it look nice and how you want it.\n\nRight now I am rocking the ‚ÄúChaos‚Äù theme with my fonts a little larger because apparently I am getting older."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 640: Graduate Statistics",
    "section": "",
    "text": "This page contains an outline of the topics, content, and preparation for the semester. This schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\nImportant\n\n\n\nReadings on the schedule will need to be completed prior to the course they are listed for. We will build on the concepts you read about in that specific class period, so it is important that you have read.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nPrepare\nSlides\nLabs\n\n\n\n\n1\n08-25\nGetting set up + R foundations\nInstall R/RStudio; Bring a laptop\nüíª Getting Started - Syllabus\nüíªGetting Started - Data\nLab 1 - Intro to Data Workflow\n\n\n2\n09-01\nLABOR DAY\nChapter 1 & 2 - ST\nChapter 2 - MSR\nLABOR DAY\nLab 2 - Data Wrangling\n\n\n3\n09-08\nDescriptives, Visualizations + Communication\nChapter 5 - LSR\nChapter 1 & 3 - R4DS\nüíª Data Wrangling\nüíª Describe & Visualize\nLab 3\n\n\n4\n09-15\nDesign, Sampling + Inference\nChapter 2 - IMS\nChapter 3 - MSR\nChapter 7 - ST\nüíª Design & Inference\nLab 4 - Intro to Inference\nStatistical Check\n\n\n5\n09-22\nCorrelation + Effect Sizes\nChapter 5.1 & 13 - ST\nChapter 11 - LSR\nüíª Correlation & ES\nLab 5 - Correlation & ES\n\n\n6\n09-29\nComparing Groups\nChapter 9 & 10 - ST\nChapter 13 - LSR\nüíªComparing Means\nLab 6 - Compare Means\n\n\n7\n10-06\nSimple Linear Regression\nChapter 14.1.1 - 14.1.4 - ST\nChapter 7.1 - 7.2.4 - IMS\nChapter 8.1.1 & 8.1.2 - MSR\n\n\n\n\n8\n10-13\nFALL BREAK\nWork on your midterm project\n\n\n\n\n9\n10-20\nVariability & Model Fit\nChapter 5 & 14- ST\nChapter 7.2.5 - IMS\n\n\n\n\n10\n10-27\nMultiple Regression I: Adding Predictors\nChapter 15.3 - 15.5 - LSR\nChapter 8 - IMS\n\n\n\n\n11\n11-03\nMultiple Regression II: Categorical Predictors\nChapter 9 - IMS\nChapter 8.3 - MSR\n\n\n\n\n12\n11-10\nAssumptions + Model Diagnostics\nChapter 7.3 - IMS\nChapter 14.5 - ST\nChapter 8.1.4 - MSR\nChapter 15.8 - LSR\n\n\n\n\n13\n11-17\nExpanding Regression\nChapter 14.2 & 14.3 - ST\n\n\n\n\n14\n11-24\nModel Building + Comparison\nChapter 15.8 - 15.10 - LSR\n\n\n\n\n15\n12-01\nMaking R Work for You\nChapter 17 & 18 - ST\n\n\n\n\n16\n12-08\nWrapping Up + Workshop\n\n\n\n\n\n\n\nIntroduction to Modern Statistics (2e) ‚Äì&gt; IMS\nLearning Statistics with R ‚Äì&gt; LSR\nR for Data Science (2e) ‚Äì&gt; R4DS\nModern Statistics with R (2e) ‚Äì&gt; MSR\nStatistical Thinking ‚Äì&gt; ST\nAn Introduction to Statistical Learning (2e) ‚Äì&gt; ISL\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) ‚Äì&gt; DA",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#slides",
    "href": "weeks/week-8.html#slides",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data",
    "crumbs": [
      "Weekly Materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#in-class-activity",
    "href": "weeks/week-8.html#in-class-activity",
    "title": "Week XX",
    "section": "",
    "text": "Getting Comfy with R",
    "crumbs": [
      "Weekly Materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#for-next-time",
    "href": "weeks/week-8.html#for-next-time",
    "title": "Week XX",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "You survived the first week! I hope your classes are off to a good start. Although we don‚Äôt have class this week (Labor Day), we will still have readings and an assignment. Please view this page to make sure you have all the information you need to get going.\nWe are going to work on expanding our comfort with the syntax in R and using the tidyverse for some more data wrangling. We will import some new data, and compute some new values. This will be a skill that will be useful no matter what data you are working with. There will be plenty of practice with this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄúIllustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst‚Äù\n\n\n\nBe sure to have read the chapters!\nDownload the data for this week\n\nDownload From Drive (CSV)\n\n\n\nNone (Labor Day)\n\n\n\nNo Class this week (Labor Day)\n\n\n\nüìãLab 2 - Getting Comfy with Data Wrangling\nüìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "",
    "text": "Be sure to have read the chapters!\nDownload the data for this week\n\nDownload From Drive (CSV)",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#slides",
    "href": "weeks/week-2.html#slides",
    "title": "Week 2",
    "section": "",
    "text": "None (Labor Day)",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#in-class-activity",
    "href": "weeks/week-2.html#in-class-activity",
    "title": "Week 2",
    "section": "",
    "text": "No Class this week (Labor Day)",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#for-next-time",
    "href": "weeks/week-2.html#for-next-time",
    "title": "Week 2",
    "section": "",
    "text": "üìãLab 2 - Getting Comfy with Data Wrangling\nüìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-11.html#slides",
    "href": "weeks/week-11.html#slides",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data"
  },
  {
    "objectID": "weeks/week-11.html#in-class-activity",
    "href": "weeks/week-11.html#in-class-activity",
    "title": "Week XX",
    "section": "",
    "text": "Getting Comfy with R"
  },
  {
    "objectID": "weeks/week-11.html#for-next-time",
    "href": "weeks/week-11.html#for-next-time",
    "title": "Week XX",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "üíª Design & Inference\n\n\n\nBeginnings of Inference\n\n\n\nüìãLab 4 - Intro to Inference\nComplete Stats Check (see myCourses)\nüìñChapter 5.1 & 13 - ST\nüìñChapter 11 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-4.html#slides",
    "href": "weeks/week-4.html#slides",
    "title": "Week 4",
    "section": "",
    "text": "üíª Design & Inference",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-4.html#in-class-activity",
    "href": "weeks/week-4.html#in-class-activity",
    "title": "Week 4",
    "section": "",
    "text": "Beginnings of Inference",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-4.html#for-next-time",
    "href": "weeks/week-4.html#for-next-time",
    "title": "Week 4",
    "section": "",
    "text": "üìãLab 4 - Intro to Inference\nComplete Stats Check (see myCourses)\nüìñChapter 5.1 & 13 - ST\nüìñChapter 11 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-9.html",
    "href": "weeks/week-9.html",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-9.html#slides",
    "href": "weeks/week-9.html#slides",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data"
  },
  {
    "objectID": "weeks/week-9.html#in-class-activity",
    "href": "weeks/week-9.html#in-class-activity",
    "title": "Week XX",
    "section": "",
    "text": "Getting Comfy with R"
  },
  {
    "objectID": "weeks/week-9.html#for-next-time",
    "href": "weeks/week-9.html#for-next-time",
    "title": "Week XX",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "labs/lab-3_describe-viz.html",
    "href": "labs/lab-3_describe-viz.html",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "",
    "text": "Can‚Äôt believe we‚Äôre at Lab #3! Keep it going! We are going to continue to practice importing data and making a reproducible workflow. In this lab, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#instructions",
    "href": "labs/lab-3_describe-viz.html#instructions",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "",
    "text": "Can‚Äôt believe we‚Äôre at Lab #3! Keep it going! We are going to continue to practice importing data and making a reproducible workflow. In this lab, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#scenario-and-goal",
    "href": "labs/lab-3_describe-viz.html#scenario-and-goal",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nIn this lab, you will act as a data journalist exploring a dataset on movies. We will use the data from the FiveThirtyEight story ‚ÄúThe Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion of Women.‚Äù\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction.\nYour goal is to import, describe, and visualize this data to understand the characteristics of movies in the dataset and see if there are relationships between a movie‚Äôs budget, its box office gross, and its Bechdel Test rating. This is the critical first step in any analysis, known as Exploratory Data Analysis (EDA).",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#variables-of-interest",
    "href": "labs/lab-3_describe-viz.html#variables-of-interest",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Variables of Interest",
    "text": "Variables of Interest\n\nyear: The year of movie release\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don‚Äôt talk to each other\nnowomen = fewer than two women\n\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\nbudget_2013: Total movie budget",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#exercises",
    "href": "labs/lab-3_describe-viz.html#exercises",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1: Importing and Inspecting\nFirst, you need to set up your RMarkdown to get it ready for importing the data and using the appropriate libraries. Be sure to have all libraries listed here in the first code chunk along with importing the data. I should not see any lines that say install.packages().\nI will attempt to reproduce your output in my own computer, so be sure that your code is reproducible.\nQuestion 1: Look at the output from your overview. How many total movies are in this database? And what year is the latest movie?\nYour Answer:\nQuestion 2: Calculate the Average budget of the whole dataset. Then, calculate the average for only movies in the year 2000.\nYour Answer:\n\n\n\nExercise 2: Grouped Descriptive Statistics\nAverages for the whole dataset are useful, but we are often more interested in comparing averages between groups. Let‚Äôs see if the average budget differs for movies that pass the Bechdel Test versus those that fail. The binary variable tells us this (‚ÄúPASS‚Äù or ‚ÄúFAIL‚Äù).\nQuestion 3: Based on your summary table, do movies that pass or fail the Bechdel test have a higher average (mean) budget?\nYour Answer:\n\n\n\nExercise 3: Visualizing a Distribution (Histogram)\nLet‚Äôs visualize the distribution of domestic gross earnings (adjusted for 2013) across all the movies.\nQuestion 4: Describe the shape of the distribution you see in the histogram. Is it symmetric (like a bell curve), or is it skewed in one direction? Where do most movies‚Äô earnings seem to be clustered?\nYour Answer:\n\n\n\nExercise 4: Examining the Bechdel Test distribution\nNow we want to see how many movies fall into each of the Bechdel categories. Generate a barplot of the clean_test variable to see what the distribution of the test is.\nThen choose a year in the dataset, create a similar plot (but only for that year). Therefore you should have 2 plots below:\nQuestion 5: Examine both charts and describe the similarities and differences that you are noticing.\nAnswer:\n\n\n\nExercise 5: Comparing Groups with a Boxplot\nNow let‚Äôs visually compare the inflation-adjusted international gross (intgross_2013) for movies that pass the Bechdel test versus those that fail. A boxplot is an excellent way to see differences in the median and spread between groups.\nQuestion 6: Look at the boxplot. The thick horizontal line in the middle of each box represents the median. Does there appear to be a large difference in the median domestic gross between movies that pass and fail the test?\nYour Answer:\n\nEnd of Lab 3. You‚Äôve now practiced exploratory data analysis! It is always important to visualize your data to get a good sense of what you are working with. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html",
    "href": "labs/lab-2_data-wrangling.html",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "",
    "text": "We have made it to Lab #2! We are going to keep practicing the skills we started using in the last week, except with using some new data. Before, we were using pre-installed data, but that won‚Äôt be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 2: Data Wrangling Beginnings\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nHere is a .Rmd file that you should be able to download and use as well.\n\nDownload Lab 2 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 2 - Wrangling Intro"
    ]
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html#instructions",
    "href": "labs/lab-2_data-wrangling.html#instructions",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "",
    "text": "We have made it to Lab #2! We are going to keep practicing the skills we started using in the last week, except with using some new data. Before, we were using pre-installed data, but that won‚Äôt be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 2: Data Wrangling Beginnings\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nHere is a .Rmd file that you should be able to download and use as well.\n\nDownload Lab 2 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 2 - Wrangling Intro"
    ]
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html#scenario-and-goal",
    "href": "labs/lab-2_data-wrangling.html#scenario-and-goal",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nCongratulations, you‚Äôve just collected data for a study on ‚ÄúPersonality‚Äù! You administered a 10-item personality questionnaire, where participants responded on a 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree). This measure is called the ‚ÄúTen Item Personality Inventory‚Äù (TIPI) and more information about the measure can be found here: TIPI Scale Info. Please refer to this page and documents to help with scoring the data and getting familiar with the measure.\nHowever, the raw data from the survey software is messy. Your goal in this lab is to import, clean, and score the data to prepare it for analysis. This process of turning raw data into usable data is called data wrangling, and it‚Äôs what researchers spend most of their time doing.\nYou will learn to: * Import a CSV file. * Rename variables for clarity. * Filter out participants based on data quality checks. * Reverse-score negatively worded items. * Compute a composite score for a psychological scale.\n\n\nGetting Data\nBe aware of your file structure and how things are organized. For some refreshers, take a look at the Resources and rstats.wtf\n\nDownload your data\nDownload Data from Drive (CSV)\nDownload Questionnaire From Drive (DOC)\n\n\n\nExercise 1: Importing and Inspecting the Data\nFirst, you need to load the appropriate packages and import your data. Use the tidyverse, rio, and here libraries.\n# Load the appropriate libraries.   \n\n# Write your import code here:   \n  ## This will look like:     \n  # your_data_name &lt;- import(here(\"path\", \"to\", \"file\", \"filename.csv))    \n\n\n# Use glimpse() to get a first look at the raw_data. \n# Write your code here:  \nQuestion 1: How many participants (rows) are in the raw, imported dataset?\n‚ùìYour Answer: [Type your answer here]\n\n\n\nExercise 2: Renaming Variables for Clarity\nThe column names are a mixture of naming conventions. Let‚Äôs rename them to be consistent and convey the appropriate information.\nFirst, let‚Äôs take a look at what the names are. You can do this by using View(), but let‚Äôs use the names() function to list out all the column names.\nnames(Whatever_you_Named_your_data)\nThis will give you your list of names. You can see which ones we may want to rename. What does Q85 even mean? Thanks Qualtrics. Review the documentation for the survey to get a sense of what the questions are asking to properly rename the variables.\nFor now, let‚Äôs update the names as follows. It is helpful to keep everything lowercase to make it easier to type (but this is a personal preference), and make sure there aren‚Äôt any spaces in your variable names:\n\nID -&gt; id\nProgress -&gt; progress\nDuration (in seconds) -&gt; duration\nConsent -&gt; consent\nQ85 -&gt; sex_orient\nQ85_6_TEXT -&gt; sex_orient_txt\nSleep Quality -&gt; sleep_qual\nHours of Sleep -&gt; sleep_hours\n\n# Task: Use the rename() function to change the variable names as listed above.\n# Create a new object called `renamed_data`.\n# Hint: The syntax is: new_object &lt;- old_object %&gt;% rename(new_name_1 = old_name_1, new_name_2 = old_name_2)\n\n# Write your code here:\n# This part is a placeholder as the actual column names from the URL will differ.\n# Be sure to update the following template with the info from your own data\nrenamed_data &lt;- raw_data %&gt;%\n  rename(participant_id = country, \n         grit_1 = year,\n         grit_2 = population)\n         # ... and so on for the other variables\n\n# Print the first few rows of your new `renamed_data` object to check your work.\nhead(renamed_data)\n\n\n\nExercise 3: Filtering for Data Quality\nOur survey includes variables that allow us to see how long they took and what percentage they completed. We should remove participants who did not finish the survey, as well as those who finished it too quickly.\nThis will be done using the filter() function (more about filter). Use filter to keep participants where their progress is equal to 100. You will also want to remove participants who completed the survey in less than 7 minutes (note: the Duration variable is in seconds).\n# Create a new object called `filtered_data`.\n\n# Example code:\n# filtered_data &lt;- renamed_data %&gt;%\n#   filter(Progress == 100) %&gt;% \n#   filter(Duration ==, &lt;, &gt; 1000)\nQuestion 2: How many participants remain from your original dataset? How many participants did you remove with your filters?\n‚ùìYour Answer: [Type your answer here]\n\n\n\nExercise 4: Reverse-Scoring Items\nIn a lot of psychological research, we need to reverse score variables. They are often worded in a negative/positive way compared to the rest of the items. Review the TIPI documentation to see what items need to be reverse scored.\nFor example, Item 2 is a item that should reflect ‚ÄúAgreeableness‚Äù, but the rated words are ‚ÄúCritical, quarrelsome‚Äù. Therefore low score on this item would reflect high amounts of Agreeableness.\nThe formula for reverse scoring an item is: (Maximum Possible Value + 1) - Original Score. So, for the TIPI, it‚Äôs 8 - TIPI_2.\nTo create/compute a new variable we use the mutate() function (more about mutate). I like to remember this function name because we are ‚Äúmutating‚Äù the data and introducing another ‚Äúgrowth‚Äù or something extra that wasn‚Äôt there before.\n# Task: Use the mutate() function to create new, reverse-scored variables.\n# Use a new name to indicate which items are reverse-scored.\n# Create a new object called `scored_data`.\n# Hint: The syntax is: \n  # new_object &lt;- old_object %&gt;% \n  #   mutate(new_variable = computation, \n  #          new_variable2 = computation)\n\n\n# Exmple code:\n# scored_data &lt;- filtered_data %&gt;%\n#   mutate(TIPI_2r = 8 - TIPI_2)\n\n\n\n# Print the first few rows, showing only the original and new reverse-scored item to check your work.\n\n# scored_data %&gt;% select(TIPI_2, TIPI_2r) %&gt;% head()\nQuestion 3: If a participant‚Äôs original score on TIPI_4 was a 6, what would their score be on the new TIPI_4r variable?\n‚ùìYour Answer: [Type your answer here]\n\n\n\nExercise 5: Computing and Finalizing the Scored File\nNow we are ready to compute the final score! There are individual subscales for each of the 5 factors of the Big 5 Personality Inex. Compute the 5 scales. Remember to use the reverse-scored items (TIPI_2r), not the original one.s\n# Task 1: Use mutate() to calculate the total grit score.\n# Sum the items corresponding to each scale.\n# Call the new variables 'extra', 'agree', 'consc', 'emo', 'open.\n# Overwrite your `scored_data` object with this new version.\n\n# Task 2: Create a final, clean dataset.\n# Use select() to keep only the 'id' and Big 5 scale columns.\n# Call this object `final_data`.\n# Conceptual code:\n# final_data &lt;- scored_data %&gt;%\n#   select(id, agree, ...)\n\n\n\n# Task 3: Calculate the mean and standard deviation of each of the subscale scores.\nQuestion 4: What would be the highest possible Emotional Stability score a participant could get? What would be the lowest?\n‚ùìYour Answer: [Type your answer here]\nQuestion 5: Report the mean‚Äôs and standard deviations of each of the subscale scores\n‚ùìYour Answer:\n\nExtraversion:\nAgreeableness:\nConscientiousness:\nEmotional Stability:\nOpenness to Experience:\n\n\n\n\nExercise 6: Visualize Relationships\nWe often want to see the relationship between 2 variables. This is often done using a scatterplot. Select 2 scales that you would like to see the relationship between. Use the code from the previous lab/class to create a scatterplot of the relationship. Take a look at this cheat sheet to help with ggplot2!\n# Using ggplot and the scored data you have, generate a scatterplot. It can be as simple or as fancy as you would like (try putting a title and changing the axis names)\n\n\n\n# Use the cheat sheet and other materials to put a straight line to the data (Hint: add another layer with a smooth geom)\nQuestion 6.1: Visually inspect the chart you have and describe the relationship below. Be sure to include the two variables and an estimate of your correlation in your answer.\n‚ùìYour Answer:\n# Compute a correltion for your variables\n# Hint: use the `cor.test()` function. You will need to specify the variable names as `name_of_data$name_of_variable`\n  \n  # Example\n    # cor.test(starwars$height, starwars$mass)\nQuestion 6.2: Calculate the correlation coefficient for your two variables of interest (refer here for more info). Report the correlation, and reflect on how close or how far away your initial estimate was. Do your best here. I recognize that we haven‚Äôt really gone over this just yet.\n‚ùìYour Answer:\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 2 - Wrangling Intro"
    ]
  },
  {
    "objectID": "labs/lab-7.html",
    "href": "labs/lab-7.html",
    "title": "Lab 4:",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#instructions",
    "href": "labs/lab-7.html#instructions",
    "title": "Lab 4:",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#scenario-and-goal",
    "href": "labs/lab-7.html#scenario-and-goal",
    "title": "Lab 4:",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#exercises",
    "href": "labs/lab-7.html#exercises",
    "title": "Lab 4:",
    "section": "Exercises",
    "text": "Exercises\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-1_data-workflow.html",
    "href": "labs/lab-1_data-workflow.html",
    "title": "Lab 1: Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 1: Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n‚ùìQuestion 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet‚Äôs say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n‚ùìQuestion: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let‚Äôs create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n‚ùìQuestion 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n‚ùìQuestion: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd of Lab 1. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 1 - Data Intro"
    ]
  },
  {
    "objectID": "labs/lab-1_data-workflow.html#instructions",
    "href": "labs/lab-1_data-workflow.html#instructions",
    "title": "Lab 1: Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 1: Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n‚ùìQuestion 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet‚Äôs say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n‚ùìQuestion: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let‚Äôs create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n‚ùìQuestion 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n‚ùìQuestion: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd of Lab 1. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 1 - Data Intro"
    ]
  },
  {
    "objectID": "labs/lab-8.html",
    "href": "labs/lab-8.html",
    "title": "Lab 4:",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-8.html#instructions",
    "href": "labs/lab-8.html#instructions",
    "title": "Lab 4:",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-8.html#scenario-and-goal",
    "href": "labs/lab-8.html#scenario-and-goal",
    "title": "Lab 4:",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-8.html#exercises",
    "href": "labs/lab-8.html#exercises",
    "title": "Lab 4:",
    "section": "Exercises",
    "text": "Exercises\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "ideas.html",
    "href": "ideas.html",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nBy Appointment\n\n\nClass Times\nAsynchronous\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course offers a broad introduction to the field of Psychology, covering various sub-disciplines and emphasizing the scientific study of behavior and cognition. Students will gain a solid understanding of the scientific process, major psychological theories, and the correct usage of psychological terminology. The curriculum fosters critical evaluation skills for examining psychological research findings and highlights practical applications of psychological concepts in daily life. Emphasizing contemporary insights, the course focuses on the scientific method in measuring human behavior, with a student-centric approach that encourages active engagement and self-knowledge.\n\n\n\n\nTextbook: We will an open source (this means free) textbook throughout the semester. The link to the textbook is included below. A PDF version of the text is uploaded to myCourses. ¬†\nSpielman, R. M., Jenkins, W., & Lovett, M. (2020). Psychology 2e. https://openstax.org/details/books/psychology-2e\nOther Required Readings: All additional readings (if necessary) will be posted to the course website.\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\n\n\n\nLecture focus\n\nThe research cycle and where statistics fits\nReproducible workflows (R, RStudio, RMarkdown/Quarto)\nIntro to tidyverse workflow\nStats anxiety & growth mindset\n\nLab\n\nInstall/load R packages\nLoad a dataset (built-in + open source)\nCreate a first plot with ggplot2\n\nReadings\n\nIs Statistics Hard? ‚Äî Wickham & Grolemund, R for Data Science (R4DS) Ch. 1‚Äì2\nAPA: Principles for Translating Statistics to Psychology Students (APA Guidelines)\n\nAssignment\n\nMini data exploration report (import, summarize, plot)\n\n\n\n\n\nLecture focus\n\nWhy regression first?\nVisualizing relationships (scatterplots, grouping)\nThinking in terms of variation & prediction\n\nLab\n\nggplot2 layering: geom_point, geom_smooth\nFaceting and grouping variables\n\nReadings\n\nR4DS Ch. 3, 5\nGelman & Hill (2007) Ch. 2 (Regression as a general method)\n\nAssignment\n\nRecreate 2 plots from lecture with a dataset of your choice\n\n\n\n\n\nLecture focus\n\nModel equation & interpretation of intercept, slope\nEffect size & confidence intervals\nResiduals & assumptions\n\nLab\n\nFit lm() models\nInterpret coefficients & plot regression lines\nDiagnostic plots\n\nReadings\n\nR4DS Ch. 23 (Model basics)\nField, A. (2018) Discovering Statistics Using R, Ch. 7 (sections on simple regression)\n\nAssignment\n\nReport a simple regression with APA-style results\n\n\n\n\n\nLecture focus\n\nAdding predictors: partial slopes\nStandardized coefficients\nCategorical predictors (dummy coding)\n\nLab\n\nlm() with multiple predictors\nModel interpretation with summary()\nCompare models using anova()\n\nReadings\n\nR4DS Ch. 24\nField Ch. 8 (multiple regression basics)\n\nAssignment\n\nMultiple regression report on a dataset you choose\n\n\n\n\n\nLecture focus\n\nInteraction terms\nCentering predictors\nModeration interpretation\n\nLab\n\nInteraction plots with ggplot2\nemmeans for marginal means\n\nReadings\n\nField Ch. 9 (interactions)\nHayes (2018) Ch. 1‚Äì2 (Intro to moderation)\n\nAssignment\n\nAnalyze a moderation model & interpret the interaction\n\n\n\n\n\nLecture focus\n\nWhen outcomes are binary\nOdds ratios & log odds\nModel fit statistics\n\nLab\n\nglm() with family = binomial\nInterpreting odds ratios\nROC curves\n\nReadings\n\nField Ch. 19 (logistic regression)\nPeng, Lee, & Ingersoll (2002) An Introduction to Logistic Regression Analysis\n\nAssignment\n\nLogistic regression report\n\n\n\n\n\nLecture focus\n\nANOVA = regression with categorical predictors\nDummy & effect coding\nPost-hoc tests & contrasts\n\nLab\n\nCompare lm() & aov() outputs\nemmeans for pairwise comparisons\n\nReadings\n\nField Ch. 10‚Äì11 (ANOVA & ANCOVA)\nR4DS Ch. 25 (Categorical variables)\n\nAssignment\n\nANOVA with APA report\n\n\n\n\n\nLecture focus\n\nAdjusting for covariates\nAssumptions & interpretation\n\nLab\n\nFit ANCOVA models\nVisualize adjusted means\n\nReadings\n\nField Ch. 12 (ANCOVA)\nGelman & Hill Ch. 9 (controlling for variables)\n\nAssignment\n\nANCOVA report\n\n\n\n\n\nLecture focus\n\nResidual plots\nNormality, homoscedasticity\nRobust regression options\n\nLab\n\ncheck_model() from performance package\nHandling outliers & transformations\n\nReadings\n\nField Ch. 4 (assumptions)\nWilcox (2012) Ch. 2 (robust methods intro)\n\nAssignment\n\nDiagnostic report on your own dataset\n\n\n\n\n\nLecture focus\n\nMCAR, MAR, MNAR\nMultiple imputation\nComplete case analysis & its dangers\n\nLab\n\nnaniar package for missingness visualization\nmice for imputation\n\nReadings\n\nEnders (2010) Ch. 1‚Äì2 (missing data theory)\nvan Buuren (2018) Ch. 3 (practical imputation)\n\nAssignment\n\nMissing data analysis & imputation\n\n\n\n\n\nLecture focus\n\nWhy random effects?\nRepeated measures within regression\nRandom intercepts & slopes\n\nLab\n\nlme4: lmer() basics\nInterpretation & visualization with sjPlot\n\nReadings\n\nGelman & Hill Ch. 11‚Äì12\nWinter (2013) Linear Mixed Effects Models in R\n\nAssignment\n\nMixed model analysis on a repeated measures dataset\n\n\n\n\n\nLecture focus\n\nDirect & indirect effects\nBootstrapping mediation\nConceptual link to SEM\n\nLab\n\nmediation package\nlavaan for path models\n\nReadings\n\nHayes (2018) Ch. 3‚Äì4 (mediation)\nR4DS Ch. 26 (model building)\n\nAssignment\n\nMediation analysis report\n\n\n\n\n\nLecture focus\n\nWhy power matters\nPower for regression & ANOVA\nPlanning sample sizes\n\nLab\n\npwr package\nSimulation-based power\n\nReadings\n\nCohen (1988) Ch. 1‚Äì2 (effect sizes & power)\nLakens (2021) Sample Size Justification\n\nAssignment\n\nPower analysis for your final project\n\n\n\n\n\nLecture focus\n\nTroubleshooting models\nRefining visualizations & write-up\n\nLab\n\nPeer review final project drafts\n\nReadings\n\nNo new readings ‚Äî review past materials\n\nAssignment\n\nSubmit draft project\n\n\n\n\n\nLecture focus\n\nCommunicating results to non-statistical audiences\nTranslating skills to the workplace\n\nLab\n\nStudent presentations\nClass reflection: ‚ÄúWhat I‚Äôll take forward‚Äù\n\nReadings\n\nNo new readings\n\nFinal Deliverable\n\nFully reproducible RMarkdown/Quarto report with:\n\nIntroduction & research question\nMethods\nRegression-based analysis\nAPA-style results\nVisualizations\nReferences\n\n\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. Due to the accelerated nature of the course, the late penalty will be more severe. There will be a 50% deduction on the first day. Work will not be accepted beyond 24 hours after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nEach course that you are involved in will have differing opinions and goals regarding generative AI (i.e., ChatGPT, Gemini, Perplexity, Claude, etc.). In this course you are allowed to use these as a tool. You can use prompts such as ‚ÄúTeach me about (insert psych topic here) and give me an example that might apply to me.‚Äù If you do use generative AI, I would like for you to disclose that information just so I can have a sense of how it is being used. If I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email."
  },
  {
    "objectID": "ideas.html#intro-to-psychology-online-asynchronous",
    "href": "ideas.html#intro-to-psychology-online-asynchronous",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nBy Appointment\n\n\nClass Times\nAsynchronous\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course offers a broad introduction to the field of Psychology, covering various sub-disciplines and emphasizing the scientific study of behavior and cognition. Students will gain a solid understanding of the scientific process, major psychological theories, and the correct usage of psychological terminology. The curriculum fosters critical evaluation skills for examining psychological research findings and highlights practical applications of psychological concepts in daily life. Emphasizing contemporary insights, the course focuses on the scientific method in measuring human behavior, with a student-centric approach that encourages active engagement and self-knowledge.\n\n\n\n\nTextbook: We will an open source (this means free) textbook throughout the semester. The link to the textbook is included below. A PDF version of the text is uploaded to myCourses. ¬†\nSpielman, R. M., Jenkins, W., & Lovett, M. (2020). Psychology 2e. https://openstax.org/details/books/psychology-2e\nOther Required Readings: All additional readings (if necessary) will be posted to the course website.\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\n\n\n\nLecture focus\n\nThe research cycle and where statistics fits\nReproducible workflows (R, RStudio, RMarkdown/Quarto)\nIntro to tidyverse workflow\nStats anxiety & growth mindset\n\nLab\n\nInstall/load R packages\nLoad a dataset (built-in + open source)\nCreate a first plot with ggplot2\n\nReadings\n\nIs Statistics Hard? ‚Äî Wickham & Grolemund, R for Data Science (R4DS) Ch. 1‚Äì2\nAPA: Principles for Translating Statistics to Psychology Students (APA Guidelines)\n\nAssignment\n\nMini data exploration report (import, summarize, plot)\n\n\n\n\n\nLecture focus\n\nWhy regression first?\nVisualizing relationships (scatterplots, grouping)\nThinking in terms of variation & prediction\n\nLab\n\nggplot2 layering: geom_point, geom_smooth\nFaceting and grouping variables\n\nReadings\n\nR4DS Ch. 3, 5\nGelman & Hill (2007) Ch. 2 (Regression as a general method)\n\nAssignment\n\nRecreate 2 plots from lecture with a dataset of your choice\n\n\n\n\n\nLecture focus\n\nModel equation & interpretation of intercept, slope\nEffect size & confidence intervals\nResiduals & assumptions\n\nLab\n\nFit lm() models\nInterpret coefficients & plot regression lines\nDiagnostic plots\n\nReadings\n\nR4DS Ch. 23 (Model basics)\nField, A. (2018) Discovering Statistics Using R, Ch. 7 (sections on simple regression)\n\nAssignment\n\nReport a simple regression with APA-style results\n\n\n\n\n\nLecture focus\n\nAdding predictors: partial slopes\nStandardized coefficients\nCategorical predictors (dummy coding)\n\nLab\n\nlm() with multiple predictors\nModel interpretation with summary()\nCompare models using anova()\n\nReadings\n\nR4DS Ch. 24\nField Ch. 8 (multiple regression basics)\n\nAssignment\n\nMultiple regression report on a dataset you choose\n\n\n\n\n\nLecture focus\n\nInteraction terms\nCentering predictors\nModeration interpretation\n\nLab\n\nInteraction plots with ggplot2\nemmeans for marginal means\n\nReadings\n\nField Ch. 9 (interactions)\nHayes (2018) Ch. 1‚Äì2 (Intro to moderation)\n\nAssignment\n\nAnalyze a moderation model & interpret the interaction\n\n\n\n\n\nLecture focus\n\nWhen outcomes are binary\nOdds ratios & log odds\nModel fit statistics\n\nLab\n\nglm() with family = binomial\nInterpreting odds ratios\nROC curves\n\nReadings\n\nField Ch. 19 (logistic regression)\nPeng, Lee, & Ingersoll (2002) An Introduction to Logistic Regression Analysis\n\nAssignment\n\nLogistic regression report\n\n\n\n\n\nLecture focus\n\nANOVA = regression with categorical predictors\nDummy & effect coding\nPost-hoc tests & contrasts\n\nLab\n\nCompare lm() & aov() outputs\nemmeans for pairwise comparisons\n\nReadings\n\nField Ch. 10‚Äì11 (ANOVA & ANCOVA)\nR4DS Ch. 25 (Categorical variables)\n\nAssignment\n\nANOVA with APA report\n\n\n\n\n\nLecture focus\n\nAdjusting for covariates\nAssumptions & interpretation\n\nLab\n\nFit ANCOVA models\nVisualize adjusted means\n\nReadings\n\nField Ch. 12 (ANCOVA)\nGelman & Hill Ch. 9 (controlling for variables)\n\nAssignment\n\nANCOVA report\n\n\n\n\n\nLecture focus\n\nResidual plots\nNormality, homoscedasticity\nRobust regression options\n\nLab\n\ncheck_model() from performance package\nHandling outliers & transformations\n\nReadings\n\nField Ch. 4 (assumptions)\nWilcox (2012) Ch. 2 (robust methods intro)\n\nAssignment\n\nDiagnostic report on your own dataset\n\n\n\n\n\nLecture focus\n\nMCAR, MAR, MNAR\nMultiple imputation\nComplete case analysis & its dangers\n\nLab\n\nnaniar package for missingness visualization\nmice for imputation\n\nReadings\n\nEnders (2010) Ch. 1‚Äì2 (missing data theory)\nvan Buuren (2018) Ch. 3 (practical imputation)\n\nAssignment\n\nMissing data analysis & imputation\n\n\n\n\n\nLecture focus\n\nWhy random effects?\nRepeated measures within regression\nRandom intercepts & slopes\n\nLab\n\nlme4: lmer() basics\nInterpretation & visualization with sjPlot\n\nReadings\n\nGelman & Hill Ch. 11‚Äì12\nWinter (2013) Linear Mixed Effects Models in R\n\nAssignment\n\nMixed model analysis on a repeated measures dataset\n\n\n\n\n\nLecture focus\n\nDirect & indirect effects\nBootstrapping mediation\nConceptual link to SEM\n\nLab\n\nmediation package\nlavaan for path models\n\nReadings\n\nHayes (2018) Ch. 3‚Äì4 (mediation)\nR4DS Ch. 26 (model building)\n\nAssignment\n\nMediation analysis report\n\n\n\n\n\nLecture focus\n\nWhy power matters\nPower for regression & ANOVA\nPlanning sample sizes\n\nLab\n\npwr package\nSimulation-based power\n\nReadings\n\nCohen (1988) Ch. 1‚Äì2 (effect sizes & power)\nLakens (2021) Sample Size Justification\n\nAssignment\n\nPower analysis for your final project\n\n\n\n\n\nLecture focus\n\nTroubleshooting models\nRefining visualizations & write-up\n\nLab\n\nPeer review final project drafts\n\nReadings\n\nNo new readings ‚Äî review past materials\n\nAssignment\n\nSubmit draft project\n\n\n\n\n\nLecture focus\n\nCommunicating results to non-statistical audiences\nTranslating skills to the workplace\n\nLab\n\nStudent presentations\nClass reflection: ‚ÄúWhat I‚Äôll take forward‚Äù\n\nReadings\n\nNo new readings\n\nFinal Deliverable\n\nFully reproducible RMarkdown/Quarto report with:\n\nIntroduction & research question\nMethods\nRegression-based analysis\nAPA-style results\nVisualizations\nReferences\n\n\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. Due to the accelerated nature of the course, the late penalty will be more severe. There will be a 50% deduction on the first day. Work will not be accepted beyond 24 hours after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nEach course that you are involved in will have differing opinions and goals regarding generative AI (i.e., ChatGPT, Gemini, Perplexity, Claude, etc.). In this course you are allowed to use these as a tool. You can use prompts such as ‚ÄúTeach me about (insert psych topic here) and give me an example that might apply to me.‚Äù If you do use generative AI, I would like for you to disclose that information just so I can have a sense of how it is being used. If I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email."
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6: Comparing Means",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 6 (.Rmd)\nDownload Treatment Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#instructions",
    "href": "labs/lab-6.html#instructions",
    "title": "Lab 6: Comparing Means",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 6 (.Rmd)\nDownload Treatment Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#scenario-and-goal",
    "href": "labs/lab-6.html#scenario-and-goal",
    "title": "Lab 6: Comparing Means",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nWelcome back! For this lab you‚Äôll step into the role of a data analyst for a clinical psychology lab. Your team has just completed a pilot randomized controlled trial (RCT) for a new, brief CBT (Cognitive Behavioral Therapy) intervention designed to reduce symptoms of depression (group variable). You‚Äôve been given the initial dataset and tasked with running the primary analyses to see if the intervention shows promise.\nThis dataset includes participant demographics (sex, age) and depression scores from before (bdi_pre) and after (bdi_post) the trial. As is common in clinical research, some participants dropped out before the final assessment, resulting in missing data.\n\n\n\n\n\n\nNote\n\n\n\nThe BDI is a common measure to assess for symptoms of depression. It stands for the Beck Depression Inventory and higher scores indicate a higher level of depression.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#exercises",
    "href": "labs/lab-6.html#exercises",
    "title": "Lab 6: Comparing Means",
    "section": "Exercises",
    "text": "Exercises\n\nTask 1: Setup & Data Inspection (10 points)\nYour first and most important task is always to understand and inspect your data before running any analyses.\nTasks:\n\nCreate a new R Markdown file named Week6_Lab.Rmd.\nLoad Libraries and Data\nInitial Inspection:\n\nUse glimpse() to see the structure of your data.\nUse summary() to get a quick overview of each variable. Pay close attention to the bdi_post variable. What do you notice?\n\nVisualization:\n\nGenerate a visualization of the distribution for bdi_pre and bdi_post\n\nThese can be two separate figures\n\n\nSummary Stats (2 tables):\n\nProvide descriptive statistics (Means & SD) in a nice looking table for age, bdi_pre, bdi_post. Include a correlation table with those variables as well.\n\n\n\n\nTask 2: Paired-Samples t-test - Did the Individual CBT Work?\nFor participants who received one-on-one therapy (group == \"Individual CBT\"), did their depression scores significantly decrease?\n\nFilter the data: Create a new data frame called individual_tx that contains only the participants from the Individual CBT group.\nRun the test: Conduct a paired-samples t-test on the bdi_pre and bdi_post scores within the individual_tx data.\nInterpret the results: Based on the results, was there a statistically significant change in BDI scores? Describe the direction and magnitude of the change.\n\n\n\nTask 3: One-Sample t-test - Achieving Clinical Remission\nA BDI score below 10 is often considered the cutoff for clinical remission. Did our individual CBT group, on average, get below this threshold?\n\nRun the test: Using the individual_tx data, conduct a one-sample t-test on the bdi_post scores, testing against a population mean (mu) of 10.\nAPA Write-up: Report your results in a full APA-formatted sentence. You will need to calculate the mean and standard deviation for the bdi_post scores separately to include in your write-up.\n\n\n\nTask 4: One-Way ANOVA\nNow we‚Äôll compare the final outcomes (bdi_post) across all three groups: Individual CBT, Group CBT, and the Waitlist Control.\n\nRun the ANOVA: Using the full cbt_data, conduct a one-way ANOVA to test for differences in bdi_post among the three group conditions.\nInterpret the ANOVA: Look at the summary() of your ANOVA object. Is the overall F-test significant? What does this tell us? Note the degrees of freedom‚Äîdoes the sample size make sense given the data?\nRun Post-Hoc Tests: A significant ANOVA requires a post-hoc test. Run a Tukey HSD test to see which specific groups differ.\nWrite a conclusion: In 2-3 sentences, summarize the findings from the post-hoc test. Which treatment(s) were effective compared to the control group?\n\n\n\nTask 5: Independent-Samples t-test - Exploring Sex as a Moderator\nWe were also interested to use exploratory analyses to further understand the impact of the treatment. For instance, did the therapy work equally well for males and females? Let‚Äôs investigate this.\nTasks:\n\nCalculate change scores: Create a new data frame called cbt_active_tx that contains only the two active therapy groups (Individual and Group CBT). Add a new column to it called bdi_change, calculated as bdi_pre - bdi_post.\nRun the test: In this cbt_active_tx data, conduct an independent-samples t-test to see if there is a significant difference in the bdi_change scores between participants identified as Male and Female.\nVisualize and Interpret: Create a ggplot boxplot to visualize the bdi_change scores by sex. Based on your test and your plot, is there any evidence that the treatment effect was different for males versus females in this pilot study?\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-9.html",
    "href": "labs/lab-9.html",
    "title": "Lab 4:",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file."
  },
  {
    "objectID": "labs/lab-9.html#instructions",
    "href": "labs/lab-9.html#instructions",
    "title": "Lab 4:",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file."
  },
  {
    "objectID": "labs/lab-9.html#scenario-and-goal",
    "href": "labs/lab-9.html#scenario-and-goal",
    "title": "Lab 4:",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal"
  },
  {
    "objectID": "labs/lab-9.html#exercises",
    "href": "labs/lab-9.html#exercises",
    "title": "Lab 4:",
    "section": "Exercises",
    "text": "Exercises\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂"
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 4 (.Rmd)\nDownload Sleep Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#instructions",
    "href": "labs/lab-4.html#instructions",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 4 (.Rmd)\nDownload Sleep Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#scenario-and-data",
    "href": "labs/lab-4.html#scenario-and-data",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Scenario and Data",
    "text": "Scenario and Data\nA researcher at the university‚Äôs sleep center is interested in the factors that affect daytime sleepiness and attention in college students. They collected survey data from a sample of students.\nThe data highlighted above contains the following variables (and more):\n\nESS1 - ESS8: (Continuous) The student‚Äôs responses to each item on the Epworth Sleepiness Scale, a measure of general daytime sleepiness. Higher scores indicate greater sleepiness. NOTE: You will need to calculate a total score which is a sum of all 8 items.\nashs1 - ashs33: (Continuous) The student‚Äôs responses to each item on the Adolescent Sleep Hygiene Scale. Higher scores indicate better sleep habits (e.g., consistent bedtime, quiet environment). The original data collection did not have an item 25 (so you won‚Äôt see one in your data).\n\nNOTE: You will need to reverse score all items except¬†#27. You will also need to calculate a total mean score with these items.\n\nattention1r - attention5r: (Categorical) An indication of whether they passed (1) or failed (0) the attention check item. A proxy for their attention during the survey. NOTE: Calculate a total attention score as a sum of all 5 items.\nage: (Continuous) The student‚Äôs age in years.\nroommate: (Categorical) Whether the student has a roommate or not (‚ÄúYes‚Äù, ‚ÄúNo‚Äù).\n\n1 = ‚ÄúYes‚Äù and 2 = ‚ÄúNo‚Äù",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#task-1-compute-scores-for-scales",
    "href": "labs/lab-4.html#task-1-compute-scores-for-scales",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Task 1: Compute scores for scales",
    "text": "Task 1: Compute scores for scales\nBe sure to compute the appropriate total scores for the ESS, ASHS and Attention variables.\n\n\n\n\n\n\nImportant\n\n\n\nThere are a couple attention items that are in the ASHS section which can get a little confusing when trying to reverse code and getting total scores.\n\n\nOnce completed, only include students who have ‚Äúpassed‚Äù the attention check (i.e., having a score of 4 or higher on the attention sum total).\nhint: use dplyr and filter",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#task-2-roommates-and-daytime-sleepiness-a-group-comparison",
    "href": "labs/lab-4.html#task-2-roommates-and-daytime-sleepiness-a-group-comparison",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Task 2: Roommates and Daytime Sleepiness (A Group Comparison)",
    "text": "Task 2: Roommates and Daytime Sleepiness (A Group Comparison)\nThe Research Question: ‚ÄúDo students who have a roommate report different levels of daytime sleepiness compared to students who do not have a roommate?‚Äù\nYour Steps:\n\nIdentify & Model:\n\nWhat is the predictor (IV) and what is the outcome (DV)?\nAre they categorical or continuous?\nBased on this, what is the appropriate model family? Write out the model in R formula syntax (outcome ~ predictor).\n\nDescribe & Visualize:\n\nCalculate the mean and standard deviation of ess_score for both groups (those with and without a roommate).\nCreate a boxplot to visualize the distribution of ess_score for each group. Make sure your plot is clearly labeled.\n\nAnalyze:\n\nRun the appropriate statistical test in R to determine if there is a significant difference between the groups.\n\nInterpret & Conclude:\n\nWhat is the p-value from your test?\nBased on the test and your descriptive statistics, write a one-sentence conclusion that directly answers the research question.\nCritical Thinking: This is an observational study. Can you conclude that having a roommate causes a change in sleepiness? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#bonus-sleep-habits-and-age-an-association",
    "href": "labs/lab-4.html#bonus-sleep-habits-and-age-an-association",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Bonus: Sleep Habits and Age (An Association)",
    "text": "Bonus: Sleep Habits and Age (An Association)\nThis question is not required. But you will get some bonus points if you decide to do it!\nThe Research Question: ‚ÄúIs there an association between a student‚Äôs sleep habits and their age?‚Äù\nYour Steps:\n\nIdentify & Model:\n\nWhat is the predictor (IV) and what is the outcome (DV)?\nAre they categorical or continuous?\nBased on this, what is the appropriate model family? Write out the model in R formula syntax.\n\nVisualize:\n\nCreate a scatterplot to visualize the relationship between ashs_score (sleep habits) and age.\nAdd a line of best fit to the plot. Make sure your plot is clearly labeled.\n\nAnalyze:\n\nRun the appropriate statistical test in R to determine if there is a significant association between the two variables.\n\nInterpret & Conclude:\n\nWhat is the correlation coefficient (r) and the p-value from your test?\nBased on these results, write a one-sentence conclusion that describes the nature and significance of the relationship.\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/reverse_results.html",
    "href": "labs/reverse_results.html",
    "title": "Reverse Results",
    "section": "",
    "text": "From Reader to Writer\nOne of the most challenging parts of writing a research paper is crafting a clear and compelling results section. How do you go from a folder full of statistical output to a coherent narrative? The best way to learn is to see how experts do it.\nIn this assignment, you will ‚Äúreverse-engineer‚Äù the results section of a published paper. Think of yourself as an apprentice studying a master‚Äôs work. Your goal is to uncover the underlying architecture‚Äîthe deliberate choices the author made to guide the reader through their findings. This process will help you build a mental toolkit of effective strategies for your own writing.\n\n\nInstructions\n\nStep 1: Select a Research Article\n\nFind a peer-reviewed, quantitative research article in a topic area that interests you. The article should be a strong example of clear scientific writing.\nThe article should test one or more specific hypotheses using statistical methods we have discussed or will be discussing (e.g., t-tests, ANOVA, correlation, regression).\nDo not choose a meta-analysis, literature review, or qualitative study.\n\n\n\nStep 2: Create Your Writer‚Äôs Blueprint\nRead the results section with a writer‚Äôs eye. Your task is to outline the author‚Äôs ‚Äúmoves.‚Äù For each paragraph or distinct analytical block, your outline should explain the narrative strategy. Instead of just summarizing, analyze how and why the paragraph is constructed the way it is.\nFor each section of your outline, describe:\n\nThe Narrative Goal: What is the author‚Äôs primary goal for this paragraph? What key question is it answering for the reader? (e.g., ‚ÄúHere, the author is setting the stage by confirming the randomization worked,‚Äù or ‚ÄúThis is the crucial paragraph where they test their main hypothesis.‚Äù).\nThe Writing Strategy: How did they structure the paragraph to achieve that goal? Notice the flow. Do they lead with a plain-language summary? How do they present the statistical evidence in support of their claim? (e.g., ‚ÄúThe author uses a ‚ÄòClaim-First‚Äô structure: they state the finding in words, then provide the stats to back it up.‚Äù).\n\n\n\n\nExample\nConsider this fictional paragraph from a results section:\n\nTo test our primary hypothesis that the CBT intervention would reduce social anxiety symptoms more than the waitlist control condition, we conducted an independent-samples t-test on post-treatment SAQ scores. The analysis revealed a significant difference between the groups, t(72) = 3.88, p &lt; .001. The mean SAQ score for the CBT group (M = 24.5, SD = 5.1) was significantly lower than the mean score for the waitlist control group (M = 35.2, SD = 6.3), indicating a strong treatment effect.\n\nYour blueprint entry for this paragraph might look like this:\n\nParagraph 3: Testing the Main Hypothesis.\n\nNarrative Goal: To present the findings for the study‚Äôs primary research question.\nWriting Strategy:\n\nState the Why: They begin by explicitly stating which hypothesis they are testing and what analysis they used (independent-samples t-test).\n\nDeliver the Punchline: They immediately present the finding (t(72)=3.88,p&lt;.001).\nExplain in Context: Translate the statistic back into meaningful terms by presenting the group means, making the result easy to understand.\nThis ‚ÄúPurpose -&gt; Evidence -&gt; Interpretation‚Äù flow is a powerful and clear way to structure a finding.\n\n\n\n\n\n\nWhat to Submit\nPlease submit a single document to myCourses with:\n\nA full APA-style citation of the article you selected\nYour complete ‚ÄúWriter‚Äôs Blueprint‚Äù of the article‚Äôs results section."
  },
  {
    "objectID": "labs/lab-5_cor.html",
    "href": "labs/lab-5_cor.html",
    "title": "Lab 5: Correlations",
    "section": "",
    "text": "We are going to investigate what is most highly related to the number of Spotify streams in this Popular Music dataset. This data was taken from: https://www.kaggle.com/datasets/ahmadrazakashif/spotify-popularity-songs\nHere are the things that you will need for this lab:\n\nDownload Spotify Data (.csv)\nDownload Lab 5 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html#instructions",
    "href": "labs/lab-5_cor.html#instructions",
    "title": "Lab 5: Correlations",
    "section": "",
    "text": "We are going to investigate what is most highly related to the number of Spotify streams in this Popular Music dataset. This data was taken from: https://www.kaggle.com/datasets/ahmadrazakashif/spotify-popularity-songs\nHere are the things that you will need for this lab:\n\nDownload Spotify Data (.csv)\nDownload Lab 5 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html#scenario-and-goal",
    "href": "labs/lab-5_cor.html#scenario-and-goal",
    "title": "Lab 5: Correlations",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nWe have been asked by an up and coming music artist to use our advanced data analytic skills to see what has been related to the most popular songs. They have provided us with all of this data for recent popular songs that have been streamed the most.\nOur goal is to identify which variable is most related to higher streams. These variables that they are looking at are things like danceability, instrumentalness, etc.\n\nVariables of Interest\n\nstreams: The number of streams for the individual song\nPercentage Variables: These variables reflect a rating from 0-100 on the intensity related to that variable\n\ndanceability_%\nvalence_%\nenergy_%\nacousticness_%\ninstrumentalness_%\nliveness_%\nspeechiness_%",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html#lab-exercises",
    "href": "labs/lab-5_cor.html#lab-exercises",
    "title": "Lab 5: Correlations",
    "section": "Lab Exercises",
    "text": "Lab Exercises\nImport your data and use the clean_names() function to make the variables a little nicer looking\nStart by creating a correlation table (make sure it looks nice and not just an output from R using cor()).\nExamine the correlation table and identify the two largest effects with the outcome (streams).\nVisualize the two correlations that you have identified.\nChoose one of the relationships that you visualized and write the results in APA format.\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "We are now in the third week and you are all probably thinking about how much you dislike R and do not ever want to look at the here() library again. But we are going to have to do just that. Importing and getting started are one of the hardest things to do when first working with R. And then trying to make things reproducible is another thing. We are going to practice this A LOT. Especially right in the beginning.\nThis week we are going to expand on some data wrangling to get more comfortable with dplyr and the larger tidyverse. Here is a good website that can also be helpful. Then we will move into an overview of descriptive statistics and how to get them using R. Finally, we will continue with visualizations using ggplot2. With time, we will start introducing how to talk communicate these types of statistics in a manuscript.\n\n\nüìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS\n\n\n\nüíª Data Wrangling\nüíª Describe & Visualize\n\n\n\nDescribing & Visualizing\n\n\n\nüìãLab 3 - Describe and Visualize\nüìñRead Chapter 2 - IMS\nüìñRead Chapter 3 - MSR\nüìñRead Chapter 7 - ST\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "üìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#slides",
    "href": "weeks/week-3.html#slides",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "üíª Data Wrangling\nüíª Describe & Visualize",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#in-class-activity",
    "href": "weeks/week-3.html#in-class-activity",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "Describing & Visualizing",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#for-next-time",
    "href": "weeks/week-3.html#for-next-time",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "üìãLab 3 - Describe and Visualize\nüìñRead Chapter 2 - IMS\nüìñRead Chapter 3 - MSR\nüìñRead Chapter 7 - ST\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-10.html#slides",
    "href": "weeks/week-10.html#slides",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data"
  },
  {
    "objectID": "weeks/week-10.html#in-class-activity",
    "href": "weeks/week-10.html#in-class-activity",
    "title": "Week XX",
    "section": "",
    "text": "Getting Comfy with R"
  },
  {
    "objectID": "weeks/week-10.html#for-next-time",
    "href": "weeks/week-10.html#for-next-time",
    "title": "Week XX",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#slides",
    "href": "weeks/week-7.html#slides",
    "title": "Week XX",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data",
    "crumbs": [
      "Weekly Materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#in-class-activity",
    "href": "weeks/week-7.html#in-class-activity",
    "title": "Week XX",
    "section": "",
    "text": "Getting Comfy with R",
    "crumbs": [
      "Weekly Materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#for-next-time",
    "href": "weeks/week-7.html#for-next-time",
    "title": "Week XX",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to the course! I am very excited to get to work with you this semester on our journey into statistics. During our first class, we will review the syllabus and the plan for the course, followed by walking through the structure of each of the classes.\nWe‚Äôll then dive right into our primary tool, R. This session will go over installing R and RStudio, navigating the interface, understanding R projects, and learning the foundational syntax of the R language and the tidyverse, including data types and basic functions.\n\n\n\nInstall R and R-Studio (https://posit.co/download/rstudio-desktop/)\nBring Laptop\n\n\n\n\nüíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "",
    "text": "Install R and R-Studio (https://posit.co/download/rstudio-desktop/)\nBring Laptop",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#slides",
    "href": "weeks/week-1.html#slides",
    "title": "Week 1",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#in-class-activity",
    "href": "weeks/week-1.html#in-class-activity",
    "title": "Week 1",
    "section": "",
    "text": "Getting Comfy with R",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#for-next-time",
    "href": "weeks/week-1.html#for-next-time",
    "title": "Week 1",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 06",
    "section": "",
    "text": "Cards Against Humanity Data (.csv)\nWeek 6 Class Activity Data (.csv)\n\n\n\n\n\nChapter 9 & 10 - ST\nChapter 13 - LSR\n\n\n\n\nüíª Comparing Means\n\n\n\nWalk along comparing means\n\n\n\nüìãLab 6 - Still Comparing Means\nüìñChapter 14.1.1 - 14.1.4 - ST\nüìñChapter 7.1 - 7.2.4 - IMS\nüìñChapter 8.1.1 & 8.1.2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#materialsdata",
    "href": "weeks/week-6.html#materialsdata",
    "title": "Week 06",
    "section": "",
    "text": "Cards Against Humanity Data (.csv)\nWeek 6 Class Activity Data (.csv)",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#prepare",
    "href": "weeks/week-6.html#prepare",
    "title": "Week 06",
    "section": "",
    "text": "Chapter 9 & 10 - ST\nChapter 13 - LSR",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#slides",
    "href": "weeks/week-6.html#slides",
    "title": "Week 06",
    "section": "",
    "text": "üíª Comparing Means",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#in-class-activity",
    "href": "weeks/week-6.html#in-class-activity",
    "title": "Week 06",
    "section": "",
    "text": "Walk along comparing means",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#for-next-time",
    "href": "weeks/week-6.html#for-next-time",
    "title": "Week 06",
    "section": "",
    "text": "üìãLab 6 - Still Comparing Means\nüìñChapter 14.1.1 - 14.1.4 - ST\nüìñChapter 7.1 - 7.2.4 - IMS\nüìñChapter 8.1.1 & 8.1.2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 05",
    "section": "",
    "text": "Chapter 5.1 & 13 - ST\nChapter 11 - LSR\n\n\n\n\nüíª Correlation & ES\n\n\n\nCorrelations\n\n\n\nüìãLab 5 - More Correlations\nüìãReverse Results\nüìñChapter 9 & 10 - ST\nüìñChapter 13 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#prepare",
    "href": "weeks/week-5.html#prepare",
    "title": "Week 05",
    "section": "",
    "text": "Chapter 5.1 & 13 - ST\nChapter 11 - LSR",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#slides",
    "href": "weeks/week-5.html#slides",
    "title": "Week 05",
    "section": "",
    "text": "üíª Correlation & ES",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#in-class-activity",
    "href": "weeks/week-5.html#in-class-activity",
    "title": "Week 05",
    "section": "",
    "text": "Correlations",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#for-next-time",
    "href": "weeks/week-5.html#for-next-time",
    "title": "Week 05",
    "section": "",
    "text": "üìãLab 5 - More Correlations\nüìãReverse Results\nüìñChapter 9 & 10 - ST\nüìñChapter 13 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "resources/introwrangling.html",
    "href": "resources/introwrangling.html",
    "title": "Intro to Data Wrangling",
    "section": "",
    "text": "Special thanks to Sara J. Weston and the work done with their class at Oregon."
  },
  {
    "objectID": "resources/introwrangling.html#create-a-reproducible-lab-report",
    "href": "resources/introwrangling.html#create-a-reproducible-lab-report",
    "title": "Intro to Data Wrangling",
    "section": "Create a reproducible lab report",
    "text": "Create a reproducible lab report\nTo create your new lab report, in RStudio, go to New File -&gt; R Markdown. Then delete everything after Line 5 and save it in the folder you will be using for the current lab. Remember, make a single folder on your computer that holds everything necessary for the project you are working on."
  },
  {
    "objectID": "resources/introwrangling.html#put-the-data-where-it-needs-to-be",
    "href": "resources/introwrangling.html#put-the-data-where-it-needs-to-be",
    "title": "Intro to Data Wrangling",
    "section": "Put the Data where it needs to be",
    "text": "Put the Data where it needs to be\nDownload your data that you will be using and place this data file in the folder you are using.¬†I always encourage a ‚ÄúData‚Äù Folder that holds all raw data."
  },
  {
    "objectID": "resources/introwrangling.html#load-the-libraries",
    "href": "resources/introwrangling.html#load-the-libraries",
    "title": "Intro to Data Wrangling",
    "section": "Load the Libraries",
    "text": "Load the Libraries\nGet the libraries loaded in their own code chunk. We will be using here, psych and rio. Remember that if you haven‚Äôt already installed these libraries (i.e., bought the book from the book store for your own personal library), you will need to run the command install.packages() in the console with the appropriate packages name in the parentheses surrounded by quotation marks.\nIn the console:\ninstall.packages(\"here\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"rio\")\nIn the first code chunk of your Rmd file\nlibrary(here)\nlibrary(tidyverse)\nlibrary(rio)"
  },
  {
    "objectID": "resources/introwrangling.html#import-the-data",
    "href": "resources/introwrangling.html#import-the-data",
    "title": "Intro to Data Wrangling",
    "section": "Import the data",
    "text": "Import the data\nImport the data using the rio package and save it to an object called sleep_data. You will be able to use the import() function as well as the here() function.\n\n\n\n\n\n\nsleep_data &lt;- import(here(‚ÄúLabs‚Äù, ‚ÄúData‚Äù, ‚ÄúSleepFile‚Äù, ‚ÄúSleepData.sav‚Äù))"
  },
  {
    "objectID": "resources/introwrangling.html#histogram",
    "href": "resources/introwrangling.html#histogram",
    "title": "Intro to Data Wrangling",
    "section": "Histogram",
    "text": "Histogram\nOne common way of visualizing distributions is using a histogram, which plots the frequencies of different values for a given variable.\nFor example, let‚Äôs take a look at a distribution of the age variable. We do this using the hist() function. (Remember, you can check out the help documentation using ?hist).\nCreate a histogram using the age variable with the title ‚ÄúHistogram of Age‚Äù and the x-axis labeled as ‚ÄúAge‚Äù.\nYou can also change the number of bins (i.e.¬†bars) in your histogram using the breaks argument. Try 5, 10, and 20 breaks. What do you notice as the number of breaks increases?"
  },
  {
    "objectID": "resources/introwrangling.html#boxplot",
    "href": "resources/introwrangling.html#boxplot",
    "title": "Intro to Data Wrangling",
    "section": "Boxplot",
    "text": "Boxplot\nAnother way to visualize distribution and to better examine the outliers is to use a boxplot. For a short guide on how to read boxplots, seehere or refer tothis section of the textbook.\nCreate a boxplot using the age variable with the title ‚ÄúBoxplot of Age‚Äù and the x-axis labeled as ‚ÄúAge‚Äù. What do you notice??\nInvestigate the distribution more with boxplot.stats(x = sleep_data$age)$out"
  },
  {
    "objectID": "resources/introwrangling.html#looking-into-the-future",
    "href": "resources/introwrangling.html#looking-into-the-future",
    "title": "Intro to Data Wrangling",
    "section": "Looking into the future‚Ä¶",
    "text": "Looking into the future‚Ä¶\nSo far we have been plotting in base R. However, theggplot2 package is generally a much better tool for plotting. For now we‚Äôll stick with base plotting to keep things simple, but in a future class you will learn how to use ggplot to make better-looking plots, such as this:\nOk, so now that we know how to visualize a basic distribution, let‚Äôs think about how we commonly characterize distributions with descriptive statistics‚Ä¶"
  },
  {
    "objectID": "resources/introwrangling.html#measures-of-central-tendency",
    "href": "resources/introwrangling.html#measures-of-central-tendency",
    "title": "Intro to Data Wrangling",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nFor a given set of observations, measures of central tendency allow us to get the ‚Äúgist‚Äù of the data. They tell us about where the ‚Äúaverage‚Äù or the ‚Äúmid-point‚Äù of the data lies. Let‚Äôs take a look at the data that we have already loaded in, and complete some of these tasks (which we may already have done in previous classes).¬†\n\nMean\nA quick way to find the mean is to use the aptly named mean() function from base R. Use this function on the age variable in the sleep_data dataset.\n\n\n\nmean(sleep_data$age)\n\n\n\nOh no! We forgot to account for the missing variables in our variable! We got NA! The reason for this is that the mean is calculated by using every value for a given variable, so if you don‚Äôt remove (or impute) the missing values before getting the mean, it won‚Äôt work.\nLet‚Äôs try that again, but using the additional argument to eliminate (or remove) the NA‚Äôs from the variable prior to computing the mean.¬†\n\n\n\nmean(sleep_data$age, na.rm = TRUE)\n\n\n\n\n\nMedian\nThe median is the middle value of a set of observations: 50% of the data points fall below the median, and 50% fall above.\nTo find the median, we can use the median() function. Use it on the age variable."
  },
  {
    "objectID": "resources/introwrangling.html#measures-of-variability",
    "href": "resources/introwrangling.html#measures-of-variability",
    "title": "Intro to Data Wrangling",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nRange\nThe range gives us the distance between the smallest and largest value in a dataset. You can find the range using the range() function, which will output the minimum and maximum values. Find the range of the age variable.\n\n\nVariance and Standard Deviation\nTo find the variance and standard deviation, we use var() and sd(), respectively. Find the variance and standard deviation of the age variable."
  },
  {
    "objectID": "resources/introwrangling.html#describe",
    "href": "resources/introwrangling.html#describe",
    "title": "Intro to Data Wrangling",
    "section": "describe()",
    "text": "describe()\nThis function automatically calculates all of the descriptives we reviewed above (and more!). Use the describe() function from the psych package on the entire sleep_data dataset.\nNotes: If you load a library at the beginning, you can directly call any function from it. Instead, you can call a function by library_name::function_name without loading the entire library.\n\n\n\n\n\n\npsych::describe(sleep_data)\n# or if you have already loaded the library\ndescribe(sleep_data)\n\n\n\nNOTE: Some variables are not numeric and are categorical variables of type character. By default, the describe() function forces non-numeric variables to be numeric and attempts to calculate descriptives for them. These variables are marked with an asterisk (*). In this case, it doesn‚Äôt make sense to calculate descriptive statistics for these variables, so we get a warning message and a bunch of NaN‚Äôs and NA‚Äôs for these variables.\nA better approach would be to remove non-numeric variables before you attempt to run numerical calculations on your dataset.\nNow let‚Äôs take a closer look at trying to update the age variable in this dataset."
  },
  {
    "objectID": "resources/introwrangling.html#what-is-data-wrangling",
    "href": "resources/introwrangling.html#what-is-data-wrangling",
    "title": "Intro to Data Wrangling",
    "section": "What is data wrangling?",
    "text": "What is data wrangling?\nData wrangling, broadly speaking, means getting your data into a useful form for visualizing and modeling it. Hadley Wickham, who has developed a lot of the tidyverse, conceptualizes the main steps involved in data wrangling as follows:\n\nImporting your data¬†\nTidying your data (see brief overview below)\nTransforming your data (what we‚Äôll cover today)\n\nThe figure below highlights the steps in data wrangling in relation to the broader scope of a typical data science workflow:"
  },
  {
    "objectID": "resources/introwrangling.html#what-is-tidy-data",
    "href": "resources/introwrangling.html#what-is-tidy-data",
    "title": "Intro to Data Wrangling",
    "section": "What is ‚Äútidy data‚Äù?",
    "text": "What is ‚Äútidy data‚Äù?\nData is considered ‚Äútidy‚Äù when:¬†\n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell\n\nThe following figure is from R for Data Science and visualizes tidy data.¬†\nIf your data is not already in tidy format when you import it, you can use functions from the {tidyR} package, e.g.¬†pivot_longer() and pivot_wider(), that allow you to ‚Äúreshape‚Äù your data to get it into tidy format.\nHowever, this term we are mostly going to work with simpler datasets that are already tidy, so we are not going to focus on these functions today. These functions will become especially useful in the future when we work with repeated measures data that has multiple observations for each subject. If you are interested in learning more about reshaping your data with {tidyR}, check outthis chapter from R for Data Science."
  },
  {
    "objectID": "resources/introwrangling.html#pipes",
    "href": "resources/introwrangling.html#pipes",
    "title": "Intro to Data Wrangling",
    "section": "Pipes",
    "text": "Pipes\nPipes come from the {magrittr} package are available when you load the tidyverse. (Technically, the pipe is imported with {dplyr}.) Pipes are a way to write strings of functions more easily, creating pipelines. They are extremely powerful and useful. A pipe looks like this:\nYou can enter a pipe with the shortcut CTRL+Shift+M for PC or CMD+Shift+M for Mac.\nA pipe passes an object on the left-hand side as the first argument (or . argument) of whatever function is on the right-hand side.\n\nx %&gt;% f(y) is the same as f(x, y)\ny %&gt;% f(x, ., z) is the same as f(x, y, z )\n\nExample: I want to calculate the mean of the mpg variable from the mtcars data set and round our answer to 2 decimal places. I can accomplish this by nesting:\n\n\n\nround(mean(mtcars$mpg, na.rm = TRUE), 2)\n\n\n\nOr, we could use pipes. Grammatically, you can think of a pipe as ‚Äúthen.‚Äù I have a variable, the mile per gallon of cars, THEN I want to take the mean of that variable, and THEN I want to round that answer to two decimal places.\n\n\n\n\n\n\nmtcars$mpg %&gt;% # select the `mpg` variable from the `mtcars` dataset\nmean(na.rm = TRUE) %&gt;% # calculate the mean\nround(2) # round to 2 decimal places\n\n\n\nNow try rewriting the following code using pipes:\n\n\n\nround(sqrt(sum(mtcars$cyl)), 1)\n\n\n\n\nWhy use pipes?\n\nCleaner code\n\nThis is nice, because it helps make your code more readable by other humans (including your future self).\n\n\n\n\nCleaner environment\n\nWhen you use pipes, you have basically no reason to save objects from intermediary steps in your data wrangling / analysis workflow, because you can just pass output from function to function without saving it.\nFinding objects you‚Äôre looking for is easier.\n\n\n\n\nEfficiency in writing code\n\nNaming objects is hard; piping means coming up with fewer names.\n\n\n\n\nMore error-proof\n\nBecause naming is hard, you might accidentally re-use a name and make an error."
  },
  {
    "objectID": "resources/introwrangling.html#manipulating-observations",
    "href": "resources/introwrangling.html#manipulating-observations",
    "title": "Intro to Data Wrangling",
    "section": "Manipulating Observations",
    "text": "Manipulating Observations\n\nExtract rows with filter()\nThe filter() function is used to subset observations based on their values. The result of filtering is a data frame with the same number of columns as before but fewer rows, as illustrated below‚Ä¶\nThe first argument is data and subsequent arguments are logical expressions that tell you which observations to retain in the data frame.\nFor example, we can filter rows to retain data only for the students who do not have a roommate.\n\n\n\n\n\n\nsleep_data %&gt;%\nfilter(roommate == 2)\n\n\n\nBut we may want to save this as a new datafile. Can assign this to a new object.\n\n\nLogical Operators\nThe == we just used is an example of a comparison operator that tests for equality. The other comparison operators available are :\n\n&gt; (greater than)\n&gt;= (greater than or equal to)\n&lt; (less than)\n&lt;= (less than or equal to)\n!= (not equal to)\n\nYou can combine multiple arguments to filter() with Boolean operators. The figure below fromR for Data Science shows the complete set of Boolean operators.\n\n\nTry it out yourself:¬†\nFirst, let‚Äôs filter for observations that are greater than the mean of age\n\n\n\n\n\n\nsleep_data %&gt;%\nfilter(age &gt; mean(age, na.rm = TRUE)\n\n\n\nNow, you try filtering observations that are greater than the mean of happiness, but the participant does have a roommate:¬†\n\n\n\n# Put your code here\n\n\n\nFilter out the age variable that are out of bounds"
  },
  {
    "objectID": "resources/introwrangling.html#manipulating-variables",
    "href": "resources/introwrangling.html#manipulating-variables",
    "title": "Intro to Data Wrangling",
    "section": "Manipulating Variables",
    "text": "Manipulating Variables\n\nExtract columns with select()\nThe select() function subsets columns in your data frame. This is particularly useful when you have a data set with a huge number of variables and you want to narrow down to the variables that are relevant for your analysis.\nThe first argument is data, followed by the name(s) of the column(s) you want to subset. Note that you can use variable positions rather than their names, but this is usually not as useful. Let‚Äôs go through some simple examples of common uses of select().\nSelect one variable\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study)\n\n\n\nSelect multiple variables\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study, bed_read, bed_friends)\n\n\n\nSelect a range of variables\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study:bed_videogames) %&gt;%\nnames()\n\n\n\nDe-select variables with a minus sign (-)\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(-age)\n\n\n\nDe-select range of variables\nNote: everything() is a helper function that gives us all the remaining variables in the data frame (see more onhelper functions below)\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(-(ESS1:everything())\n\n\n\n\n\nHelper functions for select()\nThere are some ‚Äúhelper‚Äù functions that you can use along with select() that can sometimes be more efficient than selecting your variables explicitly by name.\n\n\n\n\n\n\n\nfunction\nwhat it does\n\n\nstarts_with()\nselects columns starting with a string\n\n\nends_with()\nselects columns that end with a string\n\n\ncontains()\nselects columns that contain a string\n\n\nmatches()\nselects columns that match a regular expression\n\n\nnum_ranges()\nselects columns that match a numerical range\n\n\none_of()\nselects columns whose names match entries in a character vector\n\n\neverything()\nselects all columns\n\n\nlast_col()\nselects last column; can include an offset.\n\n\n\nQuick example:\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(starts_with(‚Äúa‚Äù)\n\n\n\n\n\nMake new variables with mutate()\nThe mutate() function is most commonly used to add new columns to your data frame that are functions of existing columns.\nmutate() requires data as its first argument, followed by a set of expressions defining new columns. Let‚Äôs take a couple examples‚Ä¶\nCreate new variables\n\nNote: New variables are automatically added at the end of the data frame (scroll to the right to see them)\n\n\n\n\n\n\n\nsleep_data &lt;- sleep_data %&gt;%\nmutate(ess_sum = ESS1 + ESS2 + ESS3 + ESS4 +\nESS5 + ESS6 + ESS7 + ESS8)\n\n\n\nLab Q‚Äôs (60 Points)\nNOTE: Use the dataset that you prepared above (put this all in the same R-Notebook)."
  },
  {
    "objectID": "resources/introwrangling.html#epworth-sleepiness-scale-30-points",
    "href": "resources/introwrangling.html#epworth-sleepiness-scale-30-points",
    "title": "Intro to Data Wrangling",
    "section": "Epworth Sleepiness Scale (30 points)",
    "text": "Epworth Sleepiness Scale (30 points)\n\nCalculate the mean, median and standard deviation of the ESS Total score. (6 points)\nCreate a histogram of the total scores. (3 points)\nCreate a boxplot of the total scores. Are there any outliers? (5 points)\nUsing the scale cutoff points below, how many individuals would be categorized as: (16 points)\n\nLower Normal Daytime Sleepiness\nModerate or above for Daytime Sleepiness (Moderate and Severe)\n\n\n\n\nHow did you identify the groups above?"
  },
  {
    "objectID": "resources/introwrangling.html#are-folks-paying-attention-30-points",
    "href": "resources/introwrangling.html#are-folks-paying-attention-30-points",
    "title": "Intro to Data Wrangling",
    "section": "Are folks paying attention? (30 points)",
    "text": "Are folks paying attention? (30 points)\n\nAggregate the ‚Äúattention‚Äù variables (attention 1 to attention5) in a sum score. (3 points)\nWhat is the distribution (hint hint do a histogram) of the scores? (3 points)\nWhat is the mean, median, minimum & maximum of the aggregate ‚Äúattention‚Äù variable? (6 points)\nCreate two new datasets labeled (1) ‚Äúdata_attend‚Äù and (2) ‚Äúdata_distract‚Äù. In each dataset have those who were paying attention in the ‚Äúdata_attend‚Äù and those who were not in the ‚Äúdata_distract‚Äù. Paying attention is operationalized as having a score of less than 4 on the aggregated variable. (18 points)\n\nWhat are the sample sizes of each of the datasets?\nWhat is the mean age and gender breakdown of each of the datasets?\nFrom the two that you just created, which dataset do you think we should use?"
  },
  {
    "objectID": "slides/lec-6_mean.html#today",
    "href": "slides/lec-6_mean.html#today",
    "title": "Week 06: Comparing Means",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nHIGHLIGHT THE USE OF THE rm() FUNCTION TO GET RID OF THINGS IN YOUR ENVIRONMENT\n\n# File management\nlibrary(here)\n# for dplyr, ggplot2\nlibrary(tidyverse)\n# Pretty tables\nlibrary(sjPlot)\nlibrary(ggstatsplot)\n# making tests easier\nlibrary(lsr) ## NEW\n# Getting marginal means\nlibrary(emmeans)\n\n#Remove Scientific Notation \noptions(scipen=999)"
  },
  {
    "objectID": "slides/lec-6_mean.html#but-firstdegrees-of-freedom",
    "href": "slides/lec-6_mean.html#but-firstdegrees-of-freedom",
    "title": "Week 06: Comparing Means",
    "section": "but first‚Ä¶Degrees of Freedom",
    "text": "but first‚Ä¶Degrees of Freedom\nDegrees of Freedom: the number of values in the final calculation of a statistic that are free to vary\nExample: Drawing a triangle\n‚ùìQuestion: If you have a sample of 5 scores and you know the mean is 3, how many of those scores can you freely change?"
  },
  {
    "objectID": "slides/lec-6_mean.html#one-sample-t-test",
    "href": "slides/lec-6_mean.html#one-sample-t-test",
    "title": "Week 06: Comparing Means",
    "section": "One Sample t-test",
    "text": "One Sample t-test\nt-tests were developed by William Sealy Gosset, who was a chemist studying the grains used in making beer. (He worked for Guinness.)\n\nSpecifically, he wanted to know whether particular strains of grain made better or worse beer than the standard.\nHe developed the t-test, to test small samples of beer against a population with an unknown standard deviation.\n\nProbably had input from Karl Pearson and Ronald Fisher\n\nPublished this as ‚ÄúStudent‚Äù because Guinness didn‚Äôt want these tests tied to the production of beer."
  },
  {
    "objectID": "slides/lec-6_mean.html#example",
    "href": "slides/lec-6_mean.html#example",
    "title": "Week 06: Comparing Means",
    "section": "Example",
    "text": "Example\nFor examples today, we will use a dataset from Cards Against Humanity‚Äôs Pulse of the Nation survey (https://thepulseofthenation.com/)\n\nCards Against Humanity Data (.csv)\n\n\n## We are using read_csv() this time\n## import() was doing something strange with missing values\ncah &lt;- read_csv(here(\"files\", \"data\", \"CAH.csv\")) %&gt;% \n  janitor::clean_names() \n\nhead(cah)\n\n# A tibble: 6 √ó 16\n     id income gender   age age_range political_affiliation education  ethnicity\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;      &lt;chr&gt;    \n1     1   8000 Female    64 55-64     Democrat              College d‚Ä¶ White    \n2     2  68000 Female    56 55-64     Democrat              High scho‚Ä¶ Black    \n3     3  46000 Male      63 55-64     Independent           Some coll‚Ä¶ White    \n4     4  51000 Male      48 45-54     Republican            High scho‚Ä¶ White    \n5     5 100000 Female    32 25-34     Democrat              Some coll‚Ä¶ White    \n6     6  54000 Female    64 55-64     Democrat              Some coll‚Ä¶ White    \n# ‚Ñπ 8 more variables: marital_status &lt;chr&gt;, climate_change &lt;chr&gt;,\n#   transformers &lt;dbl&gt;, books &lt;dbl&gt;, ghosts &lt;chr&gt;, spending &lt;chr&gt;,\n#   choice &lt;chr&gt;, shower_pee &lt;chr&gt;"
  },
  {
    "objectID": "slides/lec-6_mean.html#cohens-d",
    "href": "slides/lec-6_mean.html#cohens-d",
    "title": "Week 06: Comparing Means",
    "section": "Cohen‚Äôs D",
    "text": "Cohen‚Äôs D\nCohen suggested one of the most common effect size estimates‚Äîthe standardized mean difference‚Äîuseful when comparing a group mean to a population mean or two group means to each other.\n\\[\\delta = \\frac{\\mu_1 - \\mu_0}{\\sigma} \\approx d = \\frac{\\bar{X}-\\mu}{\\hat{\\sigma}}\\]\nCohen‚Äôs d is in the standard deviation (Z) metric."
  },
  {
    "objectID": "slides/lec-6_mean.html#students-t-test",
    "href": "slides/lec-6_mean.html#students-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Student‚Äôs t-test",
    "text": "Student‚Äôs t-test\n\\[ H_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2 \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#welchs-t-test",
    "href": "slides/lec-6_mean.html#welchs-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Welch‚Äôs t-test",
    "text": "Welch‚Äôs t-test\n\\[ H_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2 \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#cool-visualizations",
    "href": "slides/lec-6_mean.html#cool-visualizations",
    "title": "Week 06: Comparing Means",
    "section": "Cool Visualizations",
    "text": "Cool Visualizations\nThe library ggstatsplot has some wonderful visualizations of various tests\n\n\nCode\nggstatsplot::ggbetweenstats(   \n  data  = cah,   \n  x     = ghosts,   \n  y     = books,   \n  title = \"Distribution of books by belief in ghosts\" )"
  },
  {
    "objectID": "slides/lec-6_mean.html#paired-samples-t-test",
    "href": "slides/lec-6_mean.html#paired-samples-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Paired Samples \\(t\\)-Test",
    "text": "Paired Samples \\(t\\)-Test\nChapter 13.5 - Learning Stats with R\nAlso called ‚ÄúDependent Samples t-test‚Äù\n\nWe have been testing means between two independent samples. Participants may be randomly assigned to the separate groups\n\nThis is limited to those types of study designs, but what if we have repeated measures?\n\nWe will then need to compare scores across people‚Ä¶the samples we are comparing now depend on one another and are paired"
  },
  {
    "objectID": "slides/lec-6_mean.html#review-of-the-t-test-process",
    "href": "slides/lec-6_mean.html#review-of-the-t-test-process",
    "title": "Week 06: Comparing Means",
    "section": "Review of the t-test process",
    "text": "Review of the t-test process\n\nCollect Sample and define hypotheses\nSet alpha level\nDetermine the sampling distribution (\\(t\\) distribution for now)\nIdentify the critical value that corresponds to alpha and df\nCalculate test statistic for sample collected\nInspect & compare statistic to critical value; Calculate probability"
  },
  {
    "objectID": "slides/lec-6_mean.html#determining-t-crit",
    "href": "slides/lec-6_mean.html#determining-t-crit",
    "title": "Week 06: Comparing Means",
    "section": "Determining \\(t\\)-crit",
    "text": "Determining \\(t\\)-crit\nCan look things up using a t-table where you need the degrees of freedom and the alpha\nBut we have R to do those things for us:\n\n#the qt() function is for a 1 tailed test, so we are having to divide it in half to get both tails \n\nalpha &lt;- 0.05 \nn &lt;- nrow(ex1) \nt_crit &lt;- qt(alpha/2, n-1) \nt_crit\n\n[1] -2.570582"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-t",
    "href": "slides/lec-6_mean.html#calculating-t",
    "title": "Week 06: Comparing Means",
    "section": "Calculating t",
    "text": "Calculating t\nLet‚Äôs get all of the information for the sample we are focusing on (difference scores):\n\nd &lt;- mean(ex1$diff_score) \nd \n\n[1] -1.166667\n\nsd_diff &lt;- sd(ex1$diff_score) \nsd_diff\n\n[1] 4.167333"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-t-1",
    "href": "slides/lec-6_mean.html#calculating-t-1",
    "title": "Week 06: Comparing Means",
    "section": "Calculating t",
    "text": "Calculating t\nNow we can calculate our \\(t\\)-statistic: \\[t_{df=n-1} = \\frac{\\bar{D}}{\\frac{sd_{diff}}{\\sqrt{n}}}\\]\n\nt_stat &lt;- d/(sd_diff/(sqrt(n))) \nt_stat  \n\n[1] -0.6857474\n\n#Probability of this t-statistic  \np_val &lt;- pt(t_stat, n-1)*2 \np_val\n\n[1] 0.5233677"
  },
  {
    "objectID": "slides/lec-6_mean.html#make-a-decision",
    "href": "slides/lec-6_mean.html#make-a-decision",
    "title": "Week 06: Comparing Means",
    "section": "Make a decision",
    "text": "Make a decision\nHypotheses:\n\n\\(H_0:\\) There is no difference in ratings of happiness between the rooms ( \\(\\mu = 0\\) )\n\\(H_1:\\) There is a difference in ratings of happiness between the rooms ( \\(\\mu \\neq 0\\) )\n\n\n\n\n\n\n\n\n\n\n\\(alpha\\)\n\\(t-crit\\)\n\\(t-statistic\\)\n\\(p-value\\)\n\n\n\n\n0.05\n\\(\\pm\\) -2.57\n-0.69\n0.52\n\n\n\nWhat can we conclude??"
  },
  {
    "objectID": "slides/lec-6_mean.html#lets-look-at-the-data",
    "href": "slides/lec-6_mean.html#lets-look-at-the-data",
    "title": "Week 06: Comparing Means",
    "section": "Let‚Äôs Look at the data",
    "text": "Let‚Äôs Look at the data\nResearch Question: Is there a difference between school nights and weekend nights for amount of time slept?\nOnly looking at the variables that we are potentially interested in:\n\nstate_school %&gt;%    \n  select(id, Gender, Ageyears, Sleep_Hours_Schoolnight, Sleep_Hours_Non_Schoolnight) %&gt;%    \n  head() #look at first few observations\n\n# A tibble: 6 √ó 5\n     id Gender Ageyears Sleep_Hours_Schoolnight Sleep_Hours_Non_Schoolnight\n  &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;                   &lt;dbl&gt;                       &lt;dbl&gt;\n1     1 Female       16                     8                            13\n2     2 Male         17                     8                             9\n3     3 Female       19                     8                             7\n4     4 Male         17                     8                             9\n5     5 Male         16                     8.5                           5\n6     6 Female       11                    11                            12"
  },
  {
    "objectID": "slides/lec-6_mean.html#doing-the-test-in-r-one-sample",
    "href": "slides/lec-6_mean.html#doing-the-test-in-r-one-sample",
    "title": "Week 06: Comparing Means",
    "section": "Doing the test in R: One Sample",
    "text": "Doing the test in R: One Sample\nSince we have calculated the difference scores, we can basically just do a one-sample t-test with the lsr library\n\noneSampleTTest(sleep_state_school$sleep_diff, mu = 0)\n\n\n   One sample t-test \n\nData variable:   sleep_state_school$sleep_diff \n\nDescriptive statistics: \n            sleep_diff\n   mean         -1.866\n   std dev.      2.741\n\nHypotheses: \n   null:        population mean equals 0 \n   alternative: population mean not equal to 0 \n\nTest results: \n   t-statistic:  -9.106 \n   degrees of freedom:  178 \n   p-value:  &lt;.001 \n\nOther information: \n   two-sided 95% confidence interval:  [-2.27, -1.462] \n   estimated effect size (Cohen's d):  0.681"
  },
  {
    "objectID": "slides/lec-6_mean.html#doing-the-test-in-r-paired-sample",
    "href": "slides/lec-6_mean.html#doing-the-test-in-r-paired-sample",
    "title": "Week 06: Comparing Means",
    "section": "Doing the test in R: Paired Sample",
    "text": "Doing the test in R: Paired Sample\nMaybe we want to keep things separate and don‚Äôt want to calculate separate values. We can use pairedSamplesTTest() instead!\nBut this isn‚Äôt working and is making me mad‚Ä¶\n\nlsr::pairedSamplesTTest(\n  formula = ~ Sleep_Hours_Schoolnight + Sleep_Hours_Non_Schoolnight,\n  data = sleep_state_school\n)"
  },
  {
    "objectID": "slides/lec-6_mean.html#doing-the-test-in-r-classic-edition",
    "href": "slides/lec-6_mean.html#doing-the-test-in-r-classic-edition",
    "title": "Week 06: Comparing Means",
    "section": "Doing the test in R: Classic Edition",
    "text": "Doing the test in R: Classic Edition\nAs you Google around to figure things out, you will likely see folks using t.test()\n\nt.test(x = sleep_state_school$Sleep_Hours_Schoolnight,    \n       y = sleep_state_school$Sleep_Hours_Non_Schoolnight,\n       paired = TRUE )\n\n\n    Paired t-test\n\ndata:  sleep_state_school$Sleep_Hours_Schoolnight and sleep_state_school$Sleep_Hours_Non_Schoolnight\nt = -9.1062, df = 178, p-value &lt; 0.00000000000000022\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.270281 -1.461563\nsample estimates:\nmean difference \n      -1.865922"
  },
  {
    "objectID": "slides/lec-6_mean.html#reporting-t-test",
    "href": "slides/lec-6_mean.html#reporting-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Reporting \\(t\\)-test",
    "text": "Reporting \\(t\\)-test\nThe first sentence usually conveys some descriptive information about the sample you were comparing (e.g., pre & post test).\nThen you identify the type of test you conducted and what was determined (be sure to include the ‚Äústat block‚Äù here as well with the t-statistic, df, p-value, CI and Effect size).\nFinish it up by putting that into person words and saying what that means."
  },
  {
    "objectID": "slides/lec-6_mean.html#what-is-anova-lsr-ch.-14",
    "href": "slides/lec-6_mean.html#what-is-anova-lsr-ch.-14",
    "title": "Week 06: Comparing Means",
    "section": "What is ANOVA? (LSR Ch. 14)",
    "text": "What is ANOVA? (LSR Ch. 14)\n\nANOVA stands for Analysis of Variance\nComparing means between two or more groups (usually 3 or more)\n\nContinuous outcome and grouping variable with 2 or more levels\n\nUnder the larger umbrella of general linear models\n\nANOVA is basically a regression with only categorical predictors\n\nLikely the most widely used tool in Psychology"
  },
  {
    "objectID": "slides/lec-6_mean.html#different-types-of-anova",
    "href": "slides/lec-6_mean.html#different-types-of-anova",
    "title": "Week 06: Comparing Means",
    "section": "Different Types of ANOVA",
    "text": "Different Types of ANOVA\n\n\nOne-Way ANOVA\n\nTwo-Way ANOVA\nRepeated Measures ANOVA\nANCOVA\nMANOVA"
  },
  {
    "objectID": "slides/lec-6_mean.html#one-way-anova",
    "href": "slides/lec-6_mean.html#one-way-anova",
    "title": "Week 06: Comparing Means",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\nGoal: Inform of differences among the levels of our variable of interest (Omnibus Test)\n\nBut cannot tell us more than that‚Ä¶\n\nHypotheses:\n\\[ H_0: it\\: is\\: true\\: that\\: \\mu_1 = \\mu_2 = \\mu_3 =\\: ...\\mu_k  \\\\  H_1: it\\: is\\: \\boldsymbol{not}\\: true\\: that\\: \\mu_1 = \\mu_2 = \\mu_3 =\\: ...\\mu_k \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#waitmeans-or-variance",
    "href": "slides/lec-6_mean.html#waitmeans-or-variance",
    "title": "Week 06: Comparing Means",
    "section": "Wait‚Ä¶Means or Variance?",
    "text": "Wait‚Ä¶Means or Variance?\nWe are using the variance to create a ratio (within group versus between group variance) to determine differences in means\n\nWe are not directly investigating variance, but operationalize variance to create the ratio:\n\n\\[ F_{df_b, \\: df_w} = \\frac{MS_{between}}{MS_{within}} \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#anova-assumptions",
    "href": "slides/lec-6_mean.html#anova-assumptions",
    "title": "Week 06: Comparing Means",
    "section": "ANOVA: Assumptions",
    "text": "ANOVA: Assumptions\n\nIndependence\n\nObservations between and within groups should be independent. No autocorrelation\n\nHomogeneity of Variance\n\nThe variances within each group should be roughly equal\n\nLevene‚Äôs test ‚Äì&gt; Welch‚Äôs ANOVA for unequal variances\n\n\nNormality\n\nThe data within each group should follow a normal distribution\n\nShapiro-Wilk test ‚Äì&gt; can transform the data or use non-parametric tests"
  },
  {
    "objectID": "slides/lec-6_mean.html#review-of-the-nhst-process",
    "href": "slides/lec-6_mean.html#review-of-the-nhst-process",
    "title": "Week 06: Comparing Means",
    "section": "Review of the NHST process",
    "text": "Review of the NHST process\n\nCollect Sample and define hypotheses\nSet alpha level\nDetermine the sampling distribution (will be using \\(F\\)-distribution now)\nIdentify the critical value\nCalculate test statistic for sample collected\nInspect & compare statistic to critical value; Calculate probability"
  },
  {
    "objectID": "slides/lec-6_mean.html#steps-to-calculating-f-ratio",
    "href": "slides/lec-6_mean.html#steps-to-calculating-f-ratio",
    "title": "Week 06: Comparing Means",
    "section": "Steps to calculating F-ratio",
    "text": "Steps to calculating F-ratio\n\nCapture variance both between and within groups\nVariance to Sum of Squares\nDegrees of Freedom\nMean squares values\nF-Statistic"
  },
  {
    "objectID": "slides/lec-6_mean.html#capturing-variance",
    "href": "slides/lec-6_mean.html#capturing-variance",
    "title": "Week 06: Comparing Means",
    "section": "Capturing Variance",
    "text": "Capturing Variance\nWe have calculated variance before!\n\\[ Var = \\frac{1}{N}\\sum(x_i - \\bar{x})^2 \\]\nNow we have to take into account the variance between and within the groups:\n\\[ Var(Y) = \\frac{1}{N} \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y})^2 \\]\n\nNotice that we have the summation across each group ( \\(G\\) ) and the person in the group ( \\(N_k\\) )"
  },
  {
    "objectID": "slides/lec-6_mean.html#variance-to-sum-of-squares",
    "href": "slides/lec-6_mean.html#variance-to-sum-of-squares",
    "title": "Week 06: Comparing Means",
    "section": "Variance to Sum of Squares",
    "text": "Variance to Sum of Squares\nTotal Sum of Squares - Adding up the sum of squares instead of getting the average (notice the removal of \\(\\frac{1}{N}\\))\n\\[ SS_{total} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y})^2 \\]\nCan be broken up to see what is the variation between the groups AND the variation within the groups\n\\[ SS_{total}=SS_{between}+SS_{within} \\]\n\nThis gets us closer to understanding the difference between means"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---between",
    "href": "slides/lec-6_mean.html#sum-of-squares---between",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Between",
    "text": "Sum of Squares - Between\nThe difference between the group mean and grand mean\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 \\]\n\n\n\nGroup\nGroup Mean \\(\\bar{Y_k}\\)\nGrand Mean \\(\\bar{Y}\\)\n\n\n\n\nCool\n32\n41.8\n\n\nUncool\n56.5\n41.8"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---between-1",
    "href": "slides/lec-6_mean.html#sum-of-squares---between-1",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Between",
    "text": "Sum of Squares - Between\nThe difference between the group mean and grand mean\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 \\]\n\n\n\n\n\n\n\n\n\n\n\nGroup\nGroup Mean \\(\\bar{Y_k}\\)\nGrand Mean \\(\\bar{Y}\\)\nSq. Dev.\nN\nWeighted Sq. Dev.\n\n\n\n\nCool\n32\n41.8\n96.04\n3\n288.12\n\n\nUncool\n56.5\n41.8\n216.09\n2\n432.18"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---between-2",
    "href": "slides/lec-6_mean.html#sum-of-squares---between-2",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Between",
    "text": "Sum of Squares - Between\nThe difference between the group mean and grand mean\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 \\]\nNow we can sum the Weighted Squared Deviations together to get our Sum of Squares Between:\n\nssb &lt;- 288.12 + 432.18 \nssb\n\n[1] 720.3"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---within",
    "href": "slides/lec-6_mean.html#sum-of-squares---within",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Within",
    "text": "Sum of Squares - Within\nThe difference between the individual and their group mean\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 \\]\n\n\n\nName\nGrumpiness \\(Y_{ik}\\)\nGroup Mean \\(\\bar{Y_K}\\)\n\n\n\n\nFrodo\n20\n32\n\n\nSam\n55\n32\n\n\nBandit\n21\n32\n\n\nDolores U.\n91\n56.5\n\n\nDustin\n22\n56.5"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---within-1",
    "href": "slides/lec-6_mean.html#sum-of-squares---within-1",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Within",
    "text": "Sum of Squares - Within\nThe difference between the individual and their group mean\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 \\]\n\n\n\nName\nGrumpiness \\(Y_{ik}\\)\nGroup Mean \\(\\bar{Y_K}\\)\nSq. Dev\n\n\n\n\nFrodo\n20\n32\n144\n\n\nSam\n55\n32\n529\n\n\nBandit\n21\n32\n121\n\n\nDolores U.\n91\n56.5\n1190.25\n\n\nDustin\n22\n56.5\n1190.25\n\n\n\n\n\nCode\nscore &lt;- c(20, 55, 21, 91, 22) \ngroup_m &lt;- c(32, 32, 32, 56.5, 56.5) \nsq_dev &lt;- (score - group_m)^2"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---within-2",
    "href": "slides/lec-6_mean.html#sum-of-squares---within-2",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Within",
    "text": "Sum of Squares - Within\nThe difference between the individual and their group mean\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 \\] Now we can sum the Squared Deviations together to get our Sum of Squares Within:\n\nsum(sq_dev)\n\n[1] 3174.5"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares-2",
    "href": "slides/lec-6_mean.html#sum-of-squares-2",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares",
    "text": "Sum of Squares\nCan start to have an idea of what this looks like\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 = 720.3 \\]\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 = 3174.5 \\]\nNext we have to take into account the degrees of freedom"
  },
  {
    "objectID": "slides/lec-6_mean.html#degrees-of-freedom",
    "href": "slides/lec-6_mean.html#degrees-of-freedom",
    "title": "Week 06: Comparing Means",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nSince we have 2 types of variations that we are examining, this needs to be reflected in the degrees of freedom\n\nTake the number of groups and subtract 1\n\\(df_{between} = G - 1\\)\nTake the total number of observations and subtract the number of groups\n\\(df_{within} = N - G\\)"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-mean-squares",
    "href": "slides/lec-6_mean.html#calculating-mean-squares",
    "title": "Week 06: Comparing Means",
    "section": "Calculating Mean Squares",
    "text": "Calculating Mean Squares\nNext we convert our summed squares value into a ‚Äúmean squares‚Äù\nThis is done by dividing by the respective degrees of freedom\n\\[ MS_b = \\frac{SS_b}{df_b} \\]\n\\[ MS_W = \\frac{SS_w}{df_w} \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-mean-squares---example",
    "href": "slides/lec-6_mean.html#calculating-mean-squares---example",
    "title": "Week 06: Comparing Means",
    "section": "Calculating Mean Squares - Example",
    "text": "Calculating Mean Squares - Example\nLet‚Äôs take a look at how this applies to our example: \\[ MS_b = \\frac{SS_b}{G-1} = \\frac{720.3}{2-1} = 720.3 \\]\n\\[ MS_W = \\frac{SS_w}{N-G} = \\frac{3174.5}{5-2} = 1058.167  \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-the-f-statistic",
    "href": "slides/lec-6_mean.html#calculating-the-f-statistic",
    "title": "Week 06: Comparing Means",
    "section": "Calculating the F-Statistic",
    "text": "Calculating the F-Statistic\n\\[F = \\frac{MS_b}{MS_w}\\]\nIf the null hypothesis is true, \\(F\\) has an expected value close to 1 (numerator and denominator are estimates of the same variability)\nIf it is false, the numerator will likely be larger, because systematic, between-group differences contribute to the variance of the means, but not to variance within group."
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-f-statistic-example",
    "href": "slides/lec-6_mean.html#calculating-f-statistic-example",
    "title": "Week 06: Comparing Means",
    "section": "Calculating F-statistic: Example",
    "text": "Calculating F-statistic: Example\n\\[F = \\frac{MS_b}{MS_w} = \\frac{720.3}{1058.167} = 0.68\\]\nLink to probability calculator"
  },
  {
    "objectID": "slides/lec-6_mean.html#contrastspost-hoc-tests",
    "href": "slides/lec-6_mean.html#contrastspost-hoc-tests",
    "title": "Week 06: Comparing Means",
    "section": "Contrasts/Post-Hoc Tests",
    "text": "Contrasts/Post-Hoc Tests\nPerformed when there is a significant difference among the groups to examine which groups are different\n\nContrasts: When we have a priori hypotheses\nPost-hoc Tests: When we want to test everything"
  },
  {
    "objectID": "slides/lec-6_mean.html#tables",
    "href": "slides/lec-6_mean.html#tables",
    "title": "Week 06: Comparing Means",
    "section": "Tables",
    "text": "Tables\nOften times the output will be in the form of a table and then it is often reported this way in the manuscript\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\ndf\nSum of Squares\nMean Squares\nF-statistic\np-value\n\n\n\n\nGroup\n\\(G-1\\)\n\\(SS_b\\)\n\\(MS_b = \\frac{SS_b}{df_b}\\)\n\\(F = \\frac{MS_b}{MS_w}\\)\n\\(p\\)\n\n\nResidual\n\\(N-G\\)\n\\(SS_w\\)\n\\(MS_w = \\frac{SS_w}{df_w}\\)\n\n\n\n\nTotal\n\\(N-1\\)\n\\(SS_{total}\\)"
  },
  {
    "objectID": "slides/lec-6_mean.html#in-text",
    "href": "slides/lec-6_mean.html#in-text",
    "title": "Week 06: Comparing Means",
    "section": "In-Text",
    "text": "In-Text\n\nA one-way analysis of variance was used to test for differences in the [variable of interest/outcome variable] as a function of [whatever the factor is]. Specifically, differences in [variable of interest] were assessed for the [list different levels and be sure to include (M= , SD= )] . The one-way ANOVA revealed a significant/nonsignificant effect of [factor] on scores on the [variable of interest] (F(dfb, dfw) = f-ratio, p = p-value, Œ∑2 = effect size).\nPlanned comparisons were conducted to compare expected differences among the [however many groups] means. Planned contrasts revealed that participants in the [one of the conditions] had a greater/fewer [variable of interest] and then include the p-value. This same type of sentence is repeated for whichever contrasts you completed. Descriptive statistics were reported in Table 1."
  },
  {
    "objectID": "slides/lec-6_mean.html#books-by-marital-status",
    "href": "slides/lec-6_mean.html#books-by-marital-status",
    "title": "Week 06: Comparing Means",
    "section": "Books by Marital Status",
    "text": "Books by Marital Status\nWe can examine how many books (continuous) by marital status (7 categories: Married, Divorced, In a relationship, Other, Separated, Widowed, Single)\nVISUALIZE!\n\nggbetweenstats(\n  data  = cah,\n  x     = marital_status,\n  y     = books,\n  title = \"Distribution of books across marital status\"\n)"
  },
  {
    "objectID": "slides/lec-6_mean.html#family-wise-error",
    "href": "slides/lec-6_mean.html#family-wise-error",
    "title": "Week 06: Comparing Means",
    "section": "Family-wise error",
    "text": "Family-wise error\nThese pairwise comparisons can quickly grow in number as the number of Groups increases. With 3 (k) Groups, we have k(k-1)/2 = 3 possible pairwise comparisons.\nAs the number of groups in the ANOVA grows, the number of possible pairwise comparisons increases dramatically."
  },
  {
    "objectID": "slides/lec-6_mean.html#what-is-a-two-way-anova",
    "href": "slides/lec-6_mean.html#what-is-a-two-way-anova",
    "title": "Week 06: Comparing Means",
    "section": "What is a Two-Way ANOVA?",
    "text": "What is a Two-Way ANOVA?\nExamines the impact of 2 nominal/categorical variables on a continuous outcome\nWe can now examine:\n\nThe impact of variable 1 on the outcome (Main Effect)\nThe impact of variable 2 on the outcome (Main Effect)\nThe interaction¬†of variable 1 & 2 on the outcome (Interaction Effect)\n\nThe effect of variable 1 depends on the level of variable 2"
  },
  {
    "objectID": "slides/lec-6_mean.html#main-effect-interactions",
    "href": "slides/lec-6_mean.html#main-effect-interactions",
    "title": "Week 06: Comparing Means",
    "section": "Main Effect & Interactions",
    "text": "Main Effect & Interactions\nMain Effect: Basically a one-way ANOVA\n\nThe effect of variable 1 is the same across all levels of variable 2\n\nInteraction:\n\nAble to examine the effect of variable 1 across different levels of variable 2\nBasically speaking, the effect of variable 1 on our outcome DEPENDS on the levels of variable 2"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#from-squirrels-to-significance-a-guide-to-research-design-inference",
    "href": "slides/lec-4_design-inference.html#from-squirrels-to-significance-a-guide-to-research-design-inference",
    "title": "Week 04: Design & Inference",
    "section": "From Squirrels to Significance: A Guide to Research Design & Inference",
    "text": "From Squirrels to Significance: A Guide to Research Design & Inference\nWeek 4"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-core-challenge",
    "href": "slides/lec-4_design-inference.html#the-core-challenge",
    "title": "Week 04: Design & Inference",
    "section": "The Core Challenge",
    "text": "The Core Challenge\n\nLast week: We learned to describe and visualize patterns in our sample.\nThe Rest of the Course: We want to make claims about the population.\nThe Problem: How do we know if a pattern we see in our sample (e.g., a difference between groups) is a ‚Äúreal‚Äù effect or just random sampling error?\nThe Solution: We build a statistical model to test our question against the backdrop of randomness."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-journey-of-a-research-question",
    "href": "slides/lec-4_design-inference.html#the-journey-of-a-research-question",
    "title": "Week 04: Design & Inference",
    "section": "The Journey of a Research Question",
    "text": "The Journey of a Research Question\n\nAll research starts with a question about the world.\nBut how do we get from a messy, real-world question to a clean, statistical answer?\n\nOur Journey Today:\n\nPart 1: From Concept to Data (How do we measure what we care about?)\nPart 2: The Blueprint for Claims (How do we structure our study?)\nPart 3: From Design to Model (How do we analyze our data?)"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-first-most-important-choice",
    "href": "slides/lec-4_design-inference.html#the-first-most-important-choice",
    "title": "Week 04: Design & Inference",
    "section": "The First & Most Important Choice",
    "text": "The First & Most Important Choice\n\nBefore we can analyze anything, we need data. This means turning an abstract concept into a concrete, measurable variable.\nThis process is called operationalization.\nYour operationalization is your argument for what a concept means in the context of your study."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-squirrel-gang",
    "href": "slides/lec-4_design-inference.html#the-squirrel-gang",
    "title": "Week 04: Design & Inference",
    "section": "The Squirrel Gang",
    "text": "The Squirrel Gang\nLet‚Äôs imagine a new study. Our research question is:\nDoes being aggressively attacked by a campus squirrel for your sandwich increase a student‚Äôs acute stress?\n\nPredictor: squirrel_incident (Attacked vs.¬†Not Attacked).\nOutcome: acute_stress.\n\nBut what is ‚Äúacute stress‚Äù? As the researcher, how do you measure it?\n\n\n\nTurn to the person/people next to you and identify how you would define and measure ‚Äústress‚Äù."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#how-would-you-measure-stress",
    "href": "slides/lec-4_design-inference.html#how-would-you-measure-stress",
    "title": "Week 04: Design & Inference",
    "section": "How Would You Measure ‚ÄúStress‚Äù?",
    "text": "How Would You Measure ‚ÄúStress‚Äù?\n\n\n\n\n\n\n\n\n\nMethod of Measurement\nHow It Works\nData Generated\nWhat It Really Measures\n\n\nSubjective Self-Report\n‚ÄúOn a scale of 0-100, how stressed do you feel right now?‚Äù\nContinuous (0-100)\nThe feeling of stress.\n\n\nAutonomic Arousal\nMeasure heart rate in beats per minute (BPM).\nContinuous (e.g., 115 BPM)\nThe body‚Äôs alarm for stress.\n\n\nCognitive Impairment\n‚ÄúCount backward from 1,084 by 7s.‚Äù Measure speed & accuracy.\nContinuous (# of errors)\nThe brain‚Äôs processing under stress.\n\n\nCoded Facial Expression\nAnalyze video for micro-expressions of fear or anger.\nCategorical or Ordinal\nThe face‚Äôs expression of stress."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-two-big-claims",
    "href": "slides/lec-4_design-inference.html#the-two-big-claims",
    "title": "Week 04: Design & Inference",
    "section": "The Two Big Claims",
    "text": "The Two Big Claims\nNow that we know what we‚Äôre measuring, let‚Äôs talk about how we structure the study. Your design determines the kind of claim you can make.\n\nAn Associational Claim: Two variables are related.\n\n‚ÄúPeople who experience squirrel attacks tend to report higher stress.‚Äù\n\nA Causal Claim: A change in one variable causes a change in another.\n\n‚ÄúThe experience of a squirrel attack causes an increase in stress.‚Äù"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-3-rules-of-causality",
    "href": "slides/lec-4_design-inference.html#the-3-rules-of-causality",
    "title": "Week 04: Design & Inference",
    "section": "The 3 Rules of Causality",
    "text": "The 3 Rules of Causality\nTo earn the right to say ‚ÄúX causes Y,‚Äù you must demonstrate three things:\n\nCovariance: X and Y are related.\nTemporal Precedence: The cause (X) must happen before the effect (Y).\nInternal Validity: There are no other plausible explanations (we‚Äôve ruled out confounds)."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-confounding-variable-problem",
    "href": "slides/lec-4_design-inference.html#the-confounding-variable-problem",
    "title": "Week 04: Design & Inference",
    "section": "The Confounding Variable Problem",
    "text": "The Confounding Variable Problem\nA confound is a ‚Äúthird variable‚Äù that creates a spurious relationship between your two variables. This is the #1 threat to causal claims.\n\nClassic Example: Ice cream sales are positively correlated with drowning deaths.\nThe Confound: Summer heat! Hot weather causes both more ice cream sales and more swimming."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-gold-standard-for-defeating-confounds-the-experiment",
    "href": "slides/lec-4_design-inference.html#the-gold-standard-for-defeating-confounds-the-experiment",
    "title": "Week 04: Design & Inference",
    "section": "The Gold Standard for Defeating Confounds: The Experiment",
    "text": "The Gold Standard for Defeating Confounds: The Experiment\nA True Experiment is the most powerful tool for establishing causality. It has two magic ingredients:\n\nManipulation: The researcher actively manipulates the Independent Variable (IV).\nRandom Assignment: Every participant has an equal chance of being in any condition. This breaks the links to potential confounds by distributing them evenly across groups."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#key-design-dimensions",
    "href": "slides/lec-4_design-inference.html#key-design-dimensions",
    "title": "Week 04: Design & Inference",
    "section": "Key Design Dimensions",
    "text": "Key Design Dimensions\n\nBetween-Subjects: Different groups of people get different conditions. We compare Group A vs.¬†Group B.\nWithin-Subjects: The same group of people experiences all conditions. We compare people to themselves.\nCross-Sectional: All data is collected at a single point in time. (Fails temporal precedence).\nLongitudinal: Data is collected from the same people over multiple time points. (Establishes temporal precedence)."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#descriptives-vs.-inference",
    "href": "slides/lec-4_design-inference.html#descriptives-vs.-inference",
    "title": "Week 04: Design & Inference",
    "section": "Descriptives vs.¬†Inference",
    "text": "Descriptives vs.¬†Inference\n\n\nMoving from simply describing our data\nWith means and standard deviations\n\nTo drawing conclusions about the population\nUsing inferential statistics"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#probability---understanding-randomness",
    "href": "slides/lec-4_design-inference.html#probability---understanding-randomness",
    "title": "Week 04: Design & Inference",
    "section": "Probability - Understanding Randomness",
    "text": "Probability - Understanding Randomness\nThere are several possible interpretations of probability but they (almost) completely agree on the mathematical rules probability must follow:\n\\(P(A)\\) = Probablity of event A\n0 ‚â§ \\(P(A)\\) ‚â§ 1"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-law-of-large-numbers",
    "href": "slides/lec-4_design-inference.html#the-law-of-large-numbers",
    "title": "Week 04: Design & Inference",
    "section": "The Law of Large Numbers",
    "text": "The Law of Large Numbers\nAs more observations are collected, the proportion of occurrences with a particular outcome, \\(pÃÇ_n\\), converges to the probability of that outcome, \\(p\\).\nExample:\n\nAs the sample size increases, the sample mean tends to get closer to the population mean\nAnd as the sample size approaches infinity ‚ôæÔ∏è, the sample mean approaches the population mean"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#statistics-probability-inference",
    "href": "slides/lec-4_design-inference.html#statistics-probability-inference",
    "title": "Week 04: Design & Inference",
    "section": "Statistics, Probability & Inference",
    "text": "Statistics, Probability & Inference\n\nThink about seeing statistics posted on the news\n\nOften times polling companies survey a large sample to then make a statement about the population\n\nWe assume the sample is representative of the larger population, but how representative?\n\nThis is where probability theory comes in\n\nProbability theory provides tools to assess how likely sample results are if they differ from the true population parameter"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#role-of-probability-theory",
    "href": "slides/lec-4_design-inference.html#role-of-probability-theory",
    "title": "Week 04: Design & Inference",
    "section": "Role of Probability Theory",
    "text": "Role of Probability Theory"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#probability---the-2-main-realms",
    "href": "slides/lec-4_design-inference.html#probability---the-2-main-realms",
    "title": "Week 04: Design & Inference",
    "section": "Probability - The 2 main realms",
    "text": "Probability - The 2 main realms\n\n\nFrequentist\nProbability is a long-run frequency of an event\n\nBayesian\nProbability of an event as the degree of belief"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-universal-language-of-models",
    "href": "slides/lec-4_design-inference.html#the-universal-language-of-models",
    "title": "Week 04: Design & Inference",
    "section": "The Universal Language of Models",
    "text": "The Universal Language of Models\n\nYour measurement and design choices create the blueprint for your analysis. They lead you directly to the correct statistical model.\nAll models we learn this semester can be expressed in R with a simple formula:\n\nOutcome ~ Predictor"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#a-decision-tree-for-your-model",
    "href": "slides/lec-4_design-inference.html#a-decision-tree-for-your-model",
    "title": "Week 04: Design & Inference",
    "section": "A Decision Tree for Your Model üå≥",
    "text": "A Decision Tree for Your Model üå≥\n\n\nIf your goal is to‚Ä¶ COMPARE GROUPS:\n\nPredictor (IV) is Categorical\nOutcome (DV) is Continuous\nüëâ You are in the t-test / ANOVA family of models.\nThe model looks like: Continuous_Outcome ~ Categorical_Predictor\n\n\nIf your goal is to‚Ä¶ ASSESS AN ASSOCIATION:\n\nPredictor (IV) is Continuous\nOutcome (DV) is Continuous\nüëâ You are in the Correlation / Regression family of models.\nThe model looks like: Continuous_Outcome ~ Continuous_Predictor"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#data-to-models-to-inference-nhst",
    "href": "slides/lec-4_design-inference.html#data-to-models-to-inference-nhst",
    "title": "Week 04: Design & Inference",
    "section": "Data to Models to Inference (NHST)",
    "text": "Data to Models to Inference (NHST)\nSo we have a model, like: depression_score ~ therapy_group. How do we test it?\nWe use the Null Hypothesis Significance Testing (NHST) framework:\n\nThe Null Hypothesis \\(H_0\\) : A statement that the predictor has no relationship with the outcome in the population. It is the ‚Äúnull model.‚Äù\n\n\\(H_0\\) : In the population, there is no difference in depression scores between the therapy and control groups. therapy_group does not predict depression_score.\n\nThe Alternative Hypothesis \\(H_A\\) : Our research hypothesis. The predictor does have a relationship with the outcome.\n\n\\(H_A\\) : In the population, there is a difference. therapy_group does predict depression_score."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-p-value",
    "href": "slides/lec-4_design-inference.html#the-p-value",
    "title": "Week 04: Design & Inference",
    "section": "The p-value",
    "text": "The p-value\nThe p-value tells us how surprising our sample data would be if the null hypothesis (the ‚Äúno relationship‚Äù model) were true for the population.\nIt‚Äôs a measure of the incompatibility between our data and the null model.\n\nA small p-value (p&lt;.05) suggests that our data are incompatible with the null model. We have evidence to reject the null model and conclude that our predictor is likely related to the outcome.\n\nThe statistical test you run (t.test, cor.test, lm) is just the engine that calculates the p-value for your specific model. The logic is always the same."
  },
  {
    "objectID": "slides/template-seasons.html#quarto",
    "href": "slides/template-seasons.html#quarto",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets",
    "href": "slides/template-seasons.html#bullets",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations",
    "href": "slides/template-seasons.html#latex-equations",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables",
    "href": "slides/template-seasons.html#tables",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks",
    "href": "slides/template-seasons.html#callout-blocks",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-1",
    "href": "slides/template-seasons.html#quarto-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-1",
    "href": "slides/template-seasons.html#bullets-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-1",
    "href": "slides/template-seasons.html#latex-equations-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-1",
    "href": "slides/template-seasons.html#tables-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-1",
    "href": "slides/template-seasons.html#callout-blocks-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-2",
    "href": "slides/template-seasons.html#quarto-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-2",
    "href": "slides/template-seasons.html#bullets-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-2",
    "href": "slides/template-seasons.html#latex-equations-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-2",
    "href": "slides/template-seasons.html#tables-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-2",
    "href": "slides/template-seasons.html#callout-blocks-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-3",
    "href": "slides/template-seasons.html#quarto-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-3",
    "href": "slides/template-seasons.html#bullets-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-3",
    "href": "slides/template-seasons.html#latex-equations-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-3",
    "href": "slides/template-seasons.html#tables-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-3",
    "href": "slides/template-seasons.html#callout-blocks-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/lec-1_syl.html#scheduleplan",
    "href": "slides/lec-1_syl.html#scheduleplan",
    "title": "Week 01: Getting Started!",
    "section": "Schedule/Plan",
    "text": "Schedule/Plan\n\n\n\n\n\n\n\n8 - 8:45\nGet oriented. Go over syllabus. Explain course structure. Do all that fun stuff.\n\n\n8:45 - 9ish\nBreak\n\n\n9ish - 10:00\nLive Demo in R\n\n\n10 - 10:50\nGet comfortable with R"
  },
  {
    "objectID": "slides/lec-1_syl.html#when-the-teaching-happens",
    "href": "slides/lec-1_syl.html#when-the-teaching-happens",
    "title": "Week 01: Getting Started!",
    "section": "When the Teaching Happens",
    "text": "When the Teaching Happens\nüíæ Meeting Times: Monday‚Äôs 8:00 - 10:50am\nüßë‚Äçüè´ Drop in Office Hours: Wednesdays 9 - 11:00 am\nüìß Best way to contact me? Email me. I will usually respond within 24 hours. If it has been longer, then you can send me a follow-up\n\n\n\n\n\n\nNote\n\n\nI just figured out how to easily put emojis into the presentation. I‚Äôm sorry that you will have to witness that."
  },
  {
    "objectID": "slides/lec-1_syl.html#communication",
    "href": "slides/lec-1_syl.html#communication",
    "title": "Week 01: Getting Started!",
    "section": "Communication",
    "text": "Communication\nPlease ask questions! üôã‚Äç‚ôÄÔ∏è\nIf you are having trouble, just ask!!\nBe open and honest with me and I will do what I can to support you."
  },
  {
    "objectID": "slides/lec-1_syl.html#who-the-heck-am-i",
    "href": "slides/lec-1_syl.html#who-the-heck-am-i",
    "title": "Week 01: Getting Started!",
    "section": "Who the heck am I? ü§∑",
    "text": "Who the heck am I? ü§∑\n\nUndergraduate degree at University of Denver\n\nPsychology & Philosophy\nHated Statistics\n\nGraduate degree at University of Illinois at Urbana-Champaign\n\nAdvisor: Dr.¬†Benjamin Hankin\nClinical/Community PhD üéì\n\nPre-Doctoral Internship & Postdoc at Rochester Institute of Technology"
  },
  {
    "objectID": "slides/lec-1_syl.html#a-little-more-about-me",
    "href": "slides/lec-1_syl.html#a-little-more-about-me",
    "title": "Week 01: Getting Started!",
    "section": "A little more about me",
    "text": "A little more about me\n\nPronouns: he/him/his\n2 amazing kids, 2 dogs (Dachshund and Shepherd Mix), 1 wife\nCurrently Reading: Dungeon Crawler Carl\nCurrently Listening: The Lonely Island & Seth Meyers Podcast\nCurrently Watching: Wednesday, Bluey, Hot Wheels - Let‚Äôs Race"
  },
  {
    "objectID": "slides/lec-1_syl.html#teaching-philosophy",
    "href": "slides/lec-1_syl.html#teaching-philosophy",
    "title": "Week 01: Getting Started!",
    "section": "Teaching Philosophy",
    "text": "Teaching Philosophy\n\nI‚Äôm here for you and to support you however I can\nMy job is to create a supportive, low-stakes environment where you can crash test ideas and develop new skills\nYour responsibility is to come to class prepared, ready to have fun, take some risks, and actively participate!\n\nAsk questions, share relevant funny stories, seek clarification, question the status quo where applicable\n\nScience is a team sport & failures/mistakes will happen, but it is okay! That‚Äôs what science and discovery is!"
  },
  {
    "objectID": "slides/lec-1_syl.html#class-materials",
    "href": "slides/lec-1_syl.html#class-materials",
    "title": "Week 01: Getting Started!",
    "section": "Class Materials",
    "text": "Class Materials\nI‚Äôve pulled from a lot of different textbooks. Good thing is, they are all free!\n\nIntroduction to Modern Statistics (2e) (Cetinkaya-Rundel & Hardin, 2024)\nLearning Statistics with R (Navarro)\nR for Data Science (2e) (Wickham, √áetinkaya-Rundel, & Grolemund, 2023)\nModern Statistics with R (2e) (Thullin, 2025)\nStatistical Thinking (Poldrack, 2024)\nAn Introduction to Statistical Learning (2e) (James, Witten, Hastie & Tibshirani, 2023)\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) (Judd, McClelland, & Ryan, 2017)"
  },
  {
    "objectID": "slides/lec-1_syl.html#evaluation-grading",
    "href": "slides/lec-1_syl.html#evaluation-grading",
    "title": "Week 01: Getting Started!",
    "section": "Evaluation & Grading",
    "text": "Evaluation & Grading\n\n\n\nComponent\nWeight\n\n\nWeekly Labs\n30%\n\n\nJournal Entries\n10%\n\n\nParticipation & Engagement\n15%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n25%"
  },
  {
    "objectID": "slides/lec-1_syl.html#course-policies",
    "href": "slides/lec-1_syl.html#course-policies",
    "title": "Week 01: Getting Started!",
    "section": "Course Policies",
    "text": "Course Policies\n\nAccommodations\nSafety\nAcademic Integrity"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "PSYC 640: Graduate Statistics",
    "section": "",
    "text": "This course is the introduction to statistics for graduate students. The goal of the course is to provide a grounding in statistical concepts, methods and application to research. I aim to increase student‚Äôs confidence in using these techniques and introducing them to R. Topics will range from including mathematical conceptualizations to practical application with various techniques ranging from descriptive statistics to regression.\n\nWhat it feels like when you read you are going to learn R:\n\n\n\nWhat it is actually like:\n\nIllustration credit: Allison Horst (https://allisonhorst.com/allison-horst)",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "class-activities/wk5_cor.html",
    "href": "class-activities/wk5_cor.html",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "Goal: Work individually or in small groups to apply the concepts from today‚Äôs lecture and demo to a new dataset.\n\n\n\nIdentify predictor and outcome variables from a research question.\nCreate an appropriate visualization (ggplot).\nRun the correct statistical test and report the appropriate results.\n\n\n\n\nWe have data of personality traits, as measured by the Ten Item Personality Inventory, and self-reported aspects of sleep (# of hours slept on average & overall sleep quality), as well as some demographic variables. The administration is asking how different personality traits are related to sleep quality.\nDownload Week 5 Class Activity (.csv)\nPlease download the TIPI_Data.csv file (above). It contains the following variables of interest:\n\nID: A unique identifier for each participant.\nage: The participants reported age in years\nTIPI_1 - TIPI_10: The ratings on each item of the Ten Item Personality inventory. Even items need to be reverse scored (scale goes from 1 to 7). Scores for each personality index are from the mean of their respective items.\n\nExtraversion: 1 & 6; Agreeableness: 2 & 7; Conscientiousness: 3 & 8; Emotional Stability: 4 & 9; Openness to Experiences: 5 & 10\n\nSleep Quality: Scale from 1-5 with higher scores indicating better sleep quality\nHours of Sleep: Score that represents a range.\n\n0-3 hours = 1; 3-6 hours = 5; 6-9 hours = 7; 9+ hours = 8\n\n\n\n\n\n\nCreate a new R Markdown file titled week5_inclass.Rmd.\nLoad the appropriate libraries.\nLoad the TIPI_Data.csv dataset.\nFor each task below, write the R code and answer the questions.\n\n\n\n\nHow might you identify ‚Äúvalid‚Äù responses? Based on the information in the dataset, what may be variables that you may want to examine more closely? (You don‚Äôt have to do the coding for this, just answer conceptually).\nReverse code items of the TIPI\nCreate the total scores for each subscale of the TIPI\n\n\n\n\nCreate a correlation table of the subscales of the TIPI, Sleep Quality and Sleep hours. Be sure to have it include associated p-values.\nHow are you handling missing values and why?\n\n\n\nSelect one pair of variables to further examine the correlation. You must include only one subscale of the TIPI. Why did you decide these variables? (due to significance? Or effect size?)\nGenerate a scatterplot with your variables and add a fit line. Be sure to include a title, and legible axes.\nUsing APA style, write up your report of this relationship between your selected variables. Be sure to include r, df, & p-values.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk5_cor.html#objectives",
    "href": "class-activities/wk5_cor.html#objectives",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "Identify predictor and outcome variables from a research question.\nCreate an appropriate visualization (ggplot).\nRun the correct statistical test and report the appropriate results."
  },
  {
    "objectID": "class-activities/wk5_cor.html#the-scenario-dataset",
    "href": "class-activities/wk5_cor.html#the-scenario-dataset",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "We have data of personality traits, as measured by the Ten Item Personality Inventory, and self-reported aspects of sleep (# of hours slept on average & overall sleep quality), as well as some demographic variables. The administration is asking how different personality traits are related to sleep quality.\nDownload Week 5 Class Activity (.csv)\nPlease download the TIPI_Data.csv file (above). It contains the following variables of interest:\n\nID: A unique identifier for each participant.\nage: The participants reported age in years\nTIPI_1 - TIPI_10: The ratings on each item of the Ten Item Personality inventory. Even items need to be reverse scored (scale goes from 1 to 7). Scores for each personality index are from the mean of their respective items.\n\nExtraversion: 1 & 6; Agreeableness: 2 & 7; Conscientiousness: 3 & 8; Emotional Stability: 4 & 9; Openness to Experiences: 5 & 10\n\nSleep Quality: Scale from 1-5 with higher scores indicating better sleep quality\nHours of Sleep: Score that represents a range.\n\n0-3 hours = 1; 3-6 hours = 5; 6-9 hours = 7; 9+ hours = 8"
  },
  {
    "objectID": "class-activities/wk5_cor.html#instructions",
    "href": "class-activities/wk5_cor.html#instructions",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "Create a new R Markdown file titled week5_inclass.Rmd.\nLoad the appropriate libraries.\nLoad the TIPI_Data.csv dataset.\nFor each task below, write the R code and answer the questions.\n\n\n\n\nHow might you identify ‚Äúvalid‚Äù responses? Based on the information in the dataset, what may be variables that you may want to examine more closely? (You don‚Äôt have to do the coding for this, just answer conceptually).\nReverse code items of the TIPI\nCreate the total scores for each subscale of the TIPI\n\n\n\n\nCreate a correlation table of the subscales of the TIPI, Sleep Quality and Sleep hours. Be sure to have it include associated p-values.\nHow are you handling missing values and why?\n\n\n\nSelect one pair of variables to further examine the correlation. You must include only one subscale of the TIPI. Why did you decide these variables? (due to significance? Or effect size?)\nGenerate a scatterplot with your variables and add a fit line. Be sure to include a title, and legible axes.\nUsing APA style, write up your report of this relationship between your selected variables. Be sure to include r, df, & p-values.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk5_cor.html#steps",
    "href": "class-activities/wk5_cor.html#steps",
    "title": "Week 5 Exercises - Correlation",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nVisualize the Data (select 1 pairing of personality variables)\nTest the Relationship\nCreate Correlation Matrix\nCheck Group Differences\n\n\nItems in the Data:\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html",
    "href": "class-activities/wk3_desc-viz.html",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "",
    "text": "Goal: Work on importing data as well as being able to build a pipeline from descriptives to reporting to visualizing."
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#create-a-new-markdown-document",
    "href": "class-activities/wk3_desc-viz.html#create-a-new-markdown-document",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "Create a new Markdown Document",
    "text": "Create a new Markdown Document\n\nGo to File &gt; New File &gt; R Markdown\nProvide the title ‚ÄúDescribe & Visualize‚Äù and input your name as the author\nA script will open in the Source pane. Remove unnecessary code.\nGo to File &gt; Save and name it week3.Rmd. Make sure this saves in the same folder as all of your other stuff. Stay Organized!"
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#setting-it-up",
    "href": "class-activities/wk3_desc-viz.html#setting-it-up",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "Setting it up",
    "text": "Setting it up\n\nCreate a Code Chunk\nLoad the tidyverse, psych and sjPlot libraries (Install them if you need to)"
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#the-data",
    "href": "class-activities/wk3_desc-viz.html#the-data",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "The Data",
    "text": "The Data\nDownload Week 3 InClass Data (.csv)\nDownload the data and move it to the correct folder so that you can access it in this lab.\nYour dataset is from a larger study that was examining the overall impact of sleep on energy (and vice versa). Students in different areas across the country completed various questionnaires. The current data is a selection of overall sleep quality rating (0-100) and overall energy level (0-100) across all cities. You will be asked to examine these variables in a descriptive and visual way for your specific city.\nBreak up into your groups and work to visualize your assigned cities dataset.\n\n\n\nAlbuquerque\nChicago\nPittsburgh\n\n\nAtlanta\nDenver\nRochester\n\n\nBoston\nIthaca\nSacramento\n\n\nChampaign-Urbana\nMadison\nSeattle\n\n\n\nImport the data into your R file. I would suggest putting this line within the code chunk that you have your libraries in.\nFocus on having reproducible code! You may need to share your file with someone else. They should be able to run it."
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#questions",
    "href": "class-activities/wk3_desc-viz.html#questions",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "Questions",
    "text": "Questions\nWith the data that you have imported, follow the following steps and answer the questions along the way.\n\nNumber of Observations\n‚ùìAfter importing, how many total observations are there?\n‚úÖAnswer:\n\nThe dataset has all cities involved in the study. You only want to keep the data from your city. Create a new dataset that has only your city in it.\n\n\n\n\n\n\nTip\n\n\n\nWe‚Äôve used dplyr a lot to move our data around. Maybe it has something to do with select() or filter() or mutate()\n\n\n‚ùìHow many total observations are there in your new dataset (for your city)?\n‚úÖAnswer:\n\n\n\nCalculating Descriptives\nYou should now have 2 datasets (1 for the entire sample, and 1 for your city). Calculate and report the mean and standard deviation for your city. Then calcullate and report the mean and standard deviation for the whole sample.\n\n\n\nYour City\nTotal Sample\n\n\n\n\nSleep Mean:\nSleep Mean:\n\n\nSleep SD:\nSleep SD:\n\n\nEnergy Mean:\nEnergy Mean:\n\n\nEnergy SD:\nEnergy SD:\n\n\n\n‚ùìHow are the mean and standard deviations similar/different?\n‚úÖAnswer:\n\n\n\nReporting Descriptive Statistics\nNow that you have each of the pieces of information calculated for the entire sample and your specific city, you can report it in text. It is important to be able to report these basic descriptive statistics in a meaningful way, so we will practice it as often as possible. Here is an example:\n\nThe sample as a whole was relatively young (M = 19.22, SD = 3.45).\nThe average amount of drinks consumed was 3.37 (SD = 0.92).\n\n‚ùìReport the means and standard deviations in text for the two variables in your city sample.\n‚úÖAnswer:\n\n\n\nVisualizing\nWe have two variables and we would like to examine the relationship between them. Use a scatterplot to highlight the relationship between these two variables for your city.\nBe sure that your plot has a clear main title and clear labels for each axis.\n\n\n\n\n\n\nTip\n\n\n\nLook back to the lecture or past labs and pull in some of the ggplot code that you have! You can always re-use code.\n\n\n‚ùìDescribe the overall look of the data for your city.\n‚úÖAnswer:\n\nAs a class, we will review the different cities to see if we would be able to come to some broad conclusion.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/day1.html",
    "href": "class-activities/day1.html",
    "title": "Day 1 Exercise - Getting Comfy with R",
    "section": "",
    "text": "In-Class Activity: Your First R Session\nGoal: To become familiar with the RStudio interface and perform a basic data exploration workflow.\n\n\nCreate a new Markdown Document\n\nGo to File &gt; New File &gt; R Markdown\nProvide the title ‚ÄúDay 1‚Äù and input your name as the author\nA script will open in the Source pane. Remove unnecessary code.\nGo to File &gt; Save and name it introduction.Rmd. Make sure this saves in the same folder as all of your other stuff. Stay Organized!\n\nI‚Äôm not going to tell you how to organize your folders, but I will give a suggestion. Have 1 folder for the whole class. This will have the Project that we created. Inside there, have a folder for ‚ÄúClass Activities‚Äù. This is where you can save this file. Then, have other folders for the labs and what not.\n\n\n\n\nStarting the document\nIn the text field of the markdown file, introduce yourself! Answer these questions below:\n\n\nName:\nPronouns\nYear in school\nPhD/Thesis/Capstone\nArea of psychology\nResearch interests\nComfort with R (1-10 with 10 being ‚ÄúExpert‚Äù)\nOverall feelings toward Statistics\nAnything else you want to share\n\n\n\n\nYour First ‚ÄúAnalysis‚Äù\n\nCreate a Code Chunk\nLoad the tidyverse library\nCreate the object datawars and assign dataset called starwars to it (hint: data &lt;- cars)\nUse View(), head() and glimpse() to look at datawars\nIn the text below, answer these questions:\n\nWhat do each of these do?\nWhich do you like more?\n\nCreate another code chunk and use summary() to get descriptives of all variables in the dataset.\n\nLook at the output of your summary() command. For the mass and height variables, you‚Äôll see a value for NA's. In your own words, what do you think NA means in this context?\n\n\n\nVisualize your data\nNow we want to investigate the relationship between mass and height in this dataset.\n\nCreate a scatterplot using ggplot().\nThe plot should show height on the x-axis and mass on the y-axis.\nAdd some labels to make your plot clear and professional.\n\nHint: Use the code below as a template and fill in the blanks.\n\n\nggplot(data = __, aes(x = __, y = __)) +\n  geom_point() +\n  labs(title = \"__\",\n       x = \"__\",\n       y = \"__\")\n\nLook at your plot. Do you notice any characters that seem unusually heavy for their height? Briefly describe one.\n\n\n\nWrangle your Data\nSince we have some outliers that seem to be related to non-human species, let‚Äôs just look at Humans.\n\nCreate a new object called rebels.\nThis new object should contain only the characters from the starwars dataset where the species is ‚ÄúHuman‚Äù.\n\nHint: Use the filter() function. The syntax is new_object &lt;- old_object %&gt;% filter(column_name == \"value\"). Remember that ‚ÄúHuman‚Äù needs to be in quotes.\n\nPrint your new rebels object to the console to make sure your filter worked correctly. Once confirmed, calculate the average (hint: use mean()) for the height and weight of the rebels.\n\n\nHow many rows are in your new rebels dataset?\nWhat is the average height and weight?\n\n\nCreate another scatterplot with your new dataset. Copy and update the code we used previously.\n\n\n\n\nClosing out the Document\nWhat is 1 thing you are looking forward to this semester and 1 thing that you are worried about (can be in or outside of this class)?\nEnd of the document. Remember to Knit and upload to myCourses."
  }
]