[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "üîóGetting Started with R\n\n\nüîóIntro to Data Wrangling\n\n\nüîóLibrary Tracking",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "class-activities/day1.html",
    "href": "class-activities/day1.html",
    "title": "Day 1 Exercise - Getting Comfy with R",
    "section": "",
    "text": "In-Class Activity: Your First R Session\nGoal: To become familiar with the RStudio interface and perform a basic data exploration workflow.\n\n\nCreate a new Markdown Document\n\nGo to File &gt; New File &gt; R Markdown\nProvide the title ‚ÄúDay 1‚Äù and input your name as the author\nA script will open in the Source pane. Remove unnecessary code.\nGo to File &gt; Save and name it introduction.Rmd. Make sure this saves in the same folder as all of your other stuff. Stay Organized!\n\nI‚Äôm not going to tell you how to organize your folders, but I will give a suggestion. Have 1 folder for the whole class. This will have the Project that we created. Inside there, have a folder for ‚ÄúClass Activities‚Äù. This is where you can save this file. Then, have other folders for the labs and what not.\n\n\n\n\nStarting the document\nIn the text field of the markdown file, introduce yourself! Answer these questions below:\n\n\nName:\nPronouns\nYear in school\nPhD/Thesis/Capstone\nArea of psychology\nResearch interests\nComfort with R (1-10 with 10 being ‚ÄúExpert‚Äù)\nOverall feelings toward Statistics\nAnything else you want to share\n\n\n\n\nYour First ‚ÄúAnalysis‚Äù\n\nCreate a Code Chunk\nLoad the tidyverse library\nCreate the object datawars and assign dataset called starwars to it (hint: data &lt;- cars)\nUse View(), head() and glimpse() to look at datawars\nIn the text below, answer these questions:\n\nWhat do each of these do?\nWhich do you like more?\n\nCreate another code chunk and use summary() to get descriptives of all variables in the dataset.\n\nLook at the output of your summary() command. For the mass and height variables, you‚Äôll see a value for NA's. In your own words, what do you think NA means in this context?\n\n\n\nVisualize your data\nNow we want to investigate the relationship between mass and height in this dataset.\n\nCreate a scatterplot using ggplot().\nThe plot should show height on the x-axis and mass on the y-axis.\nAdd some labels to make your plot clear and professional.\n\nHint: Use the code below as a template and fill in the blanks.\n\n\nggplot(data = __, aes(x = __, y = __)) +\n  geom_point() +\n  labs(title = \"__\",\n       x = \"__\",\n       y = \"__\")\n\nLook at your plot. Do you notice any characters that seem unusually heavy for their height? Briefly describe one.\n\n\n\nWrangle your Data\nSince we have some outliers that seem to be related to non-human species, let‚Äôs just look at Humans.\n\nCreate a new object called rebels.\nThis new object should contain only the characters from the starwars dataset where the species is ‚ÄúHuman‚Äù.\n\nHint: Use the filter() function. The syntax is new_object &lt;- old_object %&gt;% filter(column_name == \"value\"). Remember that ‚ÄúHuman‚Äù needs to be in quotes.\n\nPrint your new rebels object to the console to make sure your filter worked correctly. Once confirmed, calculate the average (hint: use mean()) for the height and weight of the rebels.\n\n\nHow many rows are in your new rebels dataset?\nWhat is the average height and weight?\n\n\nCreate another scatterplot with your new dataset. Copy and update the code we used previously.\n\n\n\n\nClosing out the Document\nWhat is 1 thing you are looking forward to this semester and 1 thing that you are worried about (can be in or outside of this class)?\nEnd of the document. Remember to Knit and upload to myCourses."
  },
  {
    "objectID": "class-activities/wk10_multiple-reg.html",
    "href": "class-activities/wk10_multiple-reg.html",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "",
    "text": "Download Week 10 Class ActivityFollow Along (.csv)\nData is taken from Cards Against Humanity - Pulse of the Nation\nDownload the data and move it to the correct folder so that you can access it in this activity.\nImport the data into your R file.\nFocus on having reproducible code! You will share your file with someone else. They should be able to run it.\n\n\n\nImport Data\nCheck descriptive statistics\nCreate a correlation plot for the continuous variables\nVisualize the relationship between # of Transformers Movies and Books\nConduct a multiple linear regression predict # of Transformers Movies.\nBriefly report the results\n\n\n\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "class-activities/wk10_multiple-reg.html#steps",
    "href": "class-activities/wk10_multiple-reg.html#steps",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "",
    "text": "Import Data\nCheck descriptive statistics\nCreate a correlation plot for the continuous variables\nVisualize the relationship between # of Transformers Movies and Books\nConduct a multiple linear regression predict # of Transformers Movies.\nBriefly report the results\n\n\n\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "class-activities/wk10_multiple-reg.html#steps-1",
    "href": "class-activities/wk10_multiple-reg.html#steps-1",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nIdentify your Outcome Variable and up to 3 predictor variables. Why did you choose your predictors?\nVisualize the relationship between 2 variables (with one being your Outcome)\nConduct a multiple linear regression to predict your outcome variable (3 predictors maximum)\nUse check_model to examine the model\nBriefly report the results"
  },
  {
    "objectID": "class-activities/wk10_multiple-reg.html#when-you-get-your-shared-files",
    "href": "class-activities/wk10_multiple-reg.html#when-you-get-your-shared-files",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "When you get your shared files:",
    "text": "When you get your shared files:\n\nSave a Word doc in there that answers the following questions:\n\nYour Name:\nName of person who‚Äôs data/script you have:\nWere you able to run their code without modification?\nIf you did have to modify things, what did you have to do?\nOn a scale from 1 - 10 (10 being ‚Äúexcellent‚Äù), how would you rate the code that you received?"
  },
  {
    "objectID": "class-activities/wk6_means.html",
    "href": "class-activities/wk6_means.html",
    "title": "Week 6 Exercises - Comparing Means",
    "section": "",
    "text": "Goal: Work individually or in small groups to apply the concepts from today‚Äôs lecture to a new dataset. There will be breaks throughout the lecture today where you will be able to try out each of these tests!\n\n\nFor this activity, we are going to be using data that has stats for the majority of Pokemon (8 generations). We want to look at the differences among these various Pokemon. We want to be the very best. Like no one ever was.\nPlease download the data file:\nDownload Week 6 Class Activity (.csv)"
  },
  {
    "objectID": "class-activities/wk6_means.html#the-scenario-dataset",
    "href": "class-activities/wk6_means.html#the-scenario-dataset",
    "title": "Week 6 Exercises - Comparing Means",
    "section": "",
    "text": "For this activity, we are going to be using data that has stats for the majority of Pokemon (8 generations). We want to look at the differences among these various Pokemon. We want to be the very best. Like no one ever was.\nPlease download the data file:\nDownload Week 6 Class Activity (.csv)"
  },
  {
    "objectID": "class-activities/wk6_means.html#steps",
    "href": "class-activities/wk6_means.html#steps",
    "title": "Week 6 Exercises - Comparing Means",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nVisualize the Data (select 1 pairing of personality variables)\nTest the Relationship\nCreate Correlation Matrix\nCheck Group Differences\n\n\nItems in the Data:\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "class-activities/wk5_cor.html",
    "href": "class-activities/wk5_cor.html",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "Goal: Work individually or in small groups to apply the concepts from today‚Äôs lecture and demo to a new dataset.\n\n\n\nIdentify predictor and outcome variables from a research question.\nCreate an appropriate visualization (ggplot).\nRun the correct statistical test and report the appropriate results.\n\n\n\n\nWe have data of personality traits, as measured by the Ten Item Personality Inventory, and self-reported aspects of sleep (# of hours slept on average & overall sleep quality), as well as some demographic variables. The administration is asking how different personality traits are related to sleep quality.\nDownload Week 5 Class Activity (.csv)\nPlease download the TIPI_Data.csv file (above). It contains the following variables of interest:\n\nID: A unique identifier for each participant.\nage: The participants reported age in years\nTIPI_1 - TIPI_10: The ratings on each item of the Ten Item Personality inventory. Even items need to be reverse scored (scale goes from 1 to 7). Scores for each personality index are from the mean of their respective items.\n\nExtraversion: 1 & 6; Agreeableness: 2 & 7; Conscientiousness: 3 & 8; Emotional Stability: 4 & 9; Openness to Experiences: 5 & 10\n\nSleep Quality: Scale from 1-5 with higher scores indicating better sleep quality\nHours of Sleep: Score that represents a range.\n\n0-3 hours = 1; 3-6 hours = 5; 6-9 hours = 7; 9+ hours = 8\n\n\n\n\n\n\nCreate a new R Markdown file titled week5_inclass.Rmd.\nLoad the appropriate libraries.\nLoad the TIPI_Data.csv dataset.\nFor each task below, write the R code and answer the questions.\n\n\n\n\nHow might you identify ‚Äúvalid‚Äù responses? Based on the information in the dataset, what may be variables that you may want to examine more closely? (You don‚Äôt have to do the coding for this, just answer conceptually).\nReverse code items of the TIPI\nCreate the total scores for each subscale of the TIPI\n\n\n\n\nCreate a correlation table of the subscales of the TIPI, Sleep Quality and Sleep hours. Be sure to have it include associated p-values.\nHow are you handling missing values and why?\n\n\n\nSelect one pair of variables to further examine the correlation. You must include only one subscale of the TIPI. Why did you decide these variables? (due to significance? Or effect size?)\nGenerate a scatterplot with your variables and add a fit line. Be sure to include a title, and legible axes.\nUsing APA style, write up your report of this relationship between your selected variables. Be sure to include r, df, & p-values.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk5_cor.html#objectives",
    "href": "class-activities/wk5_cor.html#objectives",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "Identify predictor and outcome variables from a research question.\nCreate an appropriate visualization (ggplot).\nRun the correct statistical test and report the appropriate results."
  },
  {
    "objectID": "class-activities/wk5_cor.html#the-scenario-dataset",
    "href": "class-activities/wk5_cor.html#the-scenario-dataset",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "We have data of personality traits, as measured by the Ten Item Personality Inventory, and self-reported aspects of sleep (# of hours slept on average & overall sleep quality), as well as some demographic variables. The administration is asking how different personality traits are related to sleep quality.\nDownload Week 5 Class Activity (.csv)\nPlease download the TIPI_Data.csv file (above). It contains the following variables of interest:\n\nID: A unique identifier for each participant.\nage: The participants reported age in years\nTIPI_1 - TIPI_10: The ratings on each item of the Ten Item Personality inventory. Even items need to be reverse scored (scale goes from 1 to 7). Scores for each personality index are from the mean of their respective items.\n\nExtraversion: 1 & 6; Agreeableness: 2 & 7; Conscientiousness: 3 & 8; Emotional Stability: 4 & 9; Openness to Experiences: 5 & 10\n\nSleep Quality: Scale from 1-5 with higher scores indicating better sleep quality\nHours of Sleep: Score that represents a range.\n\n0-3 hours = 1; 3-6 hours = 5; 6-9 hours = 7; 9+ hours = 8"
  },
  {
    "objectID": "class-activities/wk5_cor.html#instructions",
    "href": "class-activities/wk5_cor.html#instructions",
    "title": "Week 5 Exercises - Correlation",
    "section": "",
    "text": "Create a new R Markdown file titled week5_inclass.Rmd.\nLoad the appropriate libraries.\nLoad the TIPI_Data.csv dataset.\nFor each task below, write the R code and answer the questions.\n\n\n\n\nHow might you identify ‚Äúvalid‚Äù responses? Based on the information in the dataset, what may be variables that you may want to examine more closely? (You don‚Äôt have to do the coding for this, just answer conceptually).\nReverse code items of the TIPI\nCreate the total scores for each subscale of the TIPI\n\n\n\n\nCreate a correlation table of the subscales of the TIPI, Sleep Quality and Sleep hours. Be sure to have it include associated p-values.\nHow are you handling missing values and why?\n\n\n\nSelect one pair of variables to further examine the correlation. You must include only one subscale of the TIPI. Why did you decide these variables? (due to significance? Or effect size?)\nGenerate a scatterplot with your variables and add a fit line. Be sure to include a title, and legible axes.\nUsing APA style, write up your report of this relationship between your selected variables. Be sure to include r, df, & p-values.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk5_cor.html#steps",
    "href": "class-activities/wk5_cor.html#steps",
    "title": "Week 5 Exercises - Correlation",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nVisualize the Data (select 1 pairing of personality variables)\nTest the Relationship\nCreate Correlation Matrix\nCheck Group Differences\n\n\nItems in the Data:\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "PSYC 640: Graduate Statistics",
    "section": "",
    "text": "This course is the introduction to statistics for graduate students. The goal of the course is to provide a grounding in statistical concepts, methods and application to research. I aim to increase student‚Äôs confidence in using these techniques and introducing them to R. Topics will range from including mathematical conceptualizations to practical application with various techniques ranging from descriptive statistics to regression.\n\nWhat it feels like when you read you are going to learn R:\n\n\n\nWhat it is actually like:\n\nIllustration credit: Allison Horst (https://allisonhorst.com/allison-horst)",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "slides/lec-13_mod.html#today",
    "href": "slides/lec-13_mod.html#today",
    "title": "Week 13: Intro to Moderation",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\n\nChecking back in on Regression\nMaking things complicated with moderation\nFinal Project Check in"
  },
  {
    "objectID": "slides/lec-13_mod.html#motivating-example",
    "href": "slides/lec-13_mod.html#motivating-example",
    "title": "Week 13: Intro to Moderation",
    "section": "Motivating example",
    "text": "Motivating example\n\nglimpse(t_data)\n\nRows: 20\nColumns: 4\n$ ID    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1‚Ä¶\n$ study &lt;dbl&gt; 1.62, 0.54, 0.86, 0.80, 0.36, 2.14, 1.13, 1.66, 1.23, 1.92, 1.82‚Ä¶\n$ grade &lt;dbl&gt; 9.0, 7.8, 8.5, 6.2, 6.9, 9.0, 6.6, 8.7, 6.6, 8.8, 9.7, 5.9, 9.5,‚Ä¶\n$ tutor &lt;int&gt; 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0\n\nt_data = t_data %&gt;%\n  mutate(tutor_lab = factor(tutor, \n                            levels = c(0,1),\n                            labels = c(\"No tutor\", \"Tutor\")))"
  },
  {
    "objectID": "slides/lec-13_mod.html#what-are-interactions",
    "href": "slides/lec-13_mod.html#what-are-interactions",
    "title": "Week 13: Intro to Moderation",
    "section": "What are interactions?",
    "text": "What are interactions?\nWhen we have two variables, A and B, in a regression model, we are testing whether these variables have additive effects on our outcome, Y. That is, the effect of A on Y is constant over all values of B.\n\nExample: Studying and working with a tutor have additive effects on grades; no matter how many hours I spend studying, working with a tutor will improve my grade by 2 points."
  },
  {
    "objectID": "slides/lec-13_mod.html#what-are-interactions-1",
    "href": "slides/lec-13_mod.html#what-are-interactions-1",
    "title": "Week 13: Intro to Moderation",
    "section": "What are interactions?",
    "text": "What are interactions?\nHowever, we may hypothesis that two variables have joint effects, or interact with each other. In this case, the effect of A on Y changes as a function of B.\n\nExample: Working with a tutor has a positive impact on grades but only for individuals who do not spend a lot of time studying; for individuals who study a lot, tutoring will have little or no impact.\nThis is also referred to as moderation.\n\nInteractions (moderation) tell us whether the effect of one IV (on a DV) depends on another IV."
  },
  {
    "objectID": "slides/lec-13_mod.html#interactions",
    "href": "slides/lec-13_mod.html#interactions",
    "title": "Week 13: Intro to Moderation",
    "section": "Interactions",
    "text": "Interactions\nNow extend this example to include joint effects, not just additive effects:\n\\[\\hat{\\text{grade}} = b_{0} + b_{1}\\text{Tutor} + b_2\\text{Study} + b_3(\\text{Tutor}\\times\\text{Study})\\]\n\nmod3 &lt;- lm(grade ~ tutor_lab + study + tutor_lab*study, data = t_data) \nmod3 &lt;-  lm(grade ~ tutor_lab*study, data = t_data)\nsummary(mod3)\n\n...\nCoefficients:\n                     Estimate Std. Error t value      Pr(&gt;|t|)    \n(Intercept)            5.0121     0.3496  14.337 0.00000000015 ***\ntutor_labTutor         2.9203     0.6418   4.550      0.000328 ***\nstudy                  1.7567     0.3095   5.676 0.00003443132 ***\ntutor_labTutor:study  -1.1713     0.4402  -2.661      0.017093 *  \n..."
  },
  {
    "objectID": "slides/lec-13_mod.html#interpreting-coefficients",
    "href": "slides/lec-13_mod.html#interpreting-coefficients",
    "title": "Week 13: Intro to Moderation",
    "section": "Interpreting coefficients",
    "text": "Interpreting coefficients\n\\[\\hat{\\text{grade}} = b_{0} + b_{1}\\text{Tutor} + b_2\\text{Study} + b_3(\\text{Tutor}\\times\\text{Study})\\]\n\n\n...\nCoefficients:\n                     Estimate Std. Error t value      Pr(&gt;|t|)    \n(Intercept)            5.0121     0.3496  14.337 0.00000000015 ***\ntutor_labTutor         2.9203     0.6418   4.550      0.000328 ***\nstudy                  1.7567     0.3095   5.676 0.00003443132 ***\ntutor_labTutor:study  -1.1713     0.4402  -2.661      0.017093 *  \n...\n\n\nIntercept: the expected value of Y when all predictors are 0\n\\(b_1\\): The difference in means (tutor vs no tutor) when study = 0\n\\(b_2\\): The slope of study when tutor = 0, or the reference group\n\\(b_3\\)?"
  },
  {
    "objectID": "slides/lec-13_mod.html#interpreting-coefficients-1",
    "href": "slides/lec-13_mod.html#interpreting-coefficients-1",
    "title": "Week 13: Intro to Moderation",
    "section": "Interpreting coefficients",
    "text": "Interpreting coefficients\n\\[\\hat{\\text{grade}} = b_{0} + b_{1}\\text{Tutor} + b_2\\text{Study} + b_3(\\text{Tutor}\\times\\text{Study})\\]\n\\(b_3\\)\n\nthe linear effect of the product of hours studying and tutoring\nhow much the slope of study differs for the two tutoring groups\nhow much the effect of tutoring changes for for every one 1 hour increase in studying."
  },
  {
    "objectID": "slides/lec-13_mod.html#terms",
    "href": "slides/lec-13_mod.html#terms",
    "title": "Week 13: Intro to Moderation",
    "section": "Terms",
    "text": "Terms\nInteractions tell us whether the effect of one IV (on a DV) depends on another IV. In this case, the effect of tutoring depends on a student‚Äôs time spent studying. Tutoring has a large effect when a student‚Äôs spends little time studying, but a small effect when the amount of time studying is high.\n\\(b_3\\) is referred to as a ‚Äúhigher-order term.‚Äù\nHigher-order terms are those terms that represent interactions."
  },
  {
    "objectID": "slides/lec-13_mod.html#terms-1",
    "href": "slides/lec-13_mod.html#terms-1",
    "title": "Week 13: Intro to Moderation",
    "section": "Terms",
    "text": "Terms\nLower-order terms change depending on the values of the higher-order terms. The value of \\(b_1\\) and \\(b_2\\) will change depending on the value of \\(b_3\\).\n\nThese values represent ‚Äúconditional effects‚Äù (because the value is conditional on the level of the other variable). In many cases, the value and significance test with these terms is either meaningless (if an IV is never equal to 0) or unhelpful, as these values and significance change across the data."
  },
  {
    "objectID": "slides/lec-13_mod.html#conditional-effects-and-simple-slopes",
    "href": "slides/lec-13_mod.html#conditional-effects-and-simple-slopes",
    "title": "Week 13: Intro to Moderation",
    "section": "Conditional effects and simple slopes",
    "text": "Conditional effects and simple slopes\nThe regression line estimated in this model is quite difficult to interpret on its own. A good strategy is to decompose the regression equation into simple slopes, which are determined by calculating the conditional effects at a specific level of the moderating variable.\n\nSimple slope: the equation for Y on X at different levels of Z\nConditional effect: the slope coefficients in the full regression model that can change. These are the lower-order terms associated with a variable. E.g., studying has a conditional effect on grade."
  },
  {
    "objectID": "slides/lec-13_mod.html#interaction-shapes",
    "href": "slides/lec-13_mod.html#interaction-shapes",
    "title": "Week 13: Intro to Moderation",
    "section": "Interaction shapes",
    "text": "Interaction shapes\nOften we graph the simple slopes as a way to understand the interaction. The shape of the lines in the graph are informative and help us interpret conceptually what‚Äôs happening."
  },
  {
    "objectID": "slides/lec-13_mod.html#centering",
    "href": "slides/lec-13_mod.html#centering",
    "title": "Week 13: Intro to Moderation",
    "section": "Centering",
    "text": "Centering\nThe regression equation built using the raw data is not only difficult to interpret, but often the terms displayed are not relevant to the hypotheses we‚Äôre interested.\n\n\\(b_0\\) is the expected value when all predictors are 0, but this may never happen in real life\n\\(b_1\\) is the effect of tutoring when hours spent studying is equal to 0, but this may not ever happen either."
  },
  {
    "objectID": "slides/lec-13_mod.html#wrapping-up",
    "href": "slides/lec-13_mod.html#wrapping-up",
    "title": "Week 13: Intro to Moderation",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nWe just examined moderation as an interaction between a categorical variable and a continuous variable"
  },
  {
    "objectID": "slides/lec-13_mod.html#next-steps",
    "href": "slides/lec-13_mod.html#next-steps",
    "title": "Week 13: Intro to Moderation",
    "section": "Next Steps",
    "text": "Next Steps\nModerations with two continuous predictors"
  },
  {
    "objectID": "slides/lec-13_mod.html#what-are-interactions-2",
    "href": "slides/lec-13_mod.html#what-are-interactions-2",
    "title": "Week 13: Intro to Moderation",
    "section": "What are interactions?",
    "text": "What are interactions?\nWhen we have two variables, A and B, in a regression model, we are testing whether these variables have additive effects on our outcome, Y. That is, the effect of A on Y is constant over all values of B.\n\nExample: Drinking coffee and hours of sleep have additive effects on alertness; no matter how any hours I slept the previous night, drinking one cup of coffee will make me .5 SD more awake than not drinking coffee."
  },
  {
    "objectID": "slides/lec-13_mod.html#what-are-interactions-3",
    "href": "slides/lec-13_mod.html#what-are-interactions-3",
    "title": "Week 13: Intro to Moderation",
    "section": "What are interactions?",
    "text": "What are interactions?\nHowever, we may hypothesis that two variables have joint effects, or interact with each other. In this case, the effect of A on Y changes as a function of B.\n\nExample: Chronic stress has a negative impact on health but only for individuals who receive little or no social support; for individuals with high social support, chronic stress has no impact on health.\nThis is also referred to as moderation.\nThe ‚Äúinteraction term‚Äù is the regression coefficient that tests this hypothesis."
  },
  {
    "objectID": "slides/lec-13_mod.html#conditional-effects-and-simple-slopes-1",
    "href": "slides/lec-13_mod.html#conditional-effects-and-simple-slopes-1",
    "title": "Week 13: Intro to Moderation",
    "section": "Conditional effects and simple slopes",
    "text": "Conditional effects and simple slopes\nThe regression line estimated in this model is quite difficult to interpret on its own. A good strategy is to decompose the regression equation into simple slopes, which are determined by calculating the conditional effects at a specific level of the moderating variable.\n\n\n\nSimple slope: the equation for Y on X at different levels of Z; but also refers to only the coefficient for X in this equation\n\n\n\nConditional effect: the slope coefficients in the full regression model which can change. These are the lower-order terms associated with a variable."
  },
  {
    "objectID": "slides/lec-13_mod.html#plotting-interactions",
    "href": "slides/lec-13_mod.html#plotting-interactions",
    "title": "Week 13: Intro to Moderation",
    "section": "Plotting interactions",
    "text": "Plotting interactions\nWhat is this plotting?\n\nplot_model(imodel, type = \"pred\", terms = c(\"Support\", \"Anxiety[mean]\"))"
  },
  {
    "objectID": "slides/lec-13_mod.html#testing-simple-slopes",
    "href": "slides/lec-13_mod.html#testing-simple-slopes",
    "title": "Week 13: Intro to Moderation",
    "section": "Testing simple slopes",
    "text": "Testing simple slopes\n\n#https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html?q=simple%20slo#contrasts-and-comparisons-for-slopes-of-numeric-predictors\n\npred &lt;- estimate_means(imodel, c(\"Support\", \"Anxiety = c(5,6,7)\"))\nplot(pred)\n\nestimate_slopes(imodel, \"Support\", by = \"Anxiety = c(5,6,7)\")\n\nEstimated Marginal Effects\n\nAnxiety | Slope |   SE |       95% CI | t(114) |      p\n-------------------------------------------------------\n5       |  0.46 | 0.05 | [0.36, 0.56] |   8.83 | &lt; .001\n6       |  0.42 | 0.05 | [0.32, 0.51] |   8.44 | &lt; .001\n7       |  0.37 | 0.05 | [0.28, 0.47] |   7.47 | &lt; .001\n\nMarginal effects estimated for Support\nType of slope was dY/dX"
  },
  {
    "objectID": "slides/lec-13_mod.html#testing-simple-slopes-1",
    "href": "slides/lec-13_mod.html#testing-simple-slopes-1",
    "title": "Week 13: Intro to Moderation",
    "section": "Testing simple slopes",
    "text": "Testing simple slopes\n\nestimate_slopes(imodel, \"Support\", by = \"Anxiety=[sd]\")\n\nEstimated Marginal Effects\n\nAnxiety | Slope |   SE |       95% CI | t(114) |      p\n-------------------------------------------------------\n5.13    |  0.45 | 0.05 | [0.35, 0.55] |   8.82 | &lt; .001\n7.61    |  0.35 | 0.05 | [0.25, 0.45] |   6.67 | &lt; .001\n10.10   |  0.25 | 0.07 | [0.11, 0.38] |   3.48 | &lt; .001\n\nMarginal effects estimated for Support\nType of slope was dY/dX"
  },
  {
    "objectID": "slides/lec-13_mod.html#simple-slopes---significance-tests",
    "href": "slides/lec-13_mod.html#simple-slopes---significance-tests",
    "title": "Week 13: Intro to Moderation",
    "section": "Simple slopes - Significance tests",
    "text": "Simple slopes - Significance tests\nWhat if you want to compare slopes to each other? How would we test this?\n\nThe test of the interaction coefficient is equivalent to the test of the difference in slopes at levels of Z separated by 1 unit.\n\ncoef(summary(imodel))\n\n                   Estimate Std. Error   t value           Pr(&gt;|t|)\n(Intercept)     -2.73966246 1.12100519 -2.443934 0.0160605206624654\nAnxiety          0.61561220 0.13010161  4.731780 0.0000064353728132\nSupport          0.66696689 0.09547464  6.985802 0.0000000002017698\nAnxiety:Support -0.04174076 0.01309328 -3.187954 0.0018497364252185"
  },
  {
    "objectID": "slides/lec-1_syl.html#scheduleplan",
    "href": "slides/lec-1_syl.html#scheduleplan",
    "title": "Week 01: Getting Started!",
    "section": "Schedule/Plan",
    "text": "Schedule/Plan\n\n\n\n\n\n\n\n8 - 8:45\nGet oriented. Go over syllabus. Explain course structure. Do all that fun stuff.\n\n\n8:45 - 9ish\nBreak\n\n\n9ish - 10:00\nLive Demo in R\n\n\n10 - 10:50\nGet comfortable with R"
  },
  {
    "objectID": "slides/lec-1_syl.html#when-the-teaching-happens",
    "href": "slides/lec-1_syl.html#when-the-teaching-happens",
    "title": "Week 01: Getting Started!",
    "section": "When the Teaching Happens",
    "text": "When the Teaching Happens\nüíæ Meeting Times: Monday‚Äôs 8:00 - 10:50am\nüßë‚Äçüè´ Drop in Office Hours: Wednesdays 9 - 11:00 am\nüìß Best way to contact me? Email me. I will usually respond within 24 hours. If it has been longer, then you can send me a follow-up\n\n\n\n\n\n\nNote\n\n\nI just figured out how to easily put emojis into the presentation. I‚Äôm sorry that you will have to witness that."
  },
  {
    "objectID": "slides/lec-1_syl.html#communication",
    "href": "slides/lec-1_syl.html#communication",
    "title": "Week 01: Getting Started!",
    "section": "Communication",
    "text": "Communication\nPlease ask questions! üôã‚Äç‚ôÄÔ∏è\nIf you are having trouble, just ask!!\nBe open and honest with me and I will do what I can to support you."
  },
  {
    "objectID": "slides/lec-1_syl.html#who-the-heck-am-i",
    "href": "slides/lec-1_syl.html#who-the-heck-am-i",
    "title": "Week 01: Getting Started!",
    "section": "Who the heck am I? ü§∑",
    "text": "Who the heck am I? ü§∑\n\nUndergraduate degree at University of Denver\n\nPsychology & Philosophy\nHated Statistics\n\nGraduate degree at University of Illinois at Urbana-Champaign\n\nAdvisor: Dr.¬†Benjamin Hankin\nClinical/Community PhD üéì\n\nPre-Doctoral Internship & Postdoc at Rochester Institute of Technology"
  },
  {
    "objectID": "slides/lec-1_syl.html#a-little-more-about-me",
    "href": "slides/lec-1_syl.html#a-little-more-about-me",
    "title": "Week 01: Getting Started!",
    "section": "A little more about me",
    "text": "A little more about me\n\nPronouns: he/him/his\n2 amazing kids, 2 dogs (Dachshund and Shepherd Mix), 1 wife\nCurrently Reading: Dungeon Crawler Carl\nCurrently Listening: The Lonely Island & Seth Meyers Podcast\nCurrently Watching: Wednesday, Bluey, Hot Wheels - Let‚Äôs Race"
  },
  {
    "objectID": "slides/lec-1_syl.html#teaching-philosophy",
    "href": "slides/lec-1_syl.html#teaching-philosophy",
    "title": "Week 01: Getting Started!",
    "section": "Teaching Philosophy",
    "text": "Teaching Philosophy\n\nI‚Äôm here for you and to support you however I can\nMy job is to create a supportive, low-stakes environment where you can crash test ideas and develop new skills\nYour responsibility is to come to class prepared, ready to have fun, take some risks, and actively participate!\n\nAsk questions, share relevant funny stories, seek clarification, question the status quo where applicable\n\nScience is a team sport & failures/mistakes will happen, but it is okay! That‚Äôs what science and discovery is!"
  },
  {
    "objectID": "slides/lec-1_syl.html#class-materials",
    "href": "slides/lec-1_syl.html#class-materials",
    "title": "Week 01: Getting Started!",
    "section": "Class Materials",
    "text": "Class Materials\nI‚Äôve pulled from a lot of different textbooks. Good thing is, they are all free!\n\nIntroduction to Modern Statistics (2e) (Cetinkaya-Rundel & Hardin, 2024)\nLearning Statistics with R (Navarro)\nR for Data Science (2e) (Wickham, √áetinkaya-Rundel, & Grolemund, 2023)\nModern Statistics with R (2e) (Thullin, 2025)\nStatistical Thinking (Poldrack, 2024)\nAn Introduction to Statistical Learning (2e) (James, Witten, Hastie & Tibshirani, 2023)\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) (Judd, McClelland, & Ryan, 2017)"
  },
  {
    "objectID": "slides/lec-1_syl.html#evaluation-grading",
    "href": "slides/lec-1_syl.html#evaluation-grading",
    "title": "Week 01: Getting Started!",
    "section": "Evaluation & Grading",
    "text": "Evaluation & Grading\n\n\n\nComponent\nWeight\n\n\nWeekly Labs\n30%\n\n\nJournal Entries\n10%\n\n\nParticipation & Engagement\n15%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n25%"
  },
  {
    "objectID": "slides/lec-1_syl.html#course-policies",
    "href": "slides/lec-1_syl.html#course-policies",
    "title": "Week 01: Getting Started!",
    "section": "Course Policies",
    "text": "Course Policies\n\nAccommodations\nSafety\nAcademic Integrity"
  },
  {
    "objectID": "slides/lec-12_logistic.html#today",
    "href": "slides/lec-12_logistic.html#today",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\n\nFinal Project Prep\nSome helpful tools (autosave & new library)\nRegression Review\nCategorical Predictors Review\nLogistic Regression\nModel Diagnostics ü§∑"
  },
  {
    "objectID": "slides/lec-12_logistic.html#autosave",
    "href": "slides/lec-12_logistic.html#autosave",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Autosave",
    "text": "Autosave\nTools &gt;&gt; Global Options &gt;&gt; Code &gt;&gt; Saving"
  },
  {
    "objectID": "slides/lec-12_logistic.html#new-library-genzplyr",
    "href": "slides/lec-12_logistic.html#new-library-genzplyr",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "New Library: genzplyr",
    "text": "New Library: genzplyr\n\n\ndplyr but make it bussin fr fr no cap\n\ngenzplyr üíÖ"
  },
  {
    "objectID": "slides/lec-12_logistic.html#regression",
    "href": "slides/lec-12_logistic.html#regression",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Regression",
    "text": "Regression\nWhat is the equation for a regression??"
  },
  {
    "objectID": "slides/lec-12_logistic.html#regression-1",
    "href": "slides/lec-12_logistic.html#regression-1",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Regression",
    "text": "Regression\n\\[ Y_i = b_0 + b_1X_{1i} + b_2X_{2i} + ... + b_nX_{ni}+ e_i \\]"
  },
  {
    "objectID": "slides/lec-12_logistic.html#regression-2",
    "href": "slides/lec-12_logistic.html#regression-2",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Regression",
    "text": "Regression\nHow do we interpret the regression coefficients (Intercepts & slopes)?"
  },
  {
    "objectID": "slides/lec-12_logistic.html#regression-3",
    "href": "slides/lec-12_logistic.html#regression-3",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Regression",
    "text": "Regression\nINTERCEPT: When all predictor variables are set to 0, our expected value (predicted \\(\\hat{Y}\\)) will be this value.\nSLOPES: For every 1 unit change in our \\(X_n\\) variable, there will be beta (b or \\(\\beta\\)) units increase in our Y (outcome) variable, holding all other variables constant."
  },
  {
    "objectID": "slides/lec-12_logistic.html#categorical-predictors-factors",
    "href": "slides/lec-12_logistic.html#categorical-predictors-factors",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Categorical Predictors = factors",
    "text": "Categorical Predictors = factors\nTypically identified by a grouping variable that may be a character\n\nglimpse(cah_data$political_affiliation)\n\n chr [1:1000] \"Democrat\" \"Democrat\" \"Independent\" \"Republican\" \"Democrat\" ...\n\n\nNeed to change the variable from character to factor which will assign a number to each group\n\ncah_data &lt;- cah_data %&gt;%\n  mutate(\n    pol = as.factor(political_affiliation),\n    ghosts = as.factor(ghosts)\n    )\n\nglimpse(cah_data$pol)\n\n Factor w/ 3 levels \"Democrat\",\"Independent\",..: 1 1 2 3 1 1 2 3 3 1 ..."
  },
  {
    "objectID": "slides/lec-12_logistic.html#dummy-coding-replacing-factors",
    "href": "slides/lec-12_logistic.html#dummy-coding-replacing-factors",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Dummy Coding (replacing factors)",
    "text": "Dummy Coding (replacing factors)\nNumerical placeholders used to represent categorical variables\nTaking a categorical variable with \\(k\\) levels (e.g., Democratic, Independent, Republican) into \\(k-1\\) binary variables.\n\n\n\npolitical_affiliation\nbecomes\nInd (binary1)\nRep (binary2)\n\n\n\n\nDemocrat\n‚Äì&gt;\n0\n0\n\n\nIndependent\n‚Äì&gt;\n1\n0\n\n\nRepublican\n‚Äì&gt;\n0\n1\n\n\n‚Ä¶\n\n‚Ä¶\n‚Ä¶"
  },
  {
    "objectID": "slides/lec-12_logistic.html#categorical-regression",
    "href": "slides/lec-12_logistic.html#categorical-regression",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Categorical Regression",
    "text": "Categorical Regression\nGoing back to our Transformers dataset, let‚Äôs see how our political affiliation variable can predict # of transformers movies\nUsually you have to create the separate dummy variables, but not in R. As long as your predictor is set as a factor, R will automatically dummy code the variable.\n\ncat1 &lt;- lm(transformers ~ pol,\n           data = cah_data)\n\nYou can also double check the dummy/contrast coding\n\ncontrasts(cah_data$pol)\n\n            Independent Republican\nDemocrat              0          0\nIndependent           1          0\nRepublican            0          1"
  },
  {
    "objectID": "slides/lec-12_logistic.html#categories-in-action-last-time",
    "href": "slides/lec-12_logistic.html#categories-in-action-last-time",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Categories in Action (last time)",
    "text": "Categories in Action (last time)\nGoal: Gain greater familiarity with dummy coding and categorical predictors\nScenario: We are researchers examining the impact of a new intervention on reducing the vocalization ‚Äú6Ô∏è‚É£7Ô∏è‚É£‚Äù in the youths. We have done classroom observations to collect data on how many times students say ‚Äú6Ô∏è‚É£7Ô∏è‚É£‚Äù after receiving the intervention. Youths have been randomly assigned to one of 3 groups, and we need to determine which had the biggest impact."
  },
  {
    "objectID": "slides/lec-12_logistic.html#using-r",
    "href": "slides/lec-12_logistic.html#using-r",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Using R",
    "text": "Using R\nImport dataset, include age and pre-scores to see how that changes interpretation\n\n\n\n\n\n\nWarning\n\n\nDr.¬†Haraden is going to start opening up R and doing a follow-along thing. You have been warned"
  },
  {
    "objectID": "slides/lec-12_logistic.html#status",
    "href": "slides/lec-12_logistic.html#status",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "6Ô∏è‚É£7Ô∏è‚É£ Status",
    "text": "6Ô∏è‚É£7Ô∏è‚É£ Status\nIn our last example, we were able to see how these categorical variables could predict a continuous variable. This is perfect for linear regression.\nWhat if we want to see if students have ‚Äúrecovered‚Äù from 6Ô∏è‚É£7Ô∏è‚É£?\nWe would then ask: ‚ÄúWhich participants dropped below the clinical threshold for 6Ô∏è‚É£7Ô∏è‚É£ at follow-up? Now, our outcome is either recovered or not recovered.‚Äù"
  },
  {
    "objectID": "slides/lec-12_logistic.html#recovery-status",
    "href": "slides/lec-12_logistic.html#recovery-status",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Recovery Status",
    "text": "Recovery Status\nNow we have a binary outcome; Yes/No recovery\nWhat happens when we fit a linear regression? What are the chances of someone with a pre-score of 12 recovering by the follow-up?\n\n\nCode\nsix_seven &lt;- import(here(\"files\", \"data\", \n                       \"cat_reg_complete.xlsx\")) %&gt;% \n  janitor::clean_names() %&gt;% \n  # 1 = recovered; 0 = not recovered\n  mutate(recover = if_else(post_score &gt; 14, 0, 1))"
  },
  {
    "objectID": "slides/lec-12_logistic.html#binary-outcomes-in-regression",
    "href": "slides/lec-12_logistic.html#binary-outcomes-in-regression",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Binary Outcomes in Regression",
    "text": "Binary Outcomes in Regression\n\nA simple line is not going to appropriately capture the data\n\nPlus, it definitely doesn‚Äôt make it a normal distribution! We only have 2 scores in our predictor variable‚Ä¶\n\n\nIntroducing Logistic Regression üåü\n\nUsing a logistic function we are able to better capture the data and get a ‚Äúlikelihood‚Äù or ‚Äúprobability‚Äù of an outcome"
  },
  {
    "objectID": "slides/lec-12_logistic.html#probability-to-odds-to-log-odds",
    "href": "slides/lec-12_logistic.html#probability-to-odds-to-log-odds",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Probability to Odds to Log-Odds",
    "text": "Probability to Odds to Log-Odds\nProbability (p): The chance of an event happening. Ranges from 0 to 1\nOdds: The ratio of the probability of an event happening to it not happening.\n\n\\(Odds = \\frac{p}{1-p}\\)\nRanges from 0 to ‚àû. An odds of 4 means the event is 4 times more likely to happen than not.\n\nLog-Odds (logit): The natural log of the odds\n\n\\(Logit(p) = ln(\\frac{p}{1-p})\\)\nRanges from -‚àû to +‚àû\n\n\n\n\n\n\n\nImportant\n\n\nThis step transforms our bounded outcome variable (0/1) to an unbound one!"
  },
  {
    "objectID": "slides/lec-12_logistic.html#generalized-linear-model-glm",
    "href": "slides/lec-12_logistic.html#generalized-linear-model-glm",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Generalized Linear Model (GLM)",
    "text": "Generalized Linear Model (GLM)\nA generalization of a linear model (duh) that is used when the response variable has a non-normal error distribution\nMost commonly used when there is a binary (0-1) or count variable as the outcome (we will focus on the binary)\nUltimately, we are trying to identify the probability of the outcome taking the value 1 (‚Äúsuccess‚Äù) that is being modeled in relation to the predictor variables"
  },
  {
    "objectID": "slides/lec-12_logistic.html#recovering-from-67",
    "href": "slides/lec-12_logistic.html#recovering-from-67",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Recovering from 6Ô∏è‚É£7Ô∏è‚É£",
    "text": "Recovering from 6Ô∏è‚É£7Ô∏è‚É£\nNow we have a tool to figure this out, let‚Äôs see if the pre-score can predict recovery!\n\n## Using glm() instead of lm()\nrec_glm &lt;- glm(recover ~ pre_score, \n           data = six_seven, \n           ## This is new\n           ##Tells the model we are doing logistic regression with a binary outcome\n           family = \"binomial\")"
  },
  {
    "objectID": "slides/lec-12_logistic.html#odds-ratios-or",
    "href": "slides/lec-12_logistic.html#odds-ratios-or",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Odds Ratios (OR)",
    "text": "Odds Ratios (OR)\nOR &gt; 1: The predictor increases the odds of the outcome. (e.g., OR of 2.5 means the odds of believing in ghosts are 2.5 times higher).\nOR &lt; 1: The predictor decreases the odds of the outcome. (e.g., OR of 0.4 means the odds of believing in ghosts are 60% lower).\nOR = 1: The predictor has no effect on the odds of the outcome."
  },
  {
    "objectID": "slides/lec-12_logistic.html#visualization",
    "href": "slides/lec-12_logistic.html#visualization",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Visualization",
    "text": "Visualization\nExtract the model implied probabilities for each individual\n\nprobs &lt;- broom::augment(rec_glm, type.predict = \"response\")\n\nPlotting the predicted probabilities\n\nprobs %&gt;% \nggplot(aes(pre_score, .fitted)) +\n  geom_line(color = \"blue\", linewidth = 0.5) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(\n    title = \"Predicted Probability of Recovery from 6-7 by Pre-Score\",\n    x = \"Pre-Score\",\n    y = \"Predicted Probability of Recovery\"\n  ) +\n  ylim(0, 1) + # Keep the y-axis bounded at 0 and 1\n  theme_minimal()"
  },
  {
    "objectID": "slides/lec-12_logistic.html#logistic-regression-summary",
    "href": "slides/lec-12_logistic.html#logistic-regression-summary",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Logistic Regression: Summary",
    "text": "Logistic Regression: Summary\n\n\n\n\n\n\n\n\nFeature\nLinear Regression\nLogistic Regression\n\n\n\n\nOutcome Variable\nContinuous\nCategorical (Binary)\n\n\nEquation\n\\(Y=Œ≤_0+Œ≤_1X\\)\n\\(ln‚Å°(\\frac{p}{1-p})=Œ≤_0+Œ≤_1X\\)\n\n\nKey Interpretation\n\\(\\beta_1\\) is the change in the mean of Y\n\\(\\exp(\\beta_1)\\) is the odds ratio\n\n\nR Function\nlm()\nglm(..., family=\"binomial\")"
  },
  {
    "objectID": "slides/lec-12_logistic.html#next-up",
    "href": "slides/lec-12_logistic.html#next-up",
    "title": "Week 12: Categorical & Logistic Regression",
    "section": "Next Up‚Ä¶",
    "text": "Next Up‚Ä¶\nFollow along to apply these methods to a new dataset!\nPredicting the probability of believing in ghosts. Hopefully we have time to go through this example üëª"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-1",
    "href": "slides/lec-1_background.html#replication-reproducibility-1",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üç∞",
    "text": "Replication & Reproducibility üç∞\nI want to bake a cake!\n\nFind a recipe online (try ignoring their life story narrative)\nGet ingredients (Wegmans if you üí∞)\nFollow recipe and bake üßë‚Äçüç≥\nEnjoy the delicious cake üçΩÔ∏è\n\n\nReplication"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-2",
    "href": "slides/lec-1_background.html#replication-reproducibility-2",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üç∞",
    "text": "Replication & Reproducibility üç∞\nI want to bake a cake!\nReproduction\n\nFind a recipe online ‚Äì&gt; Find their kitchen\nGet ingredients ‚Äì&gt; Use their ingredients\nFollow recipe and bake ‚Äì&gt; Watch what they do and follow\nEnjoy the delicious cake ‚Äì&gt; Enjoy cake (and jail for B&E)"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-3",
    "href": "slides/lec-1_background.html#replication-reproducibility-3",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üìä",
    "text": "Replication & Reproducibility üìä\n\n\n\n\n\n\n\n\nReplication\nReproducibility\n\n\n\n\nHave a similar research question\nUse the same research question\n\n\nCollect your own data\nUse their data\n\n\nFollow their steps with your resources\nFollow their steps with their resources\n\n\nOutcome: Similar results (depends on other factors)\nOutcome: Identical results"
  },
  {
    "objectID": "slides/lec-1_background.html#replication-reproducibility-4",
    "href": "slides/lec-1_background.html#replication-reproducibility-4",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Replication & Reproducibility üìä",
    "text": "Replication & Reproducibility üìä\nGoals of Science\nImportant: We want to replicate other researchers work\nMOST Important: Be able to reproduce all of our results\nYou are your own worst collaborator!"
  },
  {
    "objectID": "slides/lec-1_background.html#garden-of-forking-paths",
    "href": "slides/lec-1_background.html#garden-of-forking-paths",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Garden of Forking Paths",
    "text": "Garden of Forking Paths"
  },
  {
    "objectID": "slides/lec-1_background.html#installing-and-using-r",
    "href": "slides/lec-1_background.html#installing-and-using-r",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Installing and Using R",
    "text": "Installing and Using R\nFrom the course website\nModern Statistics Using R"
  },
  {
    "objectID": "slides/lec-1_background.html#working-with-r-studio",
    "href": "slides/lec-1_background.html#working-with-r-studio",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Working with R-Studio",
    "text": "Working with R-Studio\nR-Studio is just like a kitchen üßë‚Äçüç≥\nThe Environment pane is the pantry/fridge\nThe Console is like the oven/stove\nThe Markdown document is the recipe\nThe bottom right sometimes acts as the little window on the oven where you can see things baking\nCreating a Project puts these things in their place"
  },
  {
    "objectID": "slides/lec-1_background.html#next-steps",
    "href": "slides/lec-1_background.html#next-steps",
    "title": "Week 01: Getting Started - DATA!",
    "section": "Next Steps",
    "text": "Next Steps\n\nCreate a project\nSet up a Markdown Document\nRun and Knit the document\nLive Example"
  },
  {
    "objectID": "slides/lec-5_correlation.html#today",
    "href": "slides/lec-5_correlation.html#today",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nExplore hypotheses, correlations and effect sizes\n\n# File management\nlibrary(here)\n# for dplyr, ggplot2\nlibrary(tidyverse)\n# Loading data\nlibrary(rio)\n# Pretty tables\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(ggstatsplot)\n\n#Remove Scientific Notation \noptions(scipen=999)"
  },
  {
    "objectID": "slides/lec-5_correlation.html#todays-roadmap",
    "href": "slides/lec-5_correlation.html#todays-roadmap",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Today‚Äôs Roadmap üó∫Ô∏è",
    "text": "Today‚Äôs Roadmap üó∫Ô∏è\n\nExplain the counterintuitive logic of Null Hypothesis Significance Testing (NHST)\nDefine and correctly interpret a p-value\nDistinguish what a p-value is from what it is not\nApply the steps of NHST to a research question"
  },
  {
    "objectID": "slides/lec-5_correlation.html#setting",
    "href": "slides/lec-5_correlation.html#setting",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Setting:",
    "text": "Setting:\nIn 1925, during a summer afternoon on campus, a lady, Dr.¬†Muriel Bristol (who has an algae species named after her), was handed a cup of tea by Ronald Fisher. She declined saying:\n‚ÄúI prefer the flavor when the milk is poured first. I can tell when there is a difference‚Äù\nFisher, being a statistician and a white man:\n‚ÄúProve it‚Äù\n\n\n\n\n\n\nNote\n\n\nSometimes, groundbreaking insights arise from everyday claims!"
  },
  {
    "objectID": "slides/lec-5_correlation.html#designing-the-test",
    "href": "slides/lec-5_correlation.html#designing-the-test",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Designing the Test:",
    "text": "Designing the Test:\nFisher prepared 8 cups of tea; 4 with milk first & 4 with tea first\nDr.¬†Muriel Bristol correctly identified 3 out of 4 of each! (some reports claim she identified all correctly)\nWas it just chance or genuine ability?\n\n\n\n\n\n\nNote\n\n\nAlways consider both outcomes. In hypothesis testing, this means setting up null and alternative hypotheses."
  },
  {
    "objectID": "slides/lec-5_correlation.html#birth-of-hypothesis-testing",
    "href": "slides/lec-5_correlation.html#birth-of-hypothesis-testing",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Birth of Hypothesis Testing:",
    "text": "Birth of Hypothesis Testing:\nFisher framed it as a combinatorial problem\nIf it was mere luck/chance, the probability of getting all 8 correct was low\nThis way of thinking is the groundwork for the concept of the p-value\n\n\n\n\n\n\nImportant\n\n\nThe p-value gives the probability of observing data (or something more extreme) given that the null hypothesis is true."
  },
  {
    "objectID": "slides/lec-5_correlation.html#the-tortured-logic-of-nhst",
    "href": "slides/lec-5_correlation.html#the-tortured-logic-of-nhst",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "The Tortured Logic of NHST",
    "text": "The Tortured Logic of NHST\nWe create two hypotheses, \\(H_0\\) and \\(H_1\\). Usually, we care about \\(H_1\\), not \\(H_0\\). In fact, what we really want to know is how likely \\(H_1\\), given our data.\n\\[P(H_1|Data)\\] Instead, we‚Äôre going to test our null hypothesis. Well, not really. We‚Äôre going to assume our null hypothesis is true, and test how likely we would be to get these data.\n\\[P(Data|H_0)\\]"
  },
  {
    "objectID": "slides/lec-5_correlation.html#nhst-analogy-the-legal-system",
    "href": "slides/lec-5_correlation.html#nhst-analogy-the-legal-system",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "NHST Analogy: The Legal System",
    "text": "NHST Analogy: The Legal System\n\nThe Null Hypothesis ( \\(H_0\\) ) is the starting assumption: ‚Äúpresumed innocent.‚Äù In research, this means assuming there is no effect, no relationship, or no difference.\nYou, the researcher, are the prosecution, gathering evidence (data) to challenge this presumption.\nYour p-value reflects the strength of your evidence. A small p-value likely means your evidence is strong.\nRejecting the null is like a ‚Äúguilty‚Äù verdict. You have enough evidence to say the initial presumption of innocence (no effect) is unlikely to be true."
  },
  {
    "objectID": "slides/lec-5_correlation.html#p-value-formal-definition",
    "href": "slides/lec-5_correlation.html#p-value-formal-definition",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "p-value: Formal Definition",
    "text": "p-value: Formal Definition\nThis is one of the most important‚Äîand misunderstood‚Äîconcepts in statistics.\nThe p-value is:\n\nThe probability of observing a result as extreme as, or more extreme than, the one we actually observed, assuming the null hypothesis is true."
  },
  {
    "objectID": "slides/lec-5_correlation.html#p-value-formal-definition-1",
    "href": "slides/lec-5_correlation.html#p-value-formal-definition-1",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "p-value: Formal Definition",
    "text": "p-value: Formal Definition\nThis is one of the most important‚Äîand misunderstood‚Äîconcepts in statistics.\nIt is NOT:\n\nThe probability that the null hypothesis is true\nThe probability that our research hypothesis is true\nA measure of the size or importance of an effect"
  },
  {
    "objectID": "slides/lec-5_correlation.html#what-are-the-steps-of-nhst",
    "href": "slides/lec-5_correlation.html#what-are-the-steps-of-nhst",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "What are the steps of NHST?",
    "text": "What are the steps of NHST?\n\n\n\nDefine null and alternative hypothesis.\nSet and justify alpha level (usually \\(\\alpha\\) = .05)\nDetermine which sampling distribution ( \\(z\\), \\(t\\), or \\(\\chi^2\\) for now)\nCalculate parameters of your sampling distribution under the null.\n\n\nIf \\(z\\), calculate \\(\\mu\\) and \\(\\sigma_M\\)\n\n\n\nCalculate test statistic under the null.\n\n\nIf \\(z\\), \\(\\frac{\\bar{X} - \\mu}{\\sigma_M}\\)\n\n\nCalculate probability of that test statistic or more extreme under the null, and compare to alpha."
  },
  {
    "objectID": "slides/lec-5_correlation.html#think-about",
    "href": "slides/lec-5_correlation.html#think-about",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "üß† Think about‚Ä¶",
    "text": "üß† Think about‚Ä¶\n\nYou run a correlational analysis to see if levels of anxiety are related to caffeine consumption. You get a correlation of 0.38 and a p-value of p = .045.\n\nTurn to someone next to you and in your own words, explain what the p-value is telling you.\n\nLooking at the p-value, what can you conclude?\nLooking at the p-value, what can‚Äôt you conclude?"
  },
  {
    "objectID": "slides/lec-5_correlation.html#more-thinking",
    "href": "slides/lec-5_correlation.html#more-thinking",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "üß†More thinking‚Ä¶",
    "text": "üß†More thinking‚Ä¶\nWhat if you ran the same study and analyses, but found that your p-value was p = .052?"
  },
  {
    "objectID": "slides/lec-5_correlation.html#what-is-a-correlation",
    "href": "slides/lec-5_correlation.html#what-is-a-correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "What is a Correlation?",
    "text": "What is a Correlation?\nA statistical expression that quantifies the extent to which two continuous variables are linearly related\nAssociation - Correlation\nWill tell us 2 key pieces of information about the relationship:\n\nDirection (Positive vs.¬†Negative)\nStrength (Magnitude from 0 to 1)"
  },
  {
    "objectID": "slides/lec-5_correlation.html#example-candy-of-houses",
    "href": "slides/lec-5_correlation.html#example-candy-of-houses",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Example: Candy & # of Houses",
    "text": "Example: Candy & # of Houses\nResearch Question: Is there a relationship between the amount of candy we receive on Halloween and the # of houses that we go to?\n\nVariables:\n\nhouse_n: Number of houses approached\ncandy: Amount of candy (# of pieces)\n\nHypothesis \\(H_A\\) : There will be a positive correlation. As a trick-or-treater goes to more houses, their amount of candy will increase ( \\(r \\neq 0\\) .\nNull Hypothesis \\(H_0\\): There is no correlation ( \\(r = 0\\) )."
  },
  {
    "objectID": "slides/lec-5_correlation.html#association---covariance",
    "href": "slides/lec-5_correlation.html#association---covariance",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Association - Covariance",
    "text": "Association - Covariance\nBefore we talk about correlation, we need to take a look at covariance\n\\[\ncov_{xy} = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{N-1}\n\\]\n\nCovariance can be thought of as the ‚Äúaverage cross product‚Äù between two variables\nIt captures the raw/unstandardized relationship between two variables\nCovariance matrix is the basis for many statistical analyses"
  },
  {
    "objectID": "slides/lec-5_correlation.html#covariance-to-correlation",
    "href": "slides/lec-5_correlation.html#covariance-to-correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Covariance to Correlation",
    "text": "Covariance to Correlation\nThe Pearson correlation coefficient \\(r\\) addresses this by standardizing the covariance\nIt is done in the same way that we would create a \\(z-score\\)‚Ä¶by dividing by the standard deviation\n\\[\nr_{xy} = \\frac{Cov(x,y)}{sd_x sd_y}\n\\]"
  },
  {
    "objectID": "slides/lec-5_correlation.html#pearsons-r",
    "href": "slides/lec-5_correlation.html#pearsons-r",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Pearson‚Äôs \\(r\\)",
    "text": "Pearson‚Äôs \\(r\\)\nRange: Varies from -1 (perfect negative correlation) and +1 (perfect positive correlation)\nAssumptions:\n\nContinuous Variables: Both variables are measured on an interval or ratio scale.\nLinearity: The relationship between the variables is linear. (This is why you must visualize your data!)\nBivariate Normality: Data points are normally distributed for both variables. (Pearson‚Äôs \\(r\\) is fairly robust to minor violations)."
  },
  {
    "objectID": "slides/lec-5_correlation.html#calculating-correlation-in-r",
    "href": "slides/lec-5_correlation.html#calculating-correlation-in-r",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Calculating Correlation in R",
    "text": "Calculating Correlation in R\nNow how do we get a correlation value in R?\n\ncor(corr_data$house_n, corr_data$candy)\n\n[1] 0.8929946\n\n\nThat will give us the correlation, but we also want to know how to get our p-value"
  },
  {
    "objectID": "slides/lec-5_correlation.html#significance",
    "href": "slides/lec-5_correlation.html#significance",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Significance",
    "text": "Significance\nThe \\(p-value\\) gives us the statistical significance. It will tell us that the effect we identified is likely not to be 0\nIt does not tell us anything about how large or meaningful the effect actually is. This is where the effect size comes in!\n\n\n\n\n\n\nImportant\n\n\nWith a large enough sample size, even a tiny, trivial correlation (e.g., r &lt; 0.1) can become statistically significant. Think about what happens to sampling distribution when sample size increases.\n\n\n\nStatistical Significance \\(\\neq\\) Practical Significance"
  },
  {
    "objectID": "slides/lec-5_correlation.html#effect-sizes-correlation",
    "href": "slides/lec-5_correlation.html#effect-sizes-correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Effect Sizes: Correlation",
    "text": "Effect Sizes: Correlation\nFor correlation, we have two related measures of effect size:\n\nPearson‚Äôs \\(r\\): The correlation coefficient itself. A standardized measure of the strength and direction of the linear association.\n\nCohen‚Äôs Conventions (a rough guide): Small (‚à£.10‚à£), Medium (‚à£.30‚à£), Large (‚à£.50‚à£).\nOur finding of \\(r = 0.89\\) is a large effect.\n\nCoefficient of Determination (\\(R^2\\)): This is simply r squared. It represents the proportion of variance in one variable that is ‚Äúexplained‚Äù or ‚Äúaccounted for‚Äù by the other."
  },
  {
    "objectID": "slides/lec-5_correlation.html#age-x-ess_total-visualize",
    "href": "slides/lec-5_correlation.html#age-x-ess_total-visualize",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Age x ESS_total: Visualize",
    "text": "Age x ESS_total: Visualize\nLet‚Äôs examine the overall correlation between Age and overall sleepiness\nFirst: Visualize\n\n\nCode\nsleep_data %&gt;% \n  ggplot(aes(age, ess_tot)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE)\n\n\n\nIt doesn‚Äôt seem like there is much of a relationship here‚Ä¶"
  },
  {
    "objectID": "slides/lec-5_correlation.html#age-x-ess_total-test",
    "href": "slides/lec-5_correlation.html#age-x-ess_total-test",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Age x ESS_total: Test",
    "text": "Age x ESS_total: Test\nLet‚Äôs check the overall correlation just to see what we are finding\n\ncor.test(sleep_data$age, sleep_data$ess_tot)\n\n\n    Pearson's product-moment correlation\n\ndata:  sleep_data$age and sleep_data$ess_tot\nt = -2.2489, df = 1450, p-value = 0.02467\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.110064846 -0.007534546\nsample estimates:\n        cor \n-0.05895518"
  },
  {
    "objectID": "slides/lec-5_correlation.html#writing-up-example",
    "href": "slides/lec-5_correlation.html#writing-up-example",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Writing up: Example",
    "text": "Writing up: Example\nWe have all of the pieces for writing up our correlation between age and sleepiness.\nTemplate: r(degress of freedom) = the r statistic, p = p value.\n\nAmong the students in the sample, age was negatively related to overall levels of sleepiness (r(1450) = -0.06, p = .024).\n\nWhat about our \\(R^2\\) value?\n\\(R^2 = -0.06^2 = 0.0034\\). Therefore, approximately 0.34% of the variability in the sleepiness scale (ess_tot) is explained by age. Is this meaningful?"
  },
  {
    "objectID": "slides/lec-5_correlation.html#handling-missing---correlation",
    "href": "slides/lec-5_correlation.html#handling-missing---correlation",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Handling Missing - Correlation",
    "text": "Handling Missing - Correlation\n\nListwise Deletion (complete cases)\n\nRemoves participants completely if they are missing a value being compared\nSmaller Sample Sizes\nDoesn‚Äôt bias correlation estimate\n\nPairwise Deletion\n\nRemoves participants for that single pair, but leaves information in when there are complete information\nLarger Sample Sizes\nCould bias estimates if there is a systematic reason things are missing"
  },
  {
    "objectID": "slides/lec-5_correlation.html#spearmans-rank-correlation-1",
    "href": "slides/lec-5_correlation.html#spearmans-rank-correlation-1",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Spearman‚Äôs Rank Correlation",
    "text": "Spearman‚Äôs Rank Correlation\nWe need to be able to capture this different (ordinal) ‚Äúrelationship‚Äù\n\nIf student 1 works more hours than student 2, then we can guarantee that student 1 will get a better grade\n\nInstead of using the amount given by the variables (‚Äúhours studied‚Äù), we rank the variables based on least (rank = 1) to most (rank = 10)\nThen we correlate the rankings with one another"
  },
  {
    "objectID": "slides/lec-5_correlation.html#statistics-and-eugenics",
    "href": "slides/lec-5_correlation.html#statistics-and-eugenics",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Statistics and Eugenics",
    "text": "Statistics and Eugenics\nThe concept of the correlation is primarily attributed to Sir Frances Galton\n\nHe was also the founder of the concept of eugenics\n\nThe correlation coefficient was developed by his student, Karl Pearson, and adapted into the ANOVA framework by Sir Ronald Fisher\n\nBoth were prominent advocates for the eugenics movement"
  },
  {
    "objectID": "slides/lec-5_correlation.html#what-do-we-do-with-this-info",
    "href": "slides/lec-5_correlation.html#what-do-we-do-with-this-info",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "What do we do with this info?",
    "text": "What do we do with this info?\n\nNever use the correlation or the later techniques developed on it? Of course not.\nAcknowledge this history? Certainly.\nUnderstand how the perspectives of Galton, Fisher, Pearson and others shaped our practices? We must! ‚Äì these are not set in stone, nor are they necessarily the best way to move forward."
  },
  {
    "objectID": "slides/lec-5_correlation.html#be-aware-of-the-assumptions",
    "href": "slides/lec-5_correlation.html#be-aware-of-the-assumptions",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Be aware of the assumptions",
    "text": "Be aware of the assumptions\n\nStatistics are often thought of as being absent of bias‚Ä¶they are just numbers\nStatistical significance was a way to avoid talking about nuance or degree.\n‚ÄúCorrelation does not imply causation‚Äù was a refutation of work demonstrating associations between environment and poverty.\nNeed to be particularly mindful of our goals as scientists and how they can influence the way we interpret the findings"
  },
  {
    "objectID": "slides/lec-5_correlation.html#correlation-tables",
    "href": "slides/lec-5_correlation.html#correlation-tables",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Correlation Tables",
    "text": "Correlation Tables\nBefore we used the cor() function to create a correlation matrix of our variables\nBut what is missing?\n\nsleep_data %&gt;% \n  select(age, ESS1:ESS8, ess_tot) %&gt;% \n  cor(use = \"complete\") %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nESS1\nESS2\nESS3\nESS4\nESS5\nESS6\nESS7\nESS8\ness_tot\n\n\n\n\nage\n1.0000000\n-0.0057641\n0.0039691\n-0.0421214\n-0.1059506\n-0.0871016\n0.0484763\n0.0057761\n-0.0206676\n-0.0594733\n\n\nESS1\n-0.0057641\n1.0000000\n0.3303236\n0.2784836\n0.1455593\n0.2295289\n0.1422071\n0.2206383\n0.0984444\n0.5981508\n\n\nESS2\n0.0039691\n0.3303236\n1.0000000\n0.1976108\n0.1387409\n0.2190331\n0.1748049\n0.2134999\n0.1010883\n0.5565852\n\n\nESS3\n-0.0421214\n0.2784836\n0.1976108\n1.0000000\n0.2920448\n0.1948408\n0.2888370\n0.2778982\n0.2178073\n0.6121220\n\n\nESS4\n-0.1059506\n0.1455593\n0.1387409\n0.2920448\n1.0000000\n0.2579808\n0.0897873\n0.2589136\n0.2409171\n0.5936136\n\n\nESS5\n-0.0871016\n0.2295289\n0.2190331\n0.1948408\n0.2579808\n1.0000000\n0.0704590\n0.2821851\n0.0629151\n0.5718083\n\n\nESS6\n0.0484763\n0.1422071\n0.1748049\n0.2888370\n0.0897873\n0.0704590\n1.0000000\n0.2833070\n0.3493524\n0.4143559\n\n\nESS7\n0.0057761\n0.2206383\n0.2134999\n0.2778982\n0.2589136\n0.2821851\n0.2833070\n1.0000000\n0.2356524\n0.6088579\n\n\nESS8\n-0.0206676\n0.0984444\n0.1010883\n0.2178073\n0.2409171\n0.0629151\n0.3493524\n0.2356524\n1.0000000\n0.4293874\n\n\ness_tot\n-0.0594733\n0.5981508\n0.5565852\n0.6121220\n0.5936136\n0.5718083\n0.4143559\n0.6088579\n0.4293874\n1.0000000"
  },
  {
    "objectID": "slides/lec-5_correlation.html#correlation-tables---sjplot",
    "href": "slides/lec-5_correlation.html#correlation-tables---sjplot",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Correlation Tables - sjPlot",
    "text": "Correlation Tables - sjPlot\n\nsleep_data %&gt;% \n  select(ESS1:ESS8) %&gt;% \n  tab_corr(na.deletion = \"listwise\", triangle = \"lower\")\n\n\n\n\n¬†\nESS1\nESS2\nESS3\nESS4\nESS5\nESS6\nESS7\nESS8\n\n\nESS1\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS2\n0.330***\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS3\n0.278***\n0.198***\n¬†\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS4\n0.146***\n0.139***\n0.292***\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nESS5\n0.230***\n0.219***\n0.195***\n0.258***\n¬†\n¬†\n¬†\n¬†\n\n\nESS6\n0.142***\n0.175***\n0.289***\n0.090***\n0.070**\n¬†\n¬†\n¬†\n\n\nESS7\n0.221***\n0.213***\n0.278***\n0.259***\n0.282***\n0.283***\n¬†\n¬†\n\n\nESS8\n0.098***\n0.101***\n0.218***\n0.241***\n0.063*\n0.349***\n0.236***\n¬†\n\n\nComputed correlation used pearson-method with listwise-deletion."
  },
  {
    "objectID": "slides/lec-5_correlation.html#correlation-tables---sjplot-1",
    "href": "slides/lec-5_correlation.html#correlation-tables---sjplot-1",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Correlation Tables - sjPlot",
    "text": "Correlation Tables - sjPlot\nSo many different cusomizations for this type of plot\nCan add titles, indicate what missingness and method\nSaves you a TON of time when putting it into a manuscript"
  },
  {
    "objectID": "slides/lec-5_correlation.html#scatterplot",
    "href": "slides/lec-5_correlation.html#scatterplot",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Scatterplot",
    "text": "Scatterplot\nBefore we had a scatterplot that looked like this:\n\nsleep_data %&gt;% \n  ggplot(aes(age, ess_tot)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) + \n  labs(\n    x = \"Age\", \n    y = \"ESS Total\", \n    title = \"Relationship between Age and Sleepiness\" \n  )"
  },
  {
    "objectID": "slides/lec-5_correlation.html#fancier-scatterplot",
    "href": "slides/lec-5_correlation.html#fancier-scatterplot",
    "title": "Week 05: Correlation & Effect Sizes",
    "section": "Fancier Scatterplot",
    "text": "Fancier Scatterplot\nTake a look at ggstatsplot https://indrajeetpatil.github.io/ggstatsplot/\n\nggscatterstats(\n  data = sleep_data, \n  x = age, \n  y = ess_tot, \n  xlab = \"Age\", \n  ylab = \"ESS Total\", \n  title = \"Relationship between Age and Sleepiness\"\n)"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#some-terminology",
    "href": "slides/lec-3_desc-viz.html#some-terminology",
    "title": "Week 03: Describe & Vizualize",
    "section": "Some Terminology",
    "text": "Some Terminology\n\n\n\n\n\n\n\nPopulation\nSample\n\n\n\n\n\\(\\mu\\) (mu) = Population Mean\n\\(\\bar{X}\\) (x bar) = Sample Mean\n\n\n\\(\\sigma\\) (sigma) = Population Standard Deviation\n\\(s\\) = \\(\\hat{\\sigma}\\) = Sample Standard Deviation\n\n\n\\(\\sigma^2\\) (sigma squared) = Population Variance\n\\(s^2\\) = \\(\\hat{\\sigma^2}\\) = Sample Variance"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#measures-of-central-tendency",
    "href": "slides/lec-3_desc-viz.html#measures-of-central-tendency",
    "title": "Week 03: Describe & Vizualize",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nFor a given set of observations, measures of central tendency allow us to get the ‚Äúgist‚Äù of the data.\nThey tell us about where the ‚Äúaverage‚Äù or the ‚Äúmid-point‚Äù of the data lies or how much deviation there is from a central point.\nLet‚Äôs take a look at the data that we have already loaded in, and complete some of these tasks."
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#measures-of-variability",
    "href": "slides/lec-3_desc-viz.html#measures-of-variability",
    "title": "Week 03: Describe & Vizualize",
    "section": "Measures of Variability",
    "text": "Measures of Variability\nThe overall spread of the data; How far from the middle?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#variance",
    "href": "slides/lec-3_desc-viz.html#variance",
    "title": "Week 03: Describe & Vizualize",
    "section": "Variance",
    "text": "Variance\nThe sum of squared deviations\n\\[\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^N(X-\\bar{X})^2\\]\n\\[\\hat{\\sigma}^2 = s^2 = \\frac{1}{N-1}\\sum_{i=1}^N(X-\\bar{X})^2\\]"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#in-class-activity-variance",
    "href": "slides/lec-3_desc-viz.html#in-class-activity-variance",
    "title": "Week 03: Describe & Vizualize",
    "section": "In-Class Activity: Variance",
    "text": "In-Class Activity: Variance\nOpen up Instagram (that is still a thing right?)\nIdentify a celebrity and look at their most recent Instagram posts.\nLet‚Äôs calculate the variance of their likes.\nGoogle Form"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#variance-in-r",
    "href": "slides/lec-3_desc-viz.html#variance-in-r",
    "title": "Week 03: Describe & Vizualize",
    "section": "Variance in R",
    "text": "Variance in R\nTo find the variance and standard deviation, we use var() and sd(), respectively. Find the variance and standard deviation of the age variable.\n\nvar(tipi$age)\n\n[1] 3.399093\n\nsd(tipi$age)\n\n[1] 1.843663"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#describe",
    "href": "slides/lec-3_desc-viz.html#describe",
    "title": "Week 03: Describe & Vizualize",
    "section": "describe()",
    "text": "describe()\nThis function automatically calculates all of the descriptives we reviewed above (and more!). Use the describe() function from the psych package on the entire sleep_data dataset.\nNotes: If you load a library at the beginning, you can directly call any function from it. Instead, you can call a function by library_name::function_name without loading the entire library.\n\npsych::describe(tipi)\n\n                    vars  n    mean       sd median trimmed    mad    min\nid                     1 99 1058.12    31.05 1059.0 1057.93  38.55 1006.0\nprogress               2 99  100.00     0.00  100.0  100.00   0.00  100.0\nduration_in_seconds    3 99 7197.29 34904.64 1461.0 1527.88 486.29  623.0\nconsent                4 99    1.00     0.00    1.0    1.00   0.00    1.0\ngenderid               5 99    4.46     0.82    4.0    4.47   1.48    1.0\ngenderid_7_text*       6 99    1.03     0.22    1.0    1.00   0.00    1.0\nsex                    7 99    1.51     0.50    2.0    1.51   0.00    1.0\nage                    8 99   19.78     1.84   20.0   19.53   1.48   17.0\nyear_school            9 99    2.18     1.22    2.0    2.04   1.48    1.0\nq85                   10 99    1.64     1.32    1.0    1.32   0.00    1.0\nq85_6_text*           11 99    1.03     0.22    1.0    1.00   0.00    1.0\ntipi_1                12 99    3.99     1.90    4.0    3.99   2.97    1.0\ntipi_2                13 99    4.15     1.53    4.0    4.23   1.48    1.0\ntipi_3                14 99    5.38     1.26    6.0    5.51   1.48    1.0\ntipi_4                15 99    4.29     1.69    5.0    4.31   1.48    1.0\ntipi_5                16 99    5.38     1.28    6.0    5.52   1.48    1.0\ntipi_6                17 99    4.76     1.64    5.0    4.84   1.48    1.0\ntipi_7                18 99    5.45     1.24    6.0    5.57   1.48    2.0\ntipi_8                19 99    3.17     1.70    3.0    3.09   1.48    1.0\ntipi_9                20 99    5.01     1.35    5.0    5.05   1.48    2.0\ntipi_10               21 99    3.10     1.48    3.0    3.04   1.48    1.0\nsleep_quality         22 99    2.56     1.15    2.0    2.46   1.48    1.0\nhours_of_sleep        23 99    6.51     1.04    7.0    6.63   0.00    1.0\ntipi_2r               24 99    3.85     1.53    4.0    3.77   1.48    1.0\ntipi_4r               25 99    3.71     1.69    3.0    3.69   1.48    1.0\ntipi_6r               26 99    3.24     1.64    3.0    3.16   1.48    1.0\ntipi_8r               27 99    4.83     1.70    5.0    4.91   1.48    1.0\ntipi_10r              28 99    4.90     1.48    5.0    4.96   1.48    1.0\nextra                 29 99    3.62     1.60    3.5    3.56   2.22    1.0\nagree                 30 99    4.65     1.08    4.5    4.63   0.74    2.0\nconsc                 31 99    5.11     1.22    5.5    5.15   1.48    2.0\nemo                   32 99    4.36     1.29    4.5    4.37   1.48    1.5\nopen                  33 99    5.14     1.04    5.0    5.19   0.74    2.5\n                       max    range  skew kurtosis      se\nid                    1112    106.0  0.03    -1.21    3.12\nprogress               100      0.0   NaN      NaN    0.00\nduration_in_seconds 252521 251898.0  6.57    42.24 3508.05\nconsent                  1      0.0   NaN      NaN    0.00\ngenderid                 7      6.0 -0.81     5.57    0.08\ngenderid_7_text*         3      2.0  7.70    61.15    0.02\nsex                      2      1.0 -0.02    -2.02    0.05\nage                     31     14.0  2.67    12.52    0.19\nyear_school              5      4.0  0.73    -0.44    0.12\nq85                      7      6.0  2.18     4.14    0.13\nq85_6_text*              3      2.0  7.70    61.15    0.02\ntipi_1                   7      6.0  0.01    -1.34    0.19\ntipi_2                   7      6.0 -0.46    -0.58    0.15\ntipi_3                   7      6.0 -0.86     0.58    0.13\ntipi_4                   7      6.0 -0.17    -0.95    0.17\ntipi_5                   7      6.0 -0.94     0.86    0.13\ntipi_6                   7      6.0 -0.46    -0.86    0.17\ntipi_7                   7      5.0 -0.65    -0.08    0.12\ntipi_8                   7      6.0  0.37    -1.12    0.17\ntipi_9                   7      5.0 -0.29    -0.81    0.14\ntipi_10                  7      6.0  0.35    -0.71    0.15\nsleep_quality            5      4.0  0.87     0.14    0.12\nhours_of_sleep           8      7.0 -2.01     5.99    0.10\ntipi_2r                  7      6.0  0.46    -0.58    0.15\ntipi_4r                  7      6.0  0.17    -0.95    0.17\ntipi_6r                  7      6.0  0.46    -0.86    0.17\ntipi_8r                  7      6.0 -0.37    -1.12    0.17\ntipi_10r                 7      6.0 -0.35    -0.71    0.15\nextra                    7      6.0  0.18    -0.98    0.16\nagree                    7      5.0  0.11     0.04    0.11\nconsc                    7      5.0 -0.32    -0.70    0.12\nemo                      7      5.5 -0.10    -0.54    0.13\nopen                     7      4.5 -0.48     0.13    0.10\n\n# or if you have already loaded the library\n\ndescribe(tipi)\n\n                    vars  n    mean       sd median trimmed    mad    min\nid                     1 99 1058.12    31.05 1059.0 1057.93  38.55 1006.0\nprogress               2 99  100.00     0.00  100.0  100.00   0.00  100.0\nduration_in_seconds    3 99 7197.29 34904.64 1461.0 1527.88 486.29  623.0\nconsent                4 99    1.00     0.00    1.0    1.00   0.00    1.0\ngenderid               5 99    4.46     0.82    4.0    4.47   1.48    1.0\ngenderid_7_text*       6 99    1.03     0.22    1.0    1.00   0.00    1.0\nsex                    7 99    1.51     0.50    2.0    1.51   0.00    1.0\nage                    8 99   19.78     1.84   20.0   19.53   1.48   17.0\nyear_school            9 99    2.18     1.22    2.0    2.04   1.48    1.0\nq85                   10 99    1.64     1.32    1.0    1.32   0.00    1.0\nq85_6_text*           11 99    1.03     0.22    1.0    1.00   0.00    1.0\ntipi_1                12 99    3.99     1.90    4.0    3.99   2.97    1.0\ntipi_2                13 99    4.15     1.53    4.0    4.23   1.48    1.0\ntipi_3                14 99    5.38     1.26    6.0    5.51   1.48    1.0\ntipi_4                15 99    4.29     1.69    5.0    4.31   1.48    1.0\ntipi_5                16 99    5.38     1.28    6.0    5.52   1.48    1.0\ntipi_6                17 99    4.76     1.64    5.0    4.84   1.48    1.0\ntipi_7                18 99    5.45     1.24    6.0    5.57   1.48    2.0\ntipi_8                19 99    3.17     1.70    3.0    3.09   1.48    1.0\ntipi_9                20 99    5.01     1.35    5.0    5.05   1.48    2.0\ntipi_10               21 99    3.10     1.48    3.0    3.04   1.48    1.0\nsleep_quality         22 99    2.56     1.15    2.0    2.46   1.48    1.0\nhours_of_sleep        23 99    6.51     1.04    7.0    6.63   0.00    1.0\ntipi_2r               24 99    3.85     1.53    4.0    3.77   1.48    1.0\ntipi_4r               25 99    3.71     1.69    3.0    3.69   1.48    1.0\ntipi_6r               26 99    3.24     1.64    3.0    3.16   1.48    1.0\ntipi_8r               27 99    4.83     1.70    5.0    4.91   1.48    1.0\ntipi_10r              28 99    4.90     1.48    5.0    4.96   1.48    1.0\nextra                 29 99    3.62     1.60    3.5    3.56   2.22    1.0\nagree                 30 99    4.65     1.08    4.5    4.63   0.74    2.0\nconsc                 31 99    5.11     1.22    5.5    5.15   1.48    2.0\nemo                   32 99    4.36     1.29    4.5    4.37   1.48    1.5\nopen                  33 99    5.14     1.04    5.0    5.19   0.74    2.5\n                       max    range  skew kurtosis      se\nid                    1112    106.0  0.03    -1.21    3.12\nprogress               100      0.0   NaN      NaN    0.00\nduration_in_seconds 252521 251898.0  6.57    42.24 3508.05\nconsent                  1      0.0   NaN      NaN    0.00\ngenderid                 7      6.0 -0.81     5.57    0.08\ngenderid_7_text*         3      2.0  7.70    61.15    0.02\nsex                      2      1.0 -0.02    -2.02    0.05\nage                     31     14.0  2.67    12.52    0.19\nyear_school              5      4.0  0.73    -0.44    0.12\nq85                      7      6.0  2.18     4.14    0.13\nq85_6_text*              3      2.0  7.70    61.15    0.02\ntipi_1                   7      6.0  0.01    -1.34    0.19\ntipi_2                   7      6.0 -0.46    -0.58    0.15\ntipi_3                   7      6.0 -0.86     0.58    0.13\ntipi_4                   7      6.0 -0.17    -0.95    0.17\ntipi_5                   7      6.0 -0.94     0.86    0.13\ntipi_6                   7      6.0 -0.46    -0.86    0.17\ntipi_7                   7      5.0 -0.65    -0.08    0.12\ntipi_8                   7      6.0  0.37    -1.12    0.17\ntipi_9                   7      5.0 -0.29    -0.81    0.14\ntipi_10                  7      6.0  0.35    -0.71    0.15\nsleep_quality            5      4.0  0.87     0.14    0.12\nhours_of_sleep           8      7.0 -2.01     5.99    0.10\ntipi_2r                  7      6.0  0.46    -0.58    0.15\ntipi_4r                  7      6.0  0.17    -0.95    0.17\ntipi_6r                  7      6.0  0.46    -0.86    0.17\ntipi_8r                  7      6.0 -0.37    -1.12    0.17\ntipi_10r                 7      6.0 -0.35    -0.71    0.15\nextra                    7      6.0  0.18    -0.98    0.16\nagree                    7      5.0  0.11     0.04    0.11\nconsc                    7      5.0 -0.32    -0.70    0.12\nemo                      7      5.5 -0.10    -0.54    0.13\nopen                     7      4.5 -0.48     0.13    0.10\n\n\nNOTE: Some variables are not numeric and are categorical variables of type character. By default, the describe() function forces non-numeric variables to be numeric and attempts to calculate descriptives for them. These variables are marked with an asterisk (*). In this case, it doesn‚Äôt make sense to calculate descriptive statistics for these variables, so we get a warning message and a bunch of NaN‚Äôs and NA‚Äôs for these variables.\nA better approach would be to remove non-numeric variables before you attempt to run numerical calculations on your dataset."
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#make-it-pretty",
    "href": "slides/lec-3_desc-viz.html#make-it-pretty",
    "title": "Week 03: Describe & Vizualize",
    "section": "Make it Pretty",
    "text": "Make it Pretty\nUsing sjPlot (https://strengejacke.github.io/sjPlot/index.html) we can make things a little more publishable! You can use select() to also keep particular variables (maybe you don‚Äôt care about the skew)\n\ntipi %&gt;% \n  psych::describe() %&gt;% \n  sjPlot::tab_df()\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n1\n99\n1058.12\n31.05\n1059.00\n1057.93\n38.55\n1006.00\n1112\n106.00\n0.03\n-1.21\n3.12\n\n\n2\n99\n100.00\n0.00\n100.00\n100.00\n0.00\n100.00\n100\n0.00\nNaN\nNaN\n0.00\n\n\n3\n99\n7197.29\n34904.64\n1461.00\n1527.88\n486.29\n623.00\n252521\n251898.00\n6.57\n42.24\n3508.05\n\n\n4\n99\n1.00\n0.00\n1.00\n1.00\n0.00\n1.00\n1\n0.00\nNaN\nNaN\n0.00\n\n\n5\n99\n4.46\n0.82\n4.00\n4.47\n1.48\n1.00\n7\n6.00\n-0.81\n5.57\n0.08\n\n\n6\n99\n1.03\n0.22\n1.00\n1.00\n0.00\n1.00\n3\n2.00\n7.70\n61.15\n0.02\n\n\n7\n99\n1.51\n0.50\n2.00\n1.51\n0.00\n1.00\n2\n1.00\n-0.02\n-2.02\n0.05\n\n\n8\n99\n19.78\n1.84\n20.00\n19.53\n1.48\n17.00\n31\n14.00\n2.67\n12.52\n0.19\n\n\n9\n99\n2.18\n1.22\n2.00\n2.04\n1.48\n1.00\n5\n4.00\n0.73\n-0.44\n0.12\n\n\n10\n99\n1.64\n1.32\n1.00\n1.32\n0.00\n1.00\n7\n6.00\n2.18\n4.14\n0.13\n\n\n11\n99\n1.03\n0.22\n1.00\n1.00\n0.00\n1.00\n3\n2.00\n7.70\n61.15\n0.02\n\n\n12\n99\n3.99\n1.90\n4.00\n3.99\n2.97\n1.00\n7\n6.00\n0.01\n-1.34\n0.19\n\n\n13\n99\n4.15\n1.53\n4.00\n4.23\n1.48\n1.00\n7\n6.00\n-0.46\n-0.58\n0.15\n\n\n14\n99\n5.38\n1.26\n6.00\n5.51\n1.48\n1.00\n7\n6.00\n-0.86\n0.58\n0.13\n\n\n15\n99\n4.29\n1.69\n5.00\n4.31\n1.48\n1.00\n7\n6.00\n-0.17\n-0.95\n0.17\n\n\n16\n99\n5.38\n1.28\n6.00\n5.52\n1.48\n1.00\n7\n6.00\n-0.94\n0.86\n0.13\n\n\n17\n99\n4.76\n1.64\n5.00\n4.84\n1.48\n1.00\n7\n6.00\n-0.46\n-0.86\n0.17\n\n\n18\n99\n5.45\n1.24\n6.00\n5.57\n1.48\n2.00\n7\n5.00\n-0.65\n-0.08\n0.12\n\n\n19\n99\n3.17\n1.70\n3.00\n3.09\n1.48\n1.00\n7\n6.00\n0.37\n-1.12\n0.17\n\n\n20\n99\n5.01\n1.35\n5.00\n5.05\n1.48\n2.00\n7\n5.00\n-0.29\n-0.81\n0.14\n\n\n21\n99\n3.10\n1.48\n3.00\n3.04\n1.48\n1.00\n7\n6.00\n0.35\n-0.71\n0.15\n\n\n22\n99\n2.56\n1.15\n2.00\n2.46\n1.48\n1.00\n5\n4.00\n0.87\n0.14\n0.12\n\n\n23\n99\n6.51\n1.04\n7.00\n6.63\n0.00\n1.00\n8\n7.00\n-2.01\n5.99\n0.10\n\n\n24\n99\n3.85\n1.53\n4.00\n3.77\n1.48\n1.00\n7\n6.00\n0.46\n-0.58\n0.15\n\n\n25\n99\n3.71\n1.69\n3.00\n3.69\n1.48\n1.00\n7\n6.00\n0.17\n-0.95\n0.17\n\n\n26\n99\n3.24\n1.64\n3.00\n3.16\n1.48\n1.00\n7\n6.00\n0.46\n-0.86\n0.17\n\n\n27\n99\n4.83\n1.70\n5.00\n4.91\n1.48\n1.00\n7\n6.00\n-0.37\n-1.12\n0.17\n\n\n28\n99\n4.90\n1.48\n5.00\n4.96\n1.48\n1.00\n7\n6.00\n-0.35\n-0.71\n0.15\n\n\n29\n99\n3.62\n1.60\n3.50\n3.56\n2.22\n1.00\n7\n6.00\n0.18\n-0.98\n0.16\n\n\n30\n99\n4.65\n1.08\n4.50\n4.63\n0.74\n2.00\n7\n5.00\n0.11\n0.04\n0.11\n\n\n31\n99\n5.11\n1.22\n5.50\n5.15\n1.48\n2.00\n7\n5.00\n-0.32\n-0.70\n0.12\n\n\n32\n99\n4.36\n1.29\n4.50\n4.37\n1.48\n1.50\n7\n5.50\n-0.10\n-0.54\n0.13\n\n\n33\n99\n5.14\n1.04\n5.00\n5.19\n0.74\n2.50\n7\n4.50\n-0.48\n0.13\n0.10"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#ggplot2-from-the-tidyverse",
    "href": "slides/lec-3_desc-viz.html#ggplot2-from-the-tidyverse",
    "title": "Week 03: Describe & Vizualize",
    "section": "ggplot2 from the tidyverse",
    "text": "ggplot2 from the tidyverse\nSince we have already installed and loaded the library, we don‚Äôt have to do anything else at this point!\nggplot2 follows the ‚Äúgrammar of graphics‚Äù\n\nTheoretical framework for creating data visualizations\nBreaks the process down into separate components:\n\n\n\nData\nAesthetics (aes)\nGeometric Objects (geoms)\n\nFaceting\nThemes"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#grammar-of-graphics",
    "href": "slides/lec-3_desc-viz.html#grammar-of-graphics",
    "title": "Week 03: Describe & Vizualize",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#ggplot2-syntax",
    "href": "slides/lec-3_desc-viz.html#ggplot2-syntax",
    "title": "Week 03: Describe & Vizualize",
    "section": "ggplot2 syntax",
    "text": "ggplot2 syntax\nThere is a basic structure to create a plot within ggplot2, and consists of at least these three things:\n\nA Data Set\nCoordinate System\nGeoms - visual marks to represent the data points\n\nIn R it looks like this:\n\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;))\n\n#or how I like to do it\n&lt;DATA&gt; %&gt;% \n  ggplot(aes(&lt;MAPPINGS&gt;)) + \n  &lt;GEOM_FUNCTION&gt;()"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#ggplot2-syntax-1",
    "href": "slides/lec-3_desc-viz.html#ggplot2-syntax-1",
    "title": "Week 03: Describe & Vizualize",
    "section": "ggplot2 syntax",
    "text": "ggplot2 syntax\nLet‚Äôs start with a basic figure with our TIPI data\nFirst we will define the data that we are using and the variables we are visualizing\n\n#the dataset is called penguins\n\ntipi %&gt;% \n  #including the variables we want to visualize\n  ggplot(aes(x = emo, \n             y = extra))\n\nWhat happens?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#adding-in-color",
    "href": "slides/lec-3_desc-viz.html#adding-in-color",
    "title": "Week 03: Describe & Vizualize",
    "section": "Adding in Color",
    "text": "Adding in Color\nMaybe we would like to have each of the points colored by their respective sex\nThis information will be added to the aes() within the geom_point() layer\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex))"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#including-a-fit-line",
    "href": "slides/lec-3_desc-viz.html#including-a-fit-line",
    "title": "Week 03: Describe & Vizualize",
    "section": "Including a fit line",
    "text": "Including a fit line\nWhy don‚Äôt we put in a line that represents the relationship between these variables?\nWe will want to add another layer/geom\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth()\n\n\nThat looks a little wonky‚Ä¶why is that? Did you get a note in the console?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#including-a-fit-line-1",
    "href": "slides/lec-3_desc-viz.html#including-a-fit-line-1",
    "title": "Week 03: Describe & Vizualize",
    "section": "Including a fit line",
    "text": "Including a fit line\nThe geom_smooth() defaults to using a loess line to fit to the data\nIn order to update that, we need to change some of the defaults for that layer and specify that we want a ‚Äúlinear model‚Äù or lm function to the data\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm')\n\n\nDid that look a little better?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#individual-fit-lines",
    "href": "slides/lec-3_desc-viz.html#individual-fit-lines",
    "title": "Week 03: Describe & Vizualize",
    "section": "Individual fit lines",
    "text": "Individual fit lines\nIt might make more sense to have individual lines for each of the species instead of something that is across all\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra, \n             color = sex)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm')\n\n\nWhat did we move around from the last set of code?\nWhat was the error you got?"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#data-types",
    "href": "slides/lec-3_desc-viz.html#data-types",
    "title": "Week 03: Describe & Vizualize",
    "section": "Data Types",
    "text": "Data Types\nIt looks like R is looking at our binary variable as a continuous number\nWe want to be able to tell our code that these are categories/factors\nIf we want to change or compute a new variable, what do we use?\n\n\ntipi &lt;- tipi %&gt;% \n  mutate(sex = as.factor(sex))"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#updating-labelstitle",
    "href": "slides/lec-3_desc-viz.html#updating-labelstitle",
    "title": "Week 03: Describe & Vizualize",
    "section": "Updating Labels/Title",
    "text": "Updating Labels/Title\nIt will default to including the variable names as the x and y labels, but that isn‚Äôt something that makes sense. Also would be good to have a title!\nWe add on another layer called labs() for our labels (link)\n\ntipi %&gt;% \n  ggplot(aes(x = emo, \n             y = extra, \n             color = sex)) + \n  geom_point(aes(color=sex)) + \n  geom_smooth(method = 'lm') + \n  labs(\n    title = \"TIPI Data\",\n    subtitle = \"Extraversion by Emotional Stability\", \n    x = \"motional Stability\", \n    y = \"Extraversion\", \n    color = \"Sex at Birth\"\n  )"
  },
  {
    "objectID": "slides/lec-3_desc-viz.html#other-graphs",
    "href": "slides/lec-3_desc-viz.html#other-graphs",
    "title": "Week 03: Describe & Vizualize",
    "section": "Other Graphs",
    "text": "Other Graphs\nTake another look at the ggplot cheatsheet\nWhat else is a useful chart?"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#naming-conventions",
    "href": "slides/lec-3_wrangle.html#naming-conventions",
    "title": "Week 03: Wrangling",
    "section": "Naming Conventions",
    "text": "Naming Conventions\nRemember in the lab when things were named all funky? We used the rename() function to do that last time. This can be helpful if you want to change it to something specific, but we may just want to make these names a little cleaner.\nIntroducing janitor https://sfirke.github.io/janitor/index.html\n\n#same code as before\ntipi &lt;- import(here(\"files\", \"data\", \"TIPI_Data.csv\")) %&gt;% \n  # from the janitor package\n  janitor::clean_names()\nnames(tipi)\n\n [1] \"id\"                  \"progress\"            \"duration_in_seconds\"\n [4] \"consent\"             \"genderid\"            \"genderid_7_text\"    \n [7] \"sex\"                 \"age\"                 \"year_school\"        \n[10] \"q85\"                 \"q85_6_text\"          \"tipi_1\"             \n[13] \"tipi_2\"              \"tipi_3\"              \"tipi_4\"             \n[16] \"tipi_5\"              \"tipi_6\"              \"tipi_7\"             \n[19] \"tipi_8\"              \"tipi_9\"              \"tipi_10\"            \n[22] \"sleep_quality\"       \"hours_of_sleep\""
  },
  {
    "objectID": "slides/lec-3_wrangle.html#using-select",
    "href": "slides/lec-3_wrangle.html#using-select",
    "title": "Week 03: Wrangling",
    "section": "Using select()",
    "text": "Using select()\nYou used this in lab, so you are all experts. Let‚Äôs review by looking at the cheatsheet for dplyr.\nThe dplyr package makes data wrangling and transformation much easier. select() allows you to‚Ä¶well‚Ä¶select the columns that you want to keep.\n\nCreate a dataset that only includes: id, progress, duration, TIPI items"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#using-select-1",
    "href": "slides/lec-3_wrangle.html#using-select-1",
    "title": "Week 03: Wrangling",
    "section": "Using select()",
    "text": "Using select()\n\ntipi &lt;- tipi %&gt;% \n  select(c(id, progress, duration_in_seconds, tipi_1, \n           tipi_2, tipi_3, tipi_4, tipi_5, tipi_6, tipi_7, \n           tipi_8, tipi_9, tipi_10))\n\ntipi &lt;- tipi %&gt;% \n  select(c(id:duration_in_seconds, contains(\"tipi_\")))\n\n## OR\n\ntipi &lt;- tipi %&gt;% \n  select(-c(consent:q85_6_text, sleep_quality, hours_of_sleep))"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#extract-rows",
    "href": "slides/lec-3_wrangle.html#extract-rows",
    "title": "Week 03: Wrangling",
    "section": "Extract Rows",
    "text": "Extract Rows\nThe ‚Äòfilter()‚Äô function is used to subset observations based on their values.\nThe result of filtering is a data frame with the same number of columns as before but fewer rows.\nThe first argument is data and subsequent arguments are logical expressions that tell you which observations to retain in the data frame.\nNote: You are stating which types of rows you want to keep. If a variable can answer TRUE to your condition, then it will stay in the data.\n\nfilter(starwars, hair_color == \"none\")\n\n# A tibble: 38 √ó 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Darth V‚Ä¶    202   136 none       white      yellow          41.9 male  mascu‚Ä¶\n 2 IG-88       200   140 none       metal      red             15   none  mascu‚Ä¶\n 3 Bossk       190   113 none       green      red             53   male  mascu‚Ä¶\n 4 Lobot       175    79 none       light      blue            37   male  mascu‚Ä¶\n 5 Ackbar      180    83 none       brown mot‚Ä¶ orange          41   male  mascu‚Ä¶\n 6 Nien Nu‚Ä¶    160    68 none       grey       black           NA   male  mascu‚Ä¶\n 7 Nute Gu‚Ä¶    191    90 none       mottled g‚Ä¶ red             NA   male  mascu‚Ä¶\n 8 Jar Jar‚Ä¶    196    66 none       orange     orange          52   male  mascu‚Ä¶\n 9 Roos Ta‚Ä¶    224    82 none       grey       orange          NA   male  mascu‚Ä¶\n10 Rugor N‚Ä¶    206    NA none       green      orange          NA   male  mascu‚Ä¶\n# ‚Ñπ 28 more rows\n# ‚Ñπ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#filter-observations",
    "href": "slides/lec-3_wrangle.html#filter-observations",
    "title": "Week 03: Wrangling",
    "section": "Filter Observations",
    "text": "Filter Observations\nWe can now generate a subset of observations based on a particular value\nThere may be some data checks that you perform when wrangling data. One that I would suggest is to look at the overall completion percentages and the amount of time that it took for participants to complete the questionnaire.\nThis is exactly what filter() is set to do.\n\n# Assigning it to a new variable\nclean_tipi_data &lt;- tipi %&gt;% \n  filter(progress == 100 & \n         duration_in_seconds &gt; 600)"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#compute-new-variable",
    "href": "slides/lec-3_wrangle.html#compute-new-variable",
    "title": "Week 03: Wrangling",
    "section": "Compute new variable",
    "text": "Compute new variable\nWe often need to make a sum/mean score for a variable of interest, or transform it in some way.\nThe mutate() function is most commonly used to add new columns to your data frame that are functions of existing columns.\nmutate() requires data as its first argument, followed by a set of expressions defining new columns.\n\nNote: New variables are automatically added at the end of the data frame (scroll to the right to see them)\n\nFor example, in the lab, we had the Ten Item Personality Inventory\nTake a look at the scoring of the TIPI and compute the necessary variables for all subscales"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#sum-scores",
    "href": "slides/lec-3_wrangle.html#sum-scores",
    "title": "Week 03: Wrangling",
    "section": "Sum Scores",
    "text": "Sum Scores\nAnd finally, we can use mutate() to create total scores (or really any type of computation)\nFor the TIPI data, we need to compute each of the 5 pieces of the Big Five (Extraversion, Agreeableness, Conscientiousness, Emotional Stability and Openness to Experience)\n\nfinal_tipi &lt;- wizard_tipi_data %&gt;% \n  mutate(\n    extra = (tipi_1 + tipi_6r)/2,\n    agree = (tipi_2r + tipi_7)/2,\n    consc = (tipi_3 + tipi_8r)/2,\n    emo = (tipi_4r + tipi_9)/2,\n    open = (tipi_5 + tipi_10r)/2\n  )"
  },
  {
    "objectID": "slides/lec-3_wrangle.html#export",
    "href": "slides/lec-3_wrangle.html#export",
    "title": "Week 03: Wrangling",
    "section": "export()",
    "text": "export()\nNow that we have a scored dataset, we will want to save that.\nYou can do this by re-running all of your steps above, or by exporting your dataset.\nexport(final_tipi, here(\"files\", \"data\", \"final_tipi.csv\"))\n\n\n\n\n\n\nNote\n\n\nBe careful when exporting and knitting docs. Each time you knit, it will run the export code. After I export, I usually will comment out that line of code."
  },
  {
    "objectID": "slides/lec-7_regression.html#today",
    "href": "slides/lec-7_regression.html#today",
    "title": "Week 07: Simple Regression",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nRegression\n\nWhy use regression?\nOne equation to rule them all"
  },
  {
    "objectID": "slides/lec-7_regression.html#overview-of-regression",
    "href": "slides/lec-7_regression.html#overview-of-regression",
    "title": "Week 07: Simple Regression",
    "section": "Overview of Regression",
    "text": "Overview of Regression\nRegression is a general data analytic system\n\nLots of things fall under the umbrella of regression\nThis system can handle a variety of forms of relations and types of variables\n\nThe output of regression includes both effect sizes and statistical significance\nWe can also incorporate multiple influences (IVs) and account for their intercorrelations"
  },
  {
    "objectID": "slides/lec-7_regression.html#study-design-collection",
    "href": "slides/lec-7_regression.html#study-design-collection",
    "title": "Week 07: Simple Regression",
    "section": "Study Design & Collection",
    "text": "Study Design & Collection\n\n\nDesign - When data are collected\n\nRetrospective/Prospective\nLongitudinal\nCross-Sectional\n\n\nCollection - How data are collected\n\nExperimental\nField\nObservational\nMeta-analysis\nNeuroimaging/Psychophysiology\nSurvey\nQuasi-Experimental"
  },
  {
    "objectID": "slides/lec-7_regression.html#ols",
    "href": "slides/lec-7_regression.html#ols",
    "title": "Week 07: Simple Regression",
    "section": "OLS",
    "text": "OLS\n\nHow do we find the regression estimates?\nOrdinary Least Squares (OLS) estimation\nMinimizes deviations\n\n\\[ min\\sum(Y_{i} - \\hat{Y} ) ^{2} \\]\n\nOther estimation procedures possible (and necessary in some cases)"
  },
  {
    "objectID": "slides/lec-7_regression.html#compare-to-bad-fit",
    "href": "slides/lec-7_regression.html#compare-to-bad-fit",
    "title": "Week 07: Simple Regression",
    "section": "compare to bad fit",
    "text": "compare to bad fit"
  },
  {
    "objectID": "slides/lec-7_regression.html#ols-1",
    "href": "slides/lec-7_regression.html#ols-1",
    "title": "Week 07: Simple Regression",
    "section": "OLS",
    "text": "OLS\nThe line that yields the smallest sum of squared deviations\n\\[\\Sigma(Y_i - \\hat{Y_i})^2\\] \\[= \\Sigma(Y_i - (b_0+b_{1}X_i))^2\\] \\[= \\Sigma(e_i)^2\\]\n\nIn order to find the OLS solution, you could try many different coefficients \\((b_0 \\text{ and } b_{1})\\) until you find the one with the smallest sum squared deviation. Luckily, there are simple calculations that will yield the OLS solution every time."
  },
  {
    "objectID": "slides/lec-7_regression.html#regression-coefficient-b_1",
    "href": "slides/lec-7_regression.html#regression-coefficient-b_1",
    "title": "Week 07: Simple Regression",
    "section": "Regression coefficient, \\(b_{1}\\)",
    "text": "Regression coefficient, \\(b_{1}\\)\n\\[b_{1} = \\frac{cov_{XY}}{s_{x}^{2}} = r_{xy} \\frac{s_{y}}{s_{x}}\\]\nWhat units is the regression coefficient in?\n\nThe regression coefficient (slope) equals the estimated change in Y for a 1-unit change in X"
  },
  {
    "objectID": "slides/lec-7_regression.html#standardized-regression-equation",
    "href": "slides/lec-7_regression.html#standardized-regression-equation",
    "title": "Week 07: Simple Regression",
    "section": "Standardized regression equation",
    "text": "Standardized regression equation\n\\[\\Large Z_{y_i} = b_{yx}^*Z_{x_i}+e_i\\]\n\\[\\Large b_{yx}^* = b_{yx}\\frac{s_x}{s_y} = r_{xy}\\]\n\nAccording to this regression equation, when \\(X = 0, Y = 0\\). Our interpretation of the coefficient is that a one-standard deviation increase in X is associated with a \\(b_{yx}^*\\) standard deviation increase in Y. Our regression coefficient is equivalent to the correlation coefficient when we have only one predictor in our model."
  },
  {
    "objectID": "slides/lec-7_regression.html#estimating-the-intercept-b_0",
    "href": "slides/lec-7_regression.html#estimating-the-intercept-b_0",
    "title": "Week 07: Simple Regression",
    "section": "Estimating the intercept, \\(b_0\\)",
    "text": "Estimating the intercept, \\(b_0\\)\n\nintercept serves to adjust for differences in means between X and Y\n\n\\[\\hat{Y_i} = \\bar{Y} + r_{xy} \\frac{s_{y}}{s_{x}}(X_i-\\bar{X})\\]\n\nif standardized, intercept drops out\notherwise, intercept is where regression line crosses the y-axis at X = 0\n\n\n\nAlso, notice that when \\(X = \\bar{X}\\) the regression line goes through \\(\\bar{Y}\\)\n\n\\[b_0 = \\bar{Y} - b_1\\bar{X}\\]"
  },
  {
    "objectID": "slides/lec-7_regression.html#example-by-hand",
    "href": "slides/lec-7_regression.html#example-by-hand",
    "title": "Week 07: Simple Regression",
    "section": "Example (by hand)",
    "text": "Example (by hand)\n\nlibrary(gapminder)\ngapminder %&lt;&gt;% filter(year == 2007 & continent == \"Asia\") %&gt;% \n  mutate(log_gdp = log(gdpPercap))\n\ngapminder %&gt;% \n  select(log_gdp, lifeExp) %&gt;% \n  describe()\n\n        vars  n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nlog_gdp    1 33  8.74 1.24   8.41    8.73 1.42  6.85 10.76  3.91  0.21    -1.37\nlifeExp    2 33 70.73 7.96  72.40   71.31 7.70 43.83 82.60 38.77 -1.07     1.79\n          se\nlog_gdp 0.22\nlifeExp 1.39\n\ncor(gapminder$log_gdp, gapminder$lifeExp)\n\n[1] 0.8003474"
  },
  {
    "objectID": "slides/lec-7_regression.html#in-r",
    "href": "slides/lec-7_regression.html#in-r",
    "title": "Week 07: Simple Regression",
    "section": "In R",
    "text": "In R\n\nfit.1 &lt;- lm(lifeExp ~ log_gdp, data = gapminder)\nsummary(fit.1)\n\n\nCall:\nlm(formula = lifeExp ~ log_gdp, data = gapminder)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.314  -1.650  -0.040   3.428   8.370 \n\nCoefficients:\n            Estimate Std. Error t value     Pr(&gt;|t|)    \n(Intercept)  25.6501     6.1234   4.189     0.000216 ***\nlog_gdp       5.1573     0.6939   7.433 0.0000000226 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.851 on 31 degrees of freedom\nMultiple R-squared:  0.6406,    Adjusted R-squared:  0.629 \nF-statistic: 55.24 on 1 and 31 DF,  p-value: 0.00000002263\n\n\n\nThings to discuss\n\nCoefficient estimates\nStatistical tests (covered in more detail soon)"
  },
  {
    "objectID": "slides/lec-7_regression.html#using-easystats",
    "href": "slides/lec-7_regression.html#using-easystats",
    "title": "Week 07: Simple Regression",
    "section": "Using easystats",
    "text": "Using easystats\n\nperformance::check_model(fit.1)"
  },
  {
    "objectID": "slides/lec-7_regression.html#using-sjplot",
    "href": "slides/lec-7_regression.html#using-sjplot",
    "title": "Week 07: Simple Regression",
    "section": "Using sjPlot",
    "text": "Using sjPlot\n\nsjPlot::tab_model(fit.1)\n\n\n\n\n¬†\nlife Exp\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n25.65\n13.16¬†‚Äì¬†38.14\n&lt;0.001\n\n\nlog gdp\n5.16\n3.74¬†‚Äì¬†6.57\n&lt;0.001\n\n\nObservations\n33\n\n\nR2 / R2 adjusted\n0.641 / 0.629"
  },
  {
    "objectID": "slides/lec-7_regression.html#regression-to-the-mean",
    "href": "slides/lec-7_regression.html#regression-to-the-mean",
    "title": "Week 07: Simple Regression",
    "section": "Regression to the mean",
    "text": "Regression to the mean\nAn observation about heights was part of the motivation to develop the regression equation: If you selected a parent who was exceptionally tall (or short), their child was almost always not as tall (or as short).\n\n\nCode\nlibrary(psychTools)\nlibrary(tidyverse)\nheights = psychTools::galton\nmod = lm(child~parent, data = heights)\npoint = 902\nheights = broom::augment(mod)\n\n\nheights %&gt;%\n  ggplot(aes(x = parent, y = child)) +\n  geom_jitter(alpha = .3) +\n  geom_hline(aes(yintercept = 72), color = \"red\") +\n  geom_vline(aes(xintercept = 72), color = \"red\") +\n  theme_bw(base_size = 20)"
  },
  {
    "objectID": "slides/lec-7_regression.html#regression-to-the-mean-1",
    "href": "slides/lec-7_regression.html#regression-to-the-mean-1",
    "title": "Week 07: Simple Regression",
    "section": "Regression to the mean",
    "text": "Regression to the mean\nThis phenomenon is known as regression to the mean. This describes the phenomenon in which an random variable produces an extreme score on a first measurement, but a lower score on a second measurement."
  },
  {
    "objectID": "slides/lec-7_regression.html#regression-to-the-mean-2",
    "href": "slides/lec-7_regression.html#regression-to-the-mean-2",
    "title": "Week 07: Simple Regression",
    "section": "Regression to the mean",
    "text": "Regression to the mean\nThis can be a threat to internal validity if interventions are applied based on first measurement scores."
  },
  {
    "objectID": "slides/lec-7_regression.html#another-dataset",
    "href": "slides/lec-7_regression.html#another-dataset",
    "title": "Week 07: Simple Regression",
    "section": "Another Dataset",
    "text": "Another Dataset\n\nschool &lt;- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/data/example2-chisq.csv\") %&gt;% \n  mutate(Sleep_Hours_Non_Schoolnight = as.numeric(Sleep_Hours_Non_Schoolnight)) %&gt;% \n  filter(Sleep_Hours_Non_Schoolnight &lt; 24) #removing impossible values"
  },
  {
    "objectID": "slides/lec-7_regression.html#statistical-inference",
    "href": "slides/lec-7_regression.html#statistical-inference",
    "title": "Week 07: Simple Regression",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\nThe way the world is = our model + error\nHow good is our model? Does it ‚Äúfit‚Äù the data well?\n\n\nTo assess how well our model fits the data, we will examine the proportion of variance in our outcome variable that can be ‚Äúexplained‚Äù by our model.\nTo do so, we need to partition the variance into different categories. For now, we will partition it into two categories: the variability that is captured by (explained by) our model, and variability that is not."
  },
  {
    "objectID": "slides/lec-7_regression.html#partitioning-variation",
    "href": "slides/lec-7_regression.html#partitioning-variation",
    "title": "Week 07: Simple Regression",
    "section": "Partitioning variation",
    "text": "Partitioning variation\nLet‚Äôs start with the formula defining the relationship between observed \\(Y\\) and fitted \\(\\hat{Y}\\):\n\\[Y_i = \\hat{Y}_i + e_i\\]\n\nOne of the properties that we love about variance is that variances are additive when two variables are independent. In other words, if we create some variable, C, by adding together two other variables, A and B, then the variance of C is equal to the sum of the variances of A and B.\n\n\nWhy can we use that rule in this case?\n\nStudents must recognize that Y-hat and e are uncorrelated, they must be the way that we‚Äôve built the OLS function."
  },
  {
    "objectID": "slides/lec-7_regression.html#partitioning-variation-1",
    "href": "slides/lec-7_regression.html#partitioning-variation-1",
    "title": "Week 07: Simple Regression",
    "section": "Partitioning variation",
    "text": "Partitioning variation\n\n\n\\(\\hat{Y}_i\\) and \\(e_i\\) must be independent from each other. Thus, the variance of \\(Y\\) is equal to the sum of the variance of \\(\\hat{Y}\\) and \\(e\\).\n\\[\\large s^2_Y = s^2_{\\hat{Y}} + s^2_{e}\\]\n\nRecall that variances are sums of squares divided by N-1. Thus, all variances have the same sample size, so we can also note the following:\n\\[\\large SS_Y = SS_{\\hat{Y}} + SS_{\\text{e}}\\]"
  },
  {
    "objectID": "slides/lec-7_regression.html#coefficient-of-determination",
    "href": "slides/lec-7_regression.html#coefficient-of-determination",
    "title": "Week 07: Simple Regression",
    "section": "Coefficient of Determination",
    "text": "Coefficient of Determination\n\\[\\Large \\frac{SS_{Model}}{SS_{Y}} = \\frac{s_{Model}^2}{s_{y}^2} = R^2\\]\n\\(R^2\\) represents the proportion of variance in Y that is explained by the model.\n\n\\(\\sqrt{R^2} = R\\) is the correlation between the predicted values of Y from the model and the actual values of Y\n\\[\\large \\sqrt{R^2} = r_{Y\\hat{Y}}\\]"
  },
  {
    "objectID": "resources/introwrangling.html",
    "href": "resources/introwrangling.html",
    "title": "Intro to Data Wrangling",
    "section": "",
    "text": "Special thanks to Sara J. Weston and the work done with their class at Oregon."
  },
  {
    "objectID": "resources/introwrangling.html#create-a-reproducible-lab-report",
    "href": "resources/introwrangling.html#create-a-reproducible-lab-report",
    "title": "Intro to Data Wrangling",
    "section": "Create a reproducible lab report",
    "text": "Create a reproducible lab report\nTo create your new lab report, in RStudio, go to New File -&gt; R Markdown. Then delete everything after Line 5 and save it in the folder you will be using for the current lab. Remember, make a single folder on your computer that holds everything necessary for the project you are working on."
  },
  {
    "objectID": "resources/introwrangling.html#put-the-data-where-it-needs-to-be",
    "href": "resources/introwrangling.html#put-the-data-where-it-needs-to-be",
    "title": "Intro to Data Wrangling",
    "section": "Put the Data where it needs to be",
    "text": "Put the Data where it needs to be\nDownload your data that you will be using and place this data file in the folder you are using.¬†I always encourage a ‚ÄúData‚Äù Folder that holds all raw data."
  },
  {
    "objectID": "resources/introwrangling.html#load-the-libraries",
    "href": "resources/introwrangling.html#load-the-libraries",
    "title": "Intro to Data Wrangling",
    "section": "Load the Libraries",
    "text": "Load the Libraries\nGet the libraries loaded in their own code chunk. We will be using here, psych and rio. Remember that if you haven‚Äôt already installed these libraries (i.e., bought the book from the book store for your own personal library), you will need to run the command install.packages() in the console with the appropriate packages name in the parentheses surrounded by quotation marks.\nIn the console:\ninstall.packages(\"here\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"rio\")\nIn the first code chunk of your Rmd file\nlibrary(here)\nlibrary(tidyverse)\nlibrary(rio)"
  },
  {
    "objectID": "resources/introwrangling.html#import-the-data",
    "href": "resources/introwrangling.html#import-the-data",
    "title": "Intro to Data Wrangling",
    "section": "Import the data",
    "text": "Import the data\nImport the data using the rio package and save it to an object called sleep_data. You will be able to use the import() function as well as the here() function.\n\n\n\n\n\n\nsleep_data &lt;- import(here(‚ÄúLabs‚Äù, ‚ÄúData‚Äù, ‚ÄúSleepFile‚Äù, ‚ÄúSleepData.sav‚Äù))"
  },
  {
    "objectID": "resources/introwrangling.html#histogram",
    "href": "resources/introwrangling.html#histogram",
    "title": "Intro to Data Wrangling",
    "section": "Histogram",
    "text": "Histogram\nOne common way of visualizing distributions is using a histogram, which plots the frequencies of different values for a given variable.\nFor example, let‚Äôs take a look at a distribution of the age variable. We do this using the hist() function. (Remember, you can check out the help documentation using ?hist).\nCreate a histogram using the age variable with the title ‚ÄúHistogram of Age‚Äù and the x-axis labeled as ‚ÄúAge‚Äù.\nYou can also change the number of bins (i.e.¬†bars) in your histogram using the breaks argument. Try 5, 10, and 20 breaks. What do you notice as the number of breaks increases?"
  },
  {
    "objectID": "resources/introwrangling.html#boxplot",
    "href": "resources/introwrangling.html#boxplot",
    "title": "Intro to Data Wrangling",
    "section": "Boxplot",
    "text": "Boxplot\nAnother way to visualize distribution and to better examine the outliers is to use a boxplot. For a short guide on how to read boxplots, seehere or refer tothis section of the textbook.\nCreate a boxplot using the age variable with the title ‚ÄúBoxplot of Age‚Äù and the x-axis labeled as ‚ÄúAge‚Äù. What do you notice??\nInvestigate the distribution more with boxplot.stats(x = sleep_data$age)$out"
  },
  {
    "objectID": "resources/introwrangling.html#looking-into-the-future",
    "href": "resources/introwrangling.html#looking-into-the-future",
    "title": "Intro to Data Wrangling",
    "section": "Looking into the future‚Ä¶",
    "text": "Looking into the future‚Ä¶\nSo far we have been plotting in base R. However, theggplot2 package is generally a much better tool for plotting. For now we‚Äôll stick with base plotting to keep things simple, but in a future class you will learn how to use ggplot to make better-looking plots, such as this:\nOk, so now that we know how to visualize a basic distribution, let‚Äôs think about how we commonly characterize distributions with descriptive statistics‚Ä¶"
  },
  {
    "objectID": "resources/introwrangling.html#measures-of-central-tendency",
    "href": "resources/introwrangling.html#measures-of-central-tendency",
    "title": "Intro to Data Wrangling",
    "section": "Measures of Central Tendency",
    "text": "Measures of Central Tendency\nFor a given set of observations, measures of central tendency allow us to get the ‚Äúgist‚Äù of the data. They tell us about where the ‚Äúaverage‚Äù or the ‚Äúmid-point‚Äù of the data lies. Let‚Äôs take a look at the data that we have already loaded in, and complete some of these tasks (which we may already have done in previous classes).¬†\n\nMean\nA quick way to find the mean is to use the aptly named mean() function from base R. Use this function on the age variable in the sleep_data dataset.\n\n\n\nmean(sleep_data$age)\n\n\n\nOh no! We forgot to account for the missing variables in our variable! We got NA! The reason for this is that the mean is calculated by using every value for a given variable, so if you don‚Äôt remove (or impute) the missing values before getting the mean, it won‚Äôt work.\nLet‚Äôs try that again, but using the additional argument to eliminate (or remove) the NA‚Äôs from the variable prior to computing the mean.¬†\n\n\n\nmean(sleep_data$age, na.rm = TRUE)\n\n\n\n\n\nMedian\nThe median is the middle value of a set of observations: 50% of the data points fall below the median, and 50% fall above.\nTo find the median, we can use the median() function. Use it on the age variable."
  },
  {
    "objectID": "resources/introwrangling.html#measures-of-variability",
    "href": "resources/introwrangling.html#measures-of-variability",
    "title": "Intro to Data Wrangling",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nRange\nThe range gives us the distance between the smallest and largest value in a dataset. You can find the range using the range() function, which will output the minimum and maximum values. Find the range of the age variable.\n\n\nVariance and Standard Deviation\nTo find the variance and standard deviation, we use var() and sd(), respectively. Find the variance and standard deviation of the age variable."
  },
  {
    "objectID": "resources/introwrangling.html#describe",
    "href": "resources/introwrangling.html#describe",
    "title": "Intro to Data Wrangling",
    "section": "describe()",
    "text": "describe()\nThis function automatically calculates all of the descriptives we reviewed above (and more!). Use the describe() function from the psych package on the entire sleep_data dataset.\nNotes: If you load a library at the beginning, you can directly call any function from it. Instead, you can call a function by library_name::function_name without loading the entire library.\n\n\n\n\n\n\npsych::describe(sleep_data)\n# or if you have already loaded the library\ndescribe(sleep_data)\n\n\n\nNOTE: Some variables are not numeric and are categorical variables of type character. By default, the describe() function forces non-numeric variables to be numeric and attempts to calculate descriptives for them. These variables are marked with an asterisk (*). In this case, it doesn‚Äôt make sense to calculate descriptive statistics for these variables, so we get a warning message and a bunch of NaN‚Äôs and NA‚Äôs for these variables.\nA better approach would be to remove non-numeric variables before you attempt to run numerical calculations on your dataset.\nNow let‚Äôs take a closer look at trying to update the age variable in this dataset."
  },
  {
    "objectID": "resources/introwrangling.html#what-is-data-wrangling",
    "href": "resources/introwrangling.html#what-is-data-wrangling",
    "title": "Intro to Data Wrangling",
    "section": "What is data wrangling?",
    "text": "What is data wrangling?\nData wrangling, broadly speaking, means getting your data into a useful form for visualizing and modeling it. Hadley Wickham, who has developed a lot of the tidyverse, conceptualizes the main steps involved in data wrangling as follows:\n\nImporting your data¬†\nTidying your data (see brief overview below)\nTransforming your data (what we‚Äôll cover today)\n\nThe figure below highlights the steps in data wrangling in relation to the broader scope of a typical data science workflow:"
  },
  {
    "objectID": "resources/introwrangling.html#what-is-tidy-data",
    "href": "resources/introwrangling.html#what-is-tidy-data",
    "title": "Intro to Data Wrangling",
    "section": "What is ‚Äútidy data‚Äù?",
    "text": "What is ‚Äútidy data‚Äù?\nData is considered ‚Äútidy‚Äù when:¬†\n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell\n\nThe following figure is from R for Data Science and visualizes tidy data.¬†\nIf your data is not already in tidy format when you import it, you can use functions from the {tidyR} package, e.g.¬†pivot_longer() and pivot_wider(), that allow you to ‚Äúreshape‚Äù your data to get it into tidy format.\nHowever, this term we are mostly going to work with simpler datasets that are already tidy, so we are not going to focus on these functions today. These functions will become especially useful in the future when we work with repeated measures data that has multiple observations for each subject. If you are interested in learning more about reshaping your data with {tidyR}, check outthis chapter from R for Data Science."
  },
  {
    "objectID": "resources/introwrangling.html#pipes",
    "href": "resources/introwrangling.html#pipes",
    "title": "Intro to Data Wrangling",
    "section": "Pipes",
    "text": "Pipes\nPipes come from the {magrittr} package are available when you load the tidyverse. (Technically, the pipe is imported with {dplyr}.) Pipes are a way to write strings of functions more easily, creating pipelines. They are extremely powerful and useful. A pipe looks like this:\nYou can enter a pipe with the shortcut CTRL+Shift+M for PC or CMD+Shift+M for Mac.\nA pipe passes an object on the left-hand side as the first argument (or . argument) of whatever function is on the right-hand side.\n\nx %&gt;% f(y) is the same as f(x, y)\ny %&gt;% f(x, ., z) is the same as f(x, y, z )\n\nExample: I want to calculate the mean of the mpg variable from the mtcars data set and round our answer to 2 decimal places. I can accomplish this by nesting:\n\n\n\nround(mean(mtcars$mpg, na.rm = TRUE), 2)\n\n\n\nOr, we could use pipes. Grammatically, you can think of a pipe as ‚Äúthen.‚Äù I have a variable, the mile per gallon of cars, THEN I want to take the mean of that variable, and THEN I want to round that answer to two decimal places.\n\n\n\n\n\n\nmtcars$mpg %&gt;% # select the `mpg` variable from the `mtcars` dataset\nmean(na.rm = TRUE) %&gt;% # calculate the mean\nround(2) # round to 2 decimal places\n\n\n\nNow try rewriting the following code using pipes:\n\n\n\nround(sqrt(sum(mtcars$cyl)), 1)\n\n\n\n\nWhy use pipes?\n\nCleaner code\n\nThis is nice, because it helps make your code more readable by other humans (including your future self).\n\n\n\n\nCleaner environment\n\nWhen you use pipes, you have basically no reason to save objects from intermediary steps in your data wrangling / analysis workflow, because you can just pass output from function to function without saving it.\nFinding objects you‚Äôre looking for is easier.\n\n\n\n\nEfficiency in writing code\n\nNaming objects is hard; piping means coming up with fewer names.\n\n\n\n\nMore error-proof\n\nBecause naming is hard, you might accidentally re-use a name and make an error."
  },
  {
    "objectID": "resources/introwrangling.html#manipulating-observations",
    "href": "resources/introwrangling.html#manipulating-observations",
    "title": "Intro to Data Wrangling",
    "section": "Manipulating Observations",
    "text": "Manipulating Observations\n\nExtract rows with filter()\nThe filter() function is used to subset observations based on their values. The result of filtering is a data frame with the same number of columns as before but fewer rows, as illustrated below‚Ä¶\nThe first argument is data and subsequent arguments are logical expressions that tell you which observations to retain in the data frame.\nFor example, we can filter rows to retain data only for the students who do not have a roommate.\n\n\n\n\n\n\nsleep_data %&gt;%\nfilter(roommate == 2)\n\n\n\nBut we may want to save this as a new datafile. Can assign this to a new object.\n\n\nLogical Operators\nThe == we just used is an example of a comparison operator that tests for equality. The other comparison operators available are :\n\n&gt; (greater than)\n&gt;= (greater than or equal to)\n&lt; (less than)\n&lt;= (less than or equal to)\n!= (not equal to)\n\nYou can combine multiple arguments to filter() with Boolean operators. The figure below fromR for Data Science shows the complete set of Boolean operators.\n\n\nTry it out yourself:¬†\nFirst, let‚Äôs filter for observations that are greater than the mean of age\n\n\n\n\n\n\nsleep_data %&gt;%\nfilter(age &gt; mean(age, na.rm = TRUE)\n\n\n\nNow, you try filtering observations that are greater than the mean of happiness, but the participant does have a roommate:¬†\n\n\n\n# Put your code here\n\n\n\nFilter out the age variable that are out of bounds"
  },
  {
    "objectID": "resources/introwrangling.html#manipulating-variables",
    "href": "resources/introwrangling.html#manipulating-variables",
    "title": "Intro to Data Wrangling",
    "section": "Manipulating Variables",
    "text": "Manipulating Variables\n\nExtract columns with select()\nThe select() function subsets columns in your data frame. This is particularly useful when you have a data set with a huge number of variables and you want to narrow down to the variables that are relevant for your analysis.\nThe first argument is data, followed by the name(s) of the column(s) you want to subset. Note that you can use variable positions rather than their names, but this is usually not as useful. Let‚Äôs go through some simple examples of common uses of select().\nSelect one variable\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study)\n\n\n\nSelect multiple variables\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study, bed_read, bed_friends)\n\n\n\nSelect a range of variables\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(bed_study:bed_videogames) %&gt;%\nnames()\n\n\n\nDe-select variables with a minus sign (-)\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(-age)\n\n\n\nDe-select range of variables\nNote: everything() is a helper function that gives us all the remaining variables in the data frame (see more onhelper functions below)\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(-(ESS1:everything())\n\n\n\n\n\nHelper functions for select()\nThere are some ‚Äúhelper‚Äù functions that you can use along with select() that can sometimes be more efficient than selecting your variables explicitly by name.\n\n\n\n\n\n\n\nfunction\nwhat it does\n\n\nstarts_with()\nselects columns starting with a string\n\n\nends_with()\nselects columns that end with a string\n\n\ncontains()\nselects columns that contain a string\n\n\nmatches()\nselects columns that match a regular expression\n\n\nnum_ranges()\nselects columns that match a numerical range\n\n\none_of()\nselects columns whose names match entries in a character vector\n\n\neverything()\nselects all columns\n\n\nlast_col()\nselects last column; can include an offset.\n\n\n\nQuick example:\n\n\n\n\n\n\nsleep_data %&gt;%\nselect(starts_with(‚Äúa‚Äù)\n\n\n\n\n\nMake new variables with mutate()\nThe mutate() function is most commonly used to add new columns to your data frame that are functions of existing columns.\nmutate() requires data as its first argument, followed by a set of expressions defining new columns. Let‚Äôs take a couple examples‚Ä¶\nCreate new variables\n\nNote: New variables are automatically added at the end of the data frame (scroll to the right to see them)\n\n\n\n\n\n\n\nsleep_data &lt;- sleep_data %&gt;%\nmutate(ess_sum = ESS1 + ESS2 + ESS3 + ESS4 +\nESS5 + ESS6 + ESS7 + ESS8)\n\n\n\nLab Q‚Äôs (60 Points)\nNOTE: Use the dataset that you prepared above (put this all in the same R-Notebook)."
  },
  {
    "objectID": "resources/introwrangling.html#epworth-sleepiness-scale-30-points",
    "href": "resources/introwrangling.html#epworth-sleepiness-scale-30-points",
    "title": "Intro to Data Wrangling",
    "section": "Epworth Sleepiness Scale (30 points)",
    "text": "Epworth Sleepiness Scale (30 points)\n\nCalculate the mean, median and standard deviation of the ESS Total score. (6 points)\nCreate a histogram of the total scores. (3 points)\nCreate a boxplot of the total scores. Are there any outliers? (5 points)\nUsing the scale cutoff points below, how many individuals would be categorized as: (16 points)\n\nLower Normal Daytime Sleepiness\nModerate or above for Daytime Sleepiness (Moderate and Severe)\n\n\n\n\nHow did you identify the groups above?"
  },
  {
    "objectID": "resources/introwrangling.html#are-folks-paying-attention-30-points",
    "href": "resources/introwrangling.html#are-folks-paying-attention-30-points",
    "title": "Intro to Data Wrangling",
    "section": "Are folks paying attention? (30 points)",
    "text": "Are folks paying attention? (30 points)\n\nAggregate the ‚Äúattention‚Äù variables (attention 1 to attention5) in a sum score. (3 points)\nWhat is the distribution (hint hint do a histogram) of the scores? (3 points)\nWhat is the mean, median, minimum & maximum of the aggregate ‚Äúattention‚Äù variable? (6 points)\nCreate two new datasets labeled (1) ‚Äúdata_attend‚Äù and (2) ‚Äúdata_distract‚Äù. In each dataset have those who were paying attention in the ‚Äúdata_attend‚Äù and those who were not in the ‚Äúdata_distract‚Äù. Paying attention is operationalized as having a score of less than 4 on the aggregated variable. (18 points)\n\nWhat are the sample sizes of each of the datasets?\nWhat is the mean age and gender breakdown of each of the datasets?\nFrom the two that you just created, which dataset do you think we should use?"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 05",
    "section": "",
    "text": "Chapter 5.1 & 13 - ST\nChapter 11 - LSR\n\n\n\n\nüíª Correlation & ES\n\n\n\nCorrelations\n\n\n\nüìãLab 5 - More Correlations\nüìãReverse Results\nüìñChapter 9 & 10 - ST\nüìñChapter 13 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#prepare",
    "href": "weeks/week-5.html#prepare",
    "title": "Week 05",
    "section": "",
    "text": "Chapter 5.1 & 13 - ST\nChapter 11 - LSR",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#slides",
    "href": "weeks/week-5.html#slides",
    "title": "Week 05",
    "section": "",
    "text": "üíª Correlation & ES",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#in-class-activity",
    "href": "weeks/week-5.html#in-class-activity",
    "title": "Week 05",
    "section": "",
    "text": "Correlations",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-5.html#for-next-time",
    "href": "weeks/week-5.html#for-next-time",
    "title": "Week 05",
    "section": "",
    "text": "üìãLab 5 - More Correlations\nüìãReverse Results\nüìñChapter 9 & 10 - ST\nüìñChapter 13 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "You survived the first week! I hope your classes are off to a good start. Although we don‚Äôt have class this week (Labor Day), we will still have readings and an assignment. Please view this page to make sure you have all the information you need to get going.\nWe are going to work on expanding our comfort with the syntax in R and using the tidyverse for some more data wrangling. We will import some new data, and compute some new values. This will be a skill that will be useful no matter what data you are working with. There will be plenty of practice with this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄúIllustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst‚Äù\n\n\n\nBe sure to have read the chapters!\nDownload the data for this week\n\nDownload From Drive (CSV)\n\n\n\nNone (Labor Day)\n\n\n\nNo Class this week (Labor Day)\n\n\n\nüìãLab 2 - Getting Comfy with Data Wrangling\nüìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#prepare",
    "href": "weeks/week-2.html#prepare",
    "title": "Week 2",
    "section": "",
    "text": "Be sure to have read the chapters!\nDownload the data for this week\n\nDownload From Drive (CSV)",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#slides",
    "href": "weeks/week-2.html#slides",
    "title": "Week 2",
    "section": "",
    "text": "None (Labor Day)",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#in-class-activity",
    "href": "weeks/week-2.html#in-class-activity",
    "title": "Week 2",
    "section": "",
    "text": "No Class this week (Labor Day)",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#for-next-time",
    "href": "weeks/week-2.html#for-next-time",
    "title": "Week 2",
    "section": "",
    "text": "üìãLab 2 - Getting Comfy with Data Wrangling\nüìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11 - Regression with Categories",
    "section": "",
    "text": "Download Categorical data (.csv)\n\n\n\n\nüíª Categorical Data - Regression\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 11 - Categories & Regression\nüìñChapter 7.3 - IMS\nüìñChapter 14.5 - ST\nüìñChapter 8.1.4 - MSR\nüìñChapter 15.8 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 11 - Categorical Reg."
    ]
  },
  {
    "objectID": "weeks/week-11.html#stuff-for-today",
    "href": "weeks/week-11.html#stuff-for-today",
    "title": "Week 11 - Regression with Categories",
    "section": "",
    "text": "Download Categorical data (.csv)",
    "crumbs": [
      "Weekly Materials",
      "Week 11 - Categorical Reg."
    ]
  },
  {
    "objectID": "weeks/week-11.html#slides",
    "href": "weeks/week-11.html#slides",
    "title": "Week 11 - Regression with Categories",
    "section": "",
    "text": "üíª Categorical Data - Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 11 - Categorical Reg."
    ]
  },
  {
    "objectID": "weeks/week-11.html#in-class-activity",
    "href": "weeks/week-11.html#in-class-activity",
    "title": "Week 11 - Regression with Categories",
    "section": "",
    "text": "Getting Comfy with R",
    "crumbs": [
      "Weekly Materials",
      "Week 11 - Categorical Reg."
    ]
  },
  {
    "objectID": "weeks/week-11.html#for-next-time",
    "href": "weeks/week-11.html#for-next-time",
    "title": "Week 11 - Regression with Categories",
    "section": "",
    "text": "üìãLab 11 - Categories & Regression\nüìñChapter 7.3 - IMS\nüìñChapter 14.5 - ST\nüìñChapter 8.1.4 - MSR\nüìñChapter 15.8 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 11 - Categorical Reg."
    ]
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "üíª Design & Inference\n\n\n\nBeginnings of Inference\n\n\n\nüìãLab 4 - Intro to Inference\nComplete Stats Check (see myCourses)\nüìñChapter 5.1 & 13 - ST\nüìñChapter 11 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-4.html#slides",
    "href": "weeks/week-4.html#slides",
    "title": "Week 4",
    "section": "",
    "text": "üíª Design & Inference",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-4.html#in-class-activity",
    "href": "weeks/week-4.html#in-class-activity",
    "title": "Week 4",
    "section": "",
    "text": "Beginnings of Inference",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-4.html#for-next-time",
    "href": "weeks/week-4.html#for-next-time",
    "title": "Week 4",
    "section": "",
    "text": "üìãLab 4 - Intro to Inference\nComplete Stats Check (see myCourses)\nüìñChapter 5.1 & 13 - ST\nüìñChapter 11 - LSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 4 - Design & Inference"
    ]
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13 - Moderation",
    "section": "",
    "text": "Download Cards Against Humanity Data (.csv)\n\n\n\n\nüíª Intro to Moderation\n\n\n\nüìéOn Paper\n\n\n\nPart 2 of Final Project\nüìñChapter 15.8 - 15.10 - LSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-13.html#data-for-today",
    "href": "weeks/week-13.html#data-for-today",
    "title": "Week 13 - Moderation",
    "section": "",
    "text": "Download Cards Against Humanity Data (.csv)"
  },
  {
    "objectID": "weeks/week-13.html#slides",
    "href": "weeks/week-13.html#slides",
    "title": "Week 13 - Moderation",
    "section": "",
    "text": "üíª Intro to Moderation"
  },
  {
    "objectID": "weeks/week-13.html#in-class-activity",
    "href": "weeks/week-13.html#in-class-activity",
    "title": "Week 13 - Moderation",
    "section": "",
    "text": "üìéOn Paper"
  },
  {
    "objectID": "weeks/week-13.html#for-next-time",
    "href": "weeks/week-13.html#for-next-time",
    "title": "Week 13 - Moderation",
    "section": "",
    "text": "Part 2 of Final Project\nüìñChapter 15.8 - 15.10 - LSR\n\n\nBack to course schedule ‚èé"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "We are now in the third week and you are all probably thinking about how much you dislike R and do not ever want to look at the here() library again. But we are going to have to do just that. Importing and getting started are one of the hardest things to do when first working with R. And then trying to make things reproducible is another thing. We are going to practice this A LOT. Especially right in the beginning.\nThis week we are going to expand on some data wrangling to get more comfortable with dplyr and the larger tidyverse. Here is a good website that can also be helpful. Then we will move into an overview of descriptive statistics and how to get them using R. Finally, we will continue with visualizations using ggplot2. With time, we will start introducing how to talk communicate these types of statistics in a manuscript.\n\n\nüìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS\n\n\n\nüíª Data Wrangling\nüíª Describe & Visualize\n\n\n\nDescribing & Visualizing\n\n\n\nüìãLab 3 - Describe and Visualize\nüìñRead Chapter 2 - IMS\nüìñRead Chapter 3 - MSR\nüìñRead Chapter 7 - ST\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#prepare",
    "href": "weeks/week-3.html#prepare",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "üìñRead Chapter 5 - LSR\nüìñRead Chapter 1 & 3 - R4DS",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#slides",
    "href": "weeks/week-3.html#slides",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "üíª Data Wrangling\nüíª Describe & Visualize",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#in-class-activity",
    "href": "weeks/week-3.html#in-class-activity",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "Describing & Visualizing",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "weeks/week-3.html#for-next-time",
    "href": "weeks/week-3.html#for-next-time",
    "title": "Week 3 - Describe, Visualize, Communicize",
    "section": "",
    "text": "üìãLab 3 - Describe and Visualize\nüìñRead Chapter 2 - IMS\nüìñRead Chapter 3 - MSR\nüìñRead Chapter 7 - ST\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 3 - Describe & Viz"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html",
    "href": "labs/lab-3_describe-viz.html",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "",
    "text": "Can‚Äôt believe we‚Äôre at Lab #3! Keep it going! We are going to continue to practice importing data and making a reproducible workflow. In this lab, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#instructions",
    "href": "labs/lab-3_describe-viz.html#instructions",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "",
    "text": "Can‚Äôt believe we‚Äôre at Lab #3! Keep it going! We are going to continue to practice importing data and making a reproducible workflow. In this lab, you will be expanding the types of plots you are able to use.\nWe will be using data from the Bechdel test, a measure of the representation of women in fiction. You will be asked to do some Exploratory Data Analysis.\nHere are the things that you will need for this lab:\n\nDownload Lab 3 (.Rmd)\nDownload Bechdel Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#scenario-and-goal",
    "href": "labs/lab-3_describe-viz.html#scenario-and-goal",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nIn this lab, you will act as a data journalist exploring a dataset on movies. We will use the data from the FiveThirtyEight story ‚ÄúThe Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion of Women.‚Äù\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction.\nYour goal is to import, describe, and visualize this data to understand the characteristics of movies in the dataset and see if there are relationships between a movie‚Äôs budget, its box office gross, and its Bechdel Test rating. This is the critical first step in any analysis, known as Exploratory Data Analysis (EDA).",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#variables-of-interest",
    "href": "labs/lab-3_describe-viz.html#variables-of-interest",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Variables of Interest",
    "text": "Variables of Interest\n\nyear: The year of movie release\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don‚Äôt talk to each other\nnowomen = fewer than two women\n\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\nbudget_2013: Total movie budget",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-3_describe-viz.html#exercises",
    "href": "labs/lab-3_describe-viz.html#exercises",
    "title": "Lab 3: Describing and Visualizing Data",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1: Importing and Inspecting\nFirst, you need to set up your RMarkdown to get it ready for importing the data and using the appropriate libraries. Be sure to have all libraries listed here in the first code chunk along with importing the data. I should not see any lines that say install.packages().\nI will attempt to reproduce your output in my own computer, so be sure that your code is reproducible.\nQuestion 1: Look at the output from your overview. How many total movies are in this database? And what year is the latest movie?\nYour Answer:\nQuestion 2: Calculate the Average budget of the whole dataset. Then, calculate the average for only movies in the year 2000.\nYour Answer:\n\n\n\nExercise 2: Grouped Descriptive Statistics\nAverages for the whole dataset are useful, but we are often more interested in comparing averages between groups. Let‚Äôs see if the average budget differs for movies that pass the Bechdel Test versus those that fail. The binary variable tells us this (‚ÄúPASS‚Äù or ‚ÄúFAIL‚Äù).\nQuestion 3: Based on your summary table, do movies that pass or fail the Bechdel test have a higher average (mean) budget?\nYour Answer:\n\n\n\nExercise 3: Visualizing a Distribution (Histogram)\nLet‚Äôs visualize the distribution of domestic gross earnings (adjusted for 2013) across all the movies.\nQuestion 4: Describe the shape of the distribution you see in the histogram. Is it symmetric (like a bell curve), or is it skewed in one direction? Where do most movies‚Äô earnings seem to be clustered?\nYour Answer:\n\n\n\nExercise 4: Examining the Bechdel Test distribution\nNow we want to see how many movies fall into each of the Bechdel categories. Generate a barplot of the clean_test variable to see what the distribution of the test is.\nThen choose a year in the dataset, create a similar plot (but only for that year). Therefore you should have 2 plots below:\nQuestion 5: Examine both charts and describe the similarities and differences that you are noticing.\nAnswer:\n\n\n\nExercise 5: Comparing Groups with a Boxplot\nNow let‚Äôs visually compare the inflation-adjusted international gross (intgross_2013) for movies that pass the Bechdel test versus those that fail. A boxplot is an excellent way to see differences in the median and spread between groups.\nQuestion 6: Look at the boxplot. The thick horizontal line in the middle of each box represents the median. Does there appear to be a large difference in the median domestic gross between movies that pass and fail the test?\nYour Answer:\n\nEnd of Lab 3. You‚Äôve now practiced exploratory data analysis! It is always important to visualize your data to get a good sense of what you are working with. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 3 - Describe/Visualize"
    ]
  },
  {
    "objectID": "labs/lab-12.html",
    "href": "labs/lab-12.html",
    "title": "Lab 12: Categories & Regression",
    "section": "",
    "text": "Answer the questions below:\n\nHigh correlation, good or bad? Two friends, Frances and Annika, are in disagreement about whether high correlation values are always good in the context of regression. Frances claims that it‚Äôs desirable for all variables in the dataset to be highly correlated to each other when building linear models. Annika claims that while it‚Äôs desirable for each of the predictors to be highly correlated with the outcome, it is not desirable for the predictors to be highly correlated with each other. Who is right: Frances, Annika, both, or neither? Explain your reasoning using appropriate terminology.\nMeat consumption and life expectancy. In data collected for You et al.¬†(2022), total meat intake is associated with life expectancy (at birth) in 175 countries. Meat intake is measured in kg per capita per year (averaged over 2011 to 2013). The scatterplot on the top left displays the relationship between life expectancy at birth vs. per capita meat consumption. The scatterplot on the top right displays the same relationship colored by income status of the country. The set of scatterplots across the bottom display the same relationship by income status of the country.\n\n\n\nDescribe the relationship between meat consumption and life expectancy.\nWhy do you think the variables are positively associated?\nIs the relationship between meat consumption and life expectancy stronger, similar, or weaker when broken down by income bracket in the separate plots along the bottom (as compared with the relationship when combined in the top left figure)?\n\n\n\nBaby weights and smoking. US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country. The data used here are a random sample of 1,000 births from 2014. Here, we study the relationship between smoking and weight of the baby. The variable smoke is coded 1 if the mother is a smoker, and 0 if not. The summary table below shows the results of a linear regression model for predicting the average birth weight of babies, measured in pounds, based on the smoking status of the mother.\n\n\n\nWrite the equation of the regression model.\nInterpret the slope in this context, and calculate the predicted birth weight of babies born to smoker and non-smoker mothers.\n\n\n\nMovie returns, prediction. A model was fit to predict return-on-investment (ROI) on movies based on release year and genre (Adventure, Action, Drama, Horror, and Comedy). The model output is shown below.\n\n\n\nFor a given release year, which genre of movies are predicted, on average, to have the highest predicted return on investment?\nThe adjusted \\(R^2\\) of this model is 10.71%. Adding the production budget of the movie to the model increases the adjusted \\(R^2\\) to 10.84%. Should production budget be added to the model? Why or Why not?",
    "crumbs": [
      "Labs",
      "Lab 12"
    ]
  },
  {
    "objectID": "labs/lab-12.html#instructions",
    "href": "labs/lab-12.html#instructions",
    "title": "Lab 12: Categories & Regression",
    "section": "",
    "text": "Answer the questions below:\n\nHigh correlation, good or bad? Two friends, Frances and Annika, are in disagreement about whether high correlation values are always good in the context of regression. Frances claims that it‚Äôs desirable for all variables in the dataset to be highly correlated to each other when building linear models. Annika claims that while it‚Äôs desirable for each of the predictors to be highly correlated with the outcome, it is not desirable for the predictors to be highly correlated with each other. Who is right: Frances, Annika, both, or neither? Explain your reasoning using appropriate terminology.\nMeat consumption and life expectancy. In data collected for You et al.¬†(2022), total meat intake is associated with life expectancy (at birth) in 175 countries. Meat intake is measured in kg per capita per year (averaged over 2011 to 2013). The scatterplot on the top left displays the relationship between life expectancy at birth vs. per capita meat consumption. The scatterplot on the top right displays the same relationship colored by income status of the country. The set of scatterplots across the bottom display the same relationship by income status of the country.\n\n\n\nDescribe the relationship between meat consumption and life expectancy.\nWhy do you think the variables are positively associated?\nIs the relationship between meat consumption and life expectancy stronger, similar, or weaker when broken down by income bracket in the separate plots along the bottom (as compared with the relationship when combined in the top left figure)?\n\n\n\nBaby weights and smoking. US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country. The data used here are a random sample of 1,000 births from 2014. Here, we study the relationship between smoking and weight of the baby. The variable smoke is coded 1 if the mother is a smoker, and 0 if not. The summary table below shows the results of a linear regression model for predicting the average birth weight of babies, measured in pounds, based on the smoking status of the mother.\n\n\n\nWrite the equation of the regression model.\nInterpret the slope in this context, and calculate the predicted birth weight of babies born to smoker and non-smoker mothers.\n\n\n\nMovie returns, prediction. A model was fit to predict return-on-investment (ROI) on movies based on release year and genre (Adventure, Action, Drama, Horror, and Comedy). The model output is shown below.\n\n\n\nFor a given release year, which genre of movies are predicted, on average, to have the highest predicted return on investment?\nThe adjusted \\(R^2\\) of this model is 10.71%. Adding the production budget of the movie to the model increases the adjusted \\(R^2\\) to 10.84%. Should production budget be added to the model? Why or Why not?",
    "crumbs": [
      "Labs",
      "Lab 12"
    ]
  },
  {
    "objectID": "labs/lab-11.html",
    "href": "labs/lab-11.html",
    "title": "Lab 11: Categories & Regression",
    "section": "",
    "text": "Here is the data you will need for this lab:\n\nDownload Mental Health Data (.csv)\n\nData is pulled from Kaggle.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 11"
    ]
  },
  {
    "objectID": "labs/lab-11.html#instructions",
    "href": "labs/lab-11.html#instructions",
    "title": "Lab 11: Categories & Regression",
    "section": "",
    "text": "Here is the data you will need for this lab:\n\nDownload Mental Health Data (.csv)\n\nData is pulled from Kaggle.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 11"
    ]
  },
  {
    "objectID": "labs/lab-11.html#scenario-goal",
    "href": "labs/lab-11.html#scenario-goal",
    "title": "Lab 11: Categories & Regression",
    "section": "Scenario & Goal",
    "text": "Scenario & Goal\nWe are getting back to using R! ü•≥ This lab will focus on examining categorical predictors. Similar to what we did in class this week.\nThe data for the lab contains information by country (Entity) and year for the overall prevalence of various forms of mental health/psychopathology. We are seeking to examine differences that may arise as a result of country and year.\n\n\nTask 1: Setup & Data Inspection (15 points)\nYour first and most important task is always to understand and inspect your data before running any analyses.\nTasks:\n\nCreate a new R Markdown file named Week11_Lab.Rmd.\nLoad Libraries and Data\nInitial Inspection:\n\nUse glimpse() or summary() to see the structure of your data.\nWhat are all the countries included in this dataset? What is the year range?\n\nVisualization:\n\nGenerate a visualization of the distribution (histogram or bar plot) across all years for each of the mental health variables (5 total plots)\n\nThis will not be separated by country. We want to see what the overall distribution for these variables are for the whole dataset.\n\n\nSummary Stats (2 tables):\n\nProvide descriptive statistics (Means & SD) in a formatted table (not just using describe()) that is separated by country that includes the mental health variables. This will be collapsed across all years.\nInclude a correlation table examining the relationship among all mental health variables for the year 2015. Be sure to include a title and update the labels.\n\n\n\n\nTask 2: Categorical Regression (20 points)\nWe are now interested in seeing if there are differences among the years and countries when it comes to the prevalence of these mental health variables.\n\nRegression by country:\n\nInclude 3 different countries and perform 2 regressions to separately predict depression and anxiety (ignoring the year variable; meaning you don‚Äôt have to filter by year). For 1 of the regressions, provide a formatted table and write up the results in APA format.\n\nWe should be seeing two regressions that each have the country variable with 3 levels. Then a table and write up for 1 of the regressions.\n\n\n\n\n\nRegression by Time:\n\nUsing all countries, include 4 different years and perform 2 regressions to predict depression and anxiety variables. Similar to above, select one of the regressions, provide a formatted table and write up the results in APA.\n\n\n\n\nTask 3: Follow-up questions (10 points)\nPlease answer the following information about this dataset and categorical predictors\n\nFor each of your regressions, which group was your reference group? How do you know?\nBased on the results that you have identified in with your regressions, report an overarching conclusion about mental health rates over time/countries.\nA researcher is studying the effect of a student‚Äôs undergraduate major on their starting salary after graduation. The major variable has four levels: ‚ÄúPsychology‚Äù, ‚ÄúBiology‚Äù, ‚ÄúEngineering‚Äù, and ‚ÄúEnglish‚Äù.\n\nIf you were to include this variable in a regression model using\ndummy coding, how many new dummy variables would you need to create?\nIf you set \"Psychology\" as the reference group, what values would\neach dummy variable have for a student who majored in \"Engineering\"?\n\nIn a linear regression model predicting students‚Äô self-reported well_being scores from their year_in_school (a categorical variable with levels: ‚ÄúFirst-year‚Äù, ‚ÄúSophomore‚Äù, ‚ÄúJunior‚Äù, ‚ÄúSenior‚Äù), ‚ÄúFirst-year‚Äù is the reference group.\n\nThe model output shows a coefficient of **-2.5** for the\n`year_in_schoolSenior` dummy variable. In one clear sentence, what\nis the correct interpretation of this coefficient?\n\nImagine you refit the model from the previous question, but this time you set \"Senior\" as the reference group instead of \"First-year\".\n\nWould you expect the coefficient for the `year_in_schoolFirst-year`\ndummy variable in this *new* model to be positive, negative, or\nzero? Explain your reasoning in one sentence.\n\n\nFormatting (5 points)\nFormatting includes having clear code and statements in your documents. Avoid including unnecessary information.\nBe sure to submit both an .Rmd file and an HTML file that is complete. Failure to include both will result in an automatic 10 point deduction.",
    "crumbs": [
      "Labs",
      "Lab 11"
    ]
  },
  {
    "objectID": "labs/reverse_results.html",
    "href": "labs/reverse_results.html",
    "title": "Reverse Results",
    "section": "",
    "text": "From Reader to Writer\nOne of the most challenging parts of writing a research paper is crafting a clear and compelling results section. How do you go from a folder full of statistical output to a coherent narrative? The best way to learn is to see how experts do it.\nIn this assignment, you will ‚Äúreverse-engineer‚Äù the results section of a published paper. Think of yourself as an apprentice studying a master‚Äôs work. Your goal is to uncover the underlying architecture‚Äîthe deliberate choices the author made to guide the reader through their findings. This process will help you build a mental toolkit of effective strategies for your own writing.\n\n\nInstructions\n\nStep 1: Select a Research Article\n\nFind a peer-reviewed, quantitative research article in a topic area that interests you. The article should be a strong example of clear scientific writing.\nThe article should test one or more specific hypotheses using statistical methods we have discussed or will be discussing (e.g., t-tests, ANOVA, correlation, regression).\nDo not choose a meta-analysis, literature review, or qualitative study.\n\n\n\nStep 2: Create Your Writer‚Äôs Blueprint\nRead the results section with a writer‚Äôs eye. Your task is to outline the author‚Äôs ‚Äúmoves.‚Äù For each paragraph or distinct analytical block, your outline should explain the narrative strategy. Instead of just summarizing, analyze how and why the paragraph is constructed the way it is.\nFor each section of your outline, describe:\n\nThe Narrative Goal: What is the author‚Äôs primary goal for this paragraph? What key question is it answering for the reader? (e.g., ‚ÄúHere, the author is setting the stage by confirming the randomization worked,‚Äù or ‚ÄúThis is the crucial paragraph where they test their main hypothesis.‚Äù).\nThe Writing Strategy: How did they structure the paragraph to achieve that goal? Notice the flow. Do they lead with a plain-language summary? How do they present the statistical evidence in support of their claim? (e.g., ‚ÄúThe author uses a ‚ÄòClaim-First‚Äô structure: they state the finding in words, then provide the stats to back it up.‚Äù).\n\n\n\n\nExample\nConsider this fictional paragraph from a results section:\n\nTo test our primary hypothesis that the CBT intervention would reduce social anxiety symptoms more than the waitlist control condition, we conducted an independent-samples t-test on post-treatment SAQ scores. The analysis revealed a significant difference between the groups, t(72) = 3.88, p &lt; .001. The mean SAQ score for the CBT group (M = 24.5, SD = 5.1) was significantly lower than the mean score for the waitlist control group (M = 35.2, SD = 6.3), indicating a strong treatment effect.\n\nYour blueprint entry for this paragraph might look like this:\n\nParagraph 3: Testing the Main Hypothesis.\n\nNarrative Goal: To present the findings for the study‚Äôs primary research question.\nWriting Strategy:\n\nState the Why: They begin by explicitly stating which hypothesis they are testing and what analysis they used (independent-samples t-test).\n\nDeliver the Punchline: They immediately present the finding (t(72)=3.88,p&lt;.001).\nExplain in Context: Translate the statistic back into meaningful terms by presenting the group means, making the result easy to understand.\nThis ‚ÄúPurpose -&gt; Evidence -&gt; Interpretation‚Äù flow is a powerful and clear way to structure a finding.\n\n\n\n\n\n\nWhat to Submit\nPlease submit a single document to myCourses with:\n\nA full APA-style citation of the article you selected\nYour complete ‚ÄúWriter‚Äôs Blueprint‚Äù of the article‚Äôs results section."
  },
  {
    "objectID": "labs/lab-1_data-workflow.html",
    "href": "labs/lab-1_data-workflow.html",
    "title": "Lab 1: Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 1: Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n‚ùìQuestion 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet‚Äôs say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n‚ùìQuestion: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let‚Äôs create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n‚ùìQuestion 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n‚ùìQuestion: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd of Lab 1. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 1 - Data Intro"
    ]
  },
  {
    "objectID": "labs/lab-1_data-workflow.html#instructions",
    "href": "labs/lab-1_data-workflow.html#instructions",
    "title": "Lab 1: Foundations of a Data Workflow",
    "section": "",
    "text": "Welcome to your first lab! The goal of this assignment is to move beyond basic syntax and begin practicing a reproducible data analysis workflow.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 1: Foundations of a Data Workflow\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the final .html file.\n\n\n\nA major strength of R is its ecosystem of packages that add new functionality. We will use the tidyverse package in almost every analysis we do. The ggplot2 package, which is part of the tidyverse, contains a dataset called msleep about mammal sleep patterns.\n# Task 1: Load the tidyverse package.\n# Write your code here:\n\n\n# Task 2: The `msleep` dataset is available after loading the tidyverse.\n# Use the `glimpse()` function to get a quick overview of the `msleep` dataset.\n# Write your code here:\n\n\n# Task 3: Now use the `summary()` function on the `msleep` dataset.\n# Write your code here:\n‚ùìQuestion 1: Based on the output of glimpse(), how many rows (observations) and columns (variables) are in the msleep dataset?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: What is one key difference between the information provided by glimpse() and the information provided by summary() for a variable like sleep_total?\nYour Answer: [Type your answer here]\n\n\n\n\nLet‚Äôs say we are only interested in herbivores. We can use functions from the dplyr package (part of the tidyverse) to create a new, sorted dataset.\n# Task 1: Create a new object called `herbivores` that contains only the animals\n# from the `msleep` dataset where the `vore` column is equal to \"herbi\".\n# Hint: The syntax for filtering is: new_object &lt;- old_object %&gt;% filter(column_name == \"value\")\n# Write your code here:\n\n\n# Task 2: Now, sort this new `herbivores` dataset by total sleep time, from highest to lowest.\n# You can overwrite the `herbivores` object with the newly sorted version.\n# Hint: Use the `arrange()` function with `desc()` for descending order.\n# The syntax is: object &lt;- object %&gt;% arrange(desc(column_to_sort_by))\n# Write your code here:\n\n\n# Now, print the new, sorted `herbivores` object to see the result.\n‚ùìQuestion: After sorting, which herbivore sleeps the most? How many hours does it sleep?\nYour Answer: [Type your answer here]\n\n\n\n\nData visualization is a critical part of understanding data. Let‚Äôs create a scatterplot to see if there is a relationship between how long a herbivore sleeps and how much time it spends dreaming.\n# Task: Create a scatterplot using ggplot().\n# We want to plot the `sleep_rem` (dreaming sleep) on the y-axis and `sleep_total` on the x-axis,\n# using only our `herbivores` dataset.\n# Fill in the blanks in the code below.\n\nggplot(data = ________, aes(x = _______, y = _________)) +\n  geom_????? +\n  labs(title = \"Total Sleep vs. REM Sleep in Herbivores\",\n       x = \"Total Sleep (hours)\",\n       y = \"REM Sleep (hours)\")\n‚ùìQuestion 1: Look at the plot you created. In one or two sentences, describe the relationship you see between total sleep and REM sleep for these animals. Is the relationship positive, negative, or is there no clear relationship?\nYour Answer: [Type your answer here]\n‚ùìQuestion 2: Are there any animals that seem unusual or stand out from the general pattern? Briefly describe one.\nYour Answer: [Type your answer here]\n\n\n\n\nOften, we want to calculate a single value to summarize our data. The summarise() function is perfect for this.\n# Task: Calculate the average (mean) total sleep time for ALL mammals in the original `msleep` dataset.\n# Hint: The syntax is: dataset %&gt;% summarise(new_variable_name = mean(column_name, na.rm = TRUE))\n# The `na.rm = TRUE` part is important because it tells R to ignore any missing values.\n# Write your code here:\n‚ùìQuestion: What is the mean total sleep time for all mammals in the dataset?\nYour Answer: [Type your answer here]\n\nEnd of Lab 1. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 1 - Data Intro"
    ]
  },
  {
    "objectID": "labs/midterm-proj.html",
    "href": "labs/midterm-proj.html",
    "title": "Midterm Project",
    "section": "",
    "text": "Here are the things that you will need for this project:\n\nDownload Project Data (.csv)\n\nObjective: The goal of this midterm project is to apply the foundational data analysis skills we have learned in this course. You will be given a real-world dataset and tasked with importing it, preparing it for analysis, conducting descriptive and inferential statistics, and reporting your findings in a clear, professional manner.\n\n\n\n\nCreate an R Markdown File: All your work should be done in a single R Markdown (.Rmd) file. Name your file LastName_FirstName_Midterm.Rmd.\n\nThis file will include your code as well as your written responses. This should look close to a results section with the code in between.\nProvide comments within the code chunks to highlight the main goal of each of the functions or set of information that you are doing. This helps with organization since the reset of the text outside of the code chunks will be for writing the results.\n\nSubmission: You will submit both your .Rmd file and the knitted PDF or HTML document.",
    "crumbs": [
      "Labs",
      "Midterm Project"
    ]
  },
  {
    "objectID": "labs/midterm-proj.html#instructions",
    "href": "labs/midterm-proj.html#instructions",
    "title": "Midterm Project",
    "section": "",
    "text": "Here are the things that you will need for this project:\n\nDownload Project Data (.csv)\n\nObjective: The goal of this midterm project is to apply the foundational data analysis skills we have learned in this course. You will be given a real-world dataset and tasked with importing it, preparing it for analysis, conducting descriptive and inferential statistics, and reporting your findings in a clear, professional manner.\n\n\n\n\nCreate an R Markdown File: All your work should be done in a single R Markdown (.Rmd) file. Name your file LastName_FirstName_Midterm.Rmd.\n\nThis file will include your code as well as your written responses. This should look close to a results section with the code in between.\nProvide comments within the code chunks to highlight the main goal of each of the functions or set of information that you are doing. This helps with organization since the reset of the text outside of the code chunks will be for writing the results.\n\nSubmission: You will submit both your .Rmd file and the knitted PDF or HTML document.",
    "crumbs": [
      "Labs",
      "Midterm Project"
    ]
  },
  {
    "objectID": "labs/midterm-proj.html#project-steps",
    "href": "labs/midterm-proj.html#project-steps",
    "title": "Midterm Project",
    "section": "Project Steps",
    "text": "Project Steps\n\nPart 1: Setup and Data Import\nYour first step is to set up your R Markdown document and load the data.\n\nLoad Libraries: At the top of your R Markdown script, load all the necessary libraries. You don‚Äôt have to know every single library to use here. Just be sure to add them to this section as you are going through your code.\nLoad the Data: Use the appropriate function (e.g., read_csv()). Be sure that this is easily reproducible on another computer.\n\n\n\nPart 2: Data Cleaning and Scoring\nReal-world data is often messy. In this part, you will wrangle the data and create new variables needed for your analysis.\n\nScoring the ARS-SF (Anxiety Resilience Scale - Short Form): We need to first reverse score Item #6. Then we can create two subscales:\n\nAnxiety Subscale - Calculate the mean of Items 1, 2 & 3.\nResilience Subscale - Calculate the mean of Items 4, 5 & 6(reversed).\n\nRecoding Variables: Create a new, cleanly labeled factor variable for any grouping variable (see example code below on how to do this). Recode the numeric values (e.g., 1s and 2s) to meaningful labels (e.g., ‚ÄúMale‚Äù and ‚ÄúFemale‚Äù).\n\n# Recode the grouping variable into a factor with clear labels\nanalytic_data &lt;- analytic_data %&gt;%\n  mutate(\n    [FACTOR_VARIABLE_NAME] = factor([ORIGINAL_VARIABLE],\n                                  levels = c(1, 2),\n                                  labels = c(\"Group 1 Label\", \"Group 2 Label\"))\n  )\n\n\nPart 3: Descriptive Statistics\nNow that you have clean data, let‚Äôs describe it.\n\nContinuous variabels: Get descriptive statistics (mean, sd, median, range) for the continuous variables (Note: when reporting the ARS-SF, just use the subscale scores).\nFrequencies: Use table() or count() to get the frequency distribution for the categorical variables.\nWrite-up: Write a brief paragraph summarizing the descriptive statistics. Report the mean and standard deviation for continuous variables and the counts and percentages for categorical variables.\n\nFor this write-up, focus on the age, sex, group and well-being variables. Include all variables in a table.\n\n\nExample: ‚ÄúThe sample consisted of N = 143 participants (22% female) with an average age of 102.3 (SD = .03). 45% of the sample were students‚Ä¶‚Äù\n\n\nPart 4: Correlation Analysis\nNext, examine the associations between the continuous variables.\n\nCreate a Correlation Matrix: Generate a table of the correlations (hint: use sjPlot). Be sure to include a title and have the labels make sense.\nWrite-up: Report the results in APA style. Describe the direction, strength, and statistical significance of the correlation between the Anxiety score and General Well Being.\n\n\n\nPart 5: Group Differences\nTest for differences in your outcome variable across the three groups.\n\nRun the t-test or ANOVA: Test if the General Well-being score differs significantly across the levels of group. Conduct any follow-up/post-hoc analyses if necessary.\nVisualize the Difference: Create a plot showing the distribution of outcome for each of the groups.\nWrite-up: Report the results in APA style. State whether there was a significant effect of the grouping variable on the outcome. Report follow-up/post-hoc analyses if necessary.\n\n\n\nPart 6: Regression Analysis\nFinally, build a simple linear regression model to predict the General Well-being outcome. Select one predictor variable that you want to investigate.\n\nFit the Model: Use the lm() function to fit a regression model.\nView the Summary: Use summary() to get the detailed results of your model.\nVisualize the Model: Create a scatter plot (ggplot) showing the relationship between the variables (be sure to include a fit line, titles and nice axis labels)\nWrite-up: Write a paragraph summarizing the regression results in APA style. Report the overall model fit (R-squared and F-statistic) and the coefficients for the predictor, noting the statistical significance.\n\nNice work! Don‚Äôt forget to üß∂knit the document to submit!",
    "crumbs": [
      "Labs",
      "Midterm Project"
    ]
  },
  {
    "objectID": "labs/midterm-proj.html#additional-data-information",
    "href": "labs/midterm-proj.html#additional-data-information",
    "title": "Midterm Project",
    "section": "Additional Data Information",
    "text": "Additional Data Information\n\n\n\n\n\n\n\n\nVariable Name\nDescription\nType & Values\n\n\n\n\nID\nParticipant ID Number\nContinuous\n\n\nage\nParticipant‚Äôs age in years.\nContinuous\n\n\nsex\nParticipant‚Äôs self-reported sex.\nNumeric (1 = Male, 2 = Female)\n\n\nARS 1, ASRS 2, ASR 3\nItems for the ‚ÄúAnxiety‚Äù subscale.\nNumeric (0-3)\n\n\nASR 4, ASR 5, ASR 6\nPositive-worded items for the ‚ÄúResilience‚Äù subscale.\nNumeric (1-5)\n\n\nWeekday Sleep\nAverage hours of sleep on a school/work night.\nContinuous\n\n\nWeekend Sleep\nAverage hours of sleep on a non-work night.\nContinuous\n\n\nEmployment\nParticipant‚Äôs primary employment status.\nNumeric (1=‚ÄúStudent‚Äù, 2=‚ÄúEmployed‚Äù, 3=‚ÄúNot Employed‚Äù)\n\n\noutcome\nA score on a ‚ÄúGeneral Well-Being Index.‚Äù\nContinuous",
    "crumbs": [
      "Labs",
      "Midterm Project"
    ]
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6: Comparing Means",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 6 (.Rmd)\nDownload Treatment Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 6 - Comparing Means"
    ]
  },
  {
    "objectID": "labs/lab-6.html#instructions",
    "href": "labs/lab-6.html#instructions",
    "title": "Lab 6: Comparing Means",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 6 (.Rmd)\nDownload Treatment Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 6 - Comparing Means"
    ]
  },
  {
    "objectID": "labs/lab-6.html#scenario-and-goal",
    "href": "labs/lab-6.html#scenario-and-goal",
    "title": "Lab 6: Comparing Means",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nWelcome back! For this lab you‚Äôll step into the role of a data analyst for a clinical psychology lab. Your team has just completed a pilot randomized controlled trial (RCT) for a new, brief CBT (Cognitive Behavioral Therapy) intervention designed to reduce symptoms of depression (group variable). You‚Äôve been given the initial dataset and tasked with running the primary analyses to see if the intervention shows promise.\nThis dataset includes participant demographics (sex, age) and depression scores from before (bdi_pre) and after (bdi_post) the trial. As is common in clinical research, some participants dropped out before the final assessment, resulting in missing data.\n\n\n\n\n\n\nNote\n\n\n\nThe BDI is a common measure to assess for symptoms of depression. It stands for the Beck Depression Inventory and higher scores indicate a higher level of depression.",
    "crumbs": [
      "Labs",
      "Lab 6 - Comparing Means"
    ]
  },
  {
    "objectID": "labs/lab-6.html#exercises",
    "href": "labs/lab-6.html#exercises",
    "title": "Lab 6: Comparing Means",
    "section": "Exercises",
    "text": "Exercises\n\nTask 1: Setup & Data Inspection (10 points)\nYour first and most important task is always to understand and inspect your data before running any analyses.\nTasks:\n\nCreate a new R Markdown file named Week6_Lab.Rmd.\nLoad Libraries and Data\nInitial Inspection:\n\nUse glimpse() to see the structure of your data.\nUse summary() to get a quick overview of each variable. Pay close attention to the bdi_post variable. What do you notice?\n\nVisualization:\n\nGenerate a visualization of the distribution for bdi_pre and bdi_post\n\nThese can be two separate figures\n\n\nSummary Stats (2 tables):\n\nProvide descriptive statistics (Means & SD) in a nice looking table for age, bdi_pre, bdi_post. Include a correlation table with those variables as well.\n\n\n\n\nTask 2: Paired-Samples t-test - Did the Individual CBT Work?\nFor participants who received one-on-one therapy (group == \"Individual CBT\"), did their depression scores significantly decrease?\n\nFilter the data: Create a new data frame called individual_tx that contains only the participants from the Individual CBT group.\nRun the test: Conduct a paired-samples t-test on the bdi_pre and bdi_post scores within the individual_tx data.\nInterpret the results: Based on the results, was there a statistically significant change in BDI scores? Describe the direction and magnitude of the change.\n\n\n\nTask 3: One-Sample t-test - Achieving Clinical Remission\nA BDI score below 10 is often considered the cutoff for clinical remission. Did our individual CBT group, on average, get below this threshold?\n\nRun the test: Using the individual_tx data, conduct a one-sample t-test on the bdi_post scores, testing against a population mean (mu) of 10.\nAPA Write-up: Report your results in a full APA-formatted sentence. You will need to calculate the mean and standard deviation for the bdi_post scores separately to include in your write-up.\n\n\n\nTask 4: One-Way ANOVA\nNow we‚Äôll compare the final outcomes (bdi_post) across all three groups: Individual CBT, Group CBT, and the Waitlist Control.\n\nRun the ANOVA: Using the full cbt_data, conduct a one-way ANOVA to test for differences in bdi_post among the three group conditions.\nInterpret the ANOVA: Look at the summary() of your ANOVA object. Is the overall F-test significant? What does this tell us? Note the degrees of freedom‚Äîdoes the sample size make sense given the data?\nRun Post-Hoc Tests: A significant ANOVA requires a post-hoc test. Run a Tukey HSD test to see which specific groups differ.\nWrite a conclusion: In 2-3 sentences, summarize the findings from the post-hoc test. Which treatment(s) were effective compared to the control group?\n\n\n\nTask 5: Independent-Samples t-test - Exploring Sex as a Moderator\nWe were also interested to use exploratory analyses to further understand the impact of the treatment. For instance, did the therapy work equally well for males and females? Let‚Äôs investigate this.\nTasks:\n\nCalculate change scores: Create a new data frame called cbt_active_tx that contains only the two active therapy groups (Individual and Group CBT). Add a new column to it called bdi_change, calculated as bdi_pre - bdi_post.\nRun the test: In this cbt_active_tx data, conduct an independent-samples t-test to see if there is a significant difference in the bdi_change scores between participants identified as Male and Female.\nVisualize and Interpret: Create a ggplot boxplot to visualize the bdi_change scores by sex. Based on your test and your plot, is there any evidence that the treatment effect was different for males versus females in this pilot study?\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 6 - Comparing Means"
    ]
  },
  {
    "objectID": "ideas.html",
    "href": "ideas.html",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nBy Appointment\n\n\nClass Times\nAsynchronous\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course offers a broad introduction to the field of Psychology, covering various sub-disciplines and emphasizing the scientific study of behavior and cognition. Students will gain a solid understanding of the scientific process, major psychological theories, and the correct usage of psychological terminology. The curriculum fosters critical evaluation skills for examining psychological research findings and highlights practical applications of psychological concepts in daily life. Emphasizing contemporary insights, the course focuses on the scientific method in measuring human behavior, with a student-centric approach that encourages active engagement and self-knowledge.\n\n\n\n\nTextbook: We will an open source (this means free) textbook throughout the semester. The link to the textbook is included below. A PDF version of the text is uploaded to myCourses. ¬†\nSpielman, R. M., Jenkins, W., & Lovett, M. (2020). Psychology 2e. https://openstax.org/details/books/psychology-2e\nOther Required Readings: All additional readings (if necessary) will be posted to the course website.\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\n\n\n\nLecture focus\n\nThe research cycle and where statistics fits\nReproducible workflows (R, RStudio, RMarkdown/Quarto)\nIntro to tidyverse workflow\nStats anxiety & growth mindset\n\nLab\n\nInstall/load R packages\nLoad a dataset (built-in + open source)\nCreate a first plot with ggplot2\n\nReadings\n\nIs Statistics Hard? ‚Äî Wickham & Grolemund, R for Data Science (R4DS) Ch. 1‚Äì2\nAPA: Principles for Translating Statistics to Psychology Students (APA Guidelines)\n\nAssignment\n\nMini data exploration report (import, summarize, plot)\n\n\n\n\n\nLecture focus\n\nWhy regression first?\nVisualizing relationships (scatterplots, grouping)\nThinking in terms of variation & prediction\n\nLab\n\nggplot2 layering: geom_point, geom_smooth\nFaceting and grouping variables\n\nReadings\n\nR4DS Ch. 3, 5\nGelman & Hill (2007) Ch. 2 (Regression as a general method)\n\nAssignment\n\nRecreate 2 plots from lecture with a dataset of your choice\n\n\n\n\n\nLecture focus\n\nModel equation & interpretation of intercept, slope\nEffect size & confidence intervals\nResiduals & assumptions\n\nLab\n\nFit lm() models\nInterpret coefficients & plot regression lines\nDiagnostic plots\n\nReadings\n\nR4DS Ch. 23 (Model basics)\nField, A. (2018) Discovering Statistics Using R, Ch. 7 (sections on simple regression)\n\nAssignment\n\nReport a simple regression with APA-style results\n\n\n\n\n\nLecture focus\n\nAdding predictors: partial slopes\nStandardized coefficients\nCategorical predictors (dummy coding)\n\nLab\n\nlm() with multiple predictors\nModel interpretation with summary()\nCompare models using anova()\n\nReadings\n\nR4DS Ch. 24\nField Ch. 8 (multiple regression basics)\n\nAssignment\n\nMultiple regression report on a dataset you choose\n\n\n\n\n\nLecture focus\n\nInteraction terms\nCentering predictors\nModeration interpretation\n\nLab\n\nInteraction plots with ggplot2\nemmeans for marginal means\n\nReadings\n\nField Ch. 9 (interactions)\nHayes (2018) Ch. 1‚Äì2 (Intro to moderation)\n\nAssignment\n\nAnalyze a moderation model & interpret the interaction\n\n\n\n\n\nLecture focus\n\nWhen outcomes are binary\nOdds ratios & log odds\nModel fit statistics\n\nLab\n\nglm() with family = binomial\nInterpreting odds ratios\nROC curves\n\nReadings\n\nField Ch. 19 (logistic regression)\nPeng, Lee, & Ingersoll (2002) An Introduction to Logistic Regression Analysis\n\nAssignment\n\nLogistic regression report\n\n\n\n\n\nLecture focus\n\nANOVA = regression with categorical predictors\nDummy & effect coding\nPost-hoc tests & contrasts\n\nLab\n\nCompare lm() & aov() outputs\nemmeans for pairwise comparisons\n\nReadings\n\nField Ch. 10‚Äì11 (ANOVA & ANCOVA)\nR4DS Ch. 25 (Categorical variables)\n\nAssignment\n\nANOVA with APA report\n\n\n\n\n\nLecture focus\n\nAdjusting for covariates\nAssumptions & interpretation\n\nLab\n\nFit ANCOVA models\nVisualize adjusted means\n\nReadings\n\nField Ch. 12 (ANCOVA)\nGelman & Hill Ch. 9 (controlling for variables)\n\nAssignment\n\nANCOVA report\n\n\n\n\n\nLecture focus\n\nResidual plots\nNormality, homoscedasticity\nRobust regression options\n\nLab\n\ncheck_model() from performance package\nHandling outliers & transformations\n\nReadings\n\nField Ch. 4 (assumptions)\nWilcox (2012) Ch. 2 (robust methods intro)\n\nAssignment\n\nDiagnostic report on your own dataset\n\n\n\n\n\nLecture focus\n\nMCAR, MAR, MNAR\nMultiple imputation\nComplete case analysis & its dangers\n\nLab\n\nnaniar package for missingness visualization\nmice for imputation\n\nReadings\n\nEnders (2010) Ch. 1‚Äì2 (missing data theory)\nvan Buuren (2018) Ch. 3 (practical imputation)\n\nAssignment\n\nMissing data analysis & imputation\n\n\n\n\n\nLecture focus\n\nWhy random effects?\nRepeated measures within regression\nRandom intercepts & slopes\n\nLab\n\nlme4: lmer() basics\nInterpretation & visualization with sjPlot\n\nReadings\n\nGelman & Hill Ch. 11‚Äì12\nWinter (2013) Linear Mixed Effects Models in R\n\nAssignment\n\nMixed model analysis on a repeated measures dataset\n\n\n\n\n\nLecture focus\n\nDirect & indirect effects\nBootstrapping mediation\nConceptual link to SEM\n\nLab\n\nmediation package\nlavaan for path models\n\nReadings\n\nHayes (2018) Ch. 3‚Äì4 (mediation)\nR4DS Ch. 26 (model building)\n\nAssignment\n\nMediation analysis report\n\n\n\n\n\nLecture focus\n\nWhy power matters\nPower for regression & ANOVA\nPlanning sample sizes\n\nLab\n\npwr package\nSimulation-based power\n\nReadings\n\nCohen (1988) Ch. 1‚Äì2 (effect sizes & power)\nLakens (2021) Sample Size Justification\n\nAssignment\n\nPower analysis for your final project\n\n\n\n\n\nLecture focus\n\nTroubleshooting models\nRefining visualizations & write-up\n\nLab\n\nPeer review final project drafts\n\nReadings\n\nNo new readings ‚Äî review past materials\n\nAssignment\n\nSubmit draft project\n\n\n\n\n\nLecture focus\n\nCommunicating results to non-statistical audiences\nTranslating skills to the workplace\n\nLab\n\nStudent presentations\nClass reflection: ‚ÄúWhat I‚Äôll take forward‚Äù\n\nReadings\n\nNo new readings\n\nFinal Deliverable\n\nFully reproducible RMarkdown/Quarto report with:\n\nIntroduction & research question\nMethods\nRegression-based analysis\nAPA-style results\nVisualizations\nReferences\n\n\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. Due to the accelerated nature of the course, the late penalty will be more severe. There will be a 50% deduction on the first day. Work will not be accepted beyond 24 hours after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nEach course that you are involved in will have differing opinions and goals regarding generative AI (i.e., ChatGPT, Gemini, Perplexity, Claude, etc.). In this course you are allowed to use these as a tool. You can use prompts such as ‚ÄúTeach me about (insert psych topic here) and give me an example that might apply to me.‚Äù If you do use generative AI, I would like for you to disclose that information just so I can have a sense of how it is being used. If I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email."
  },
  {
    "objectID": "ideas.html#intro-to-psychology-online-asynchronous",
    "href": "ideas.html#intro-to-psychology-online-asynchronous",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nBy Appointment\n\n\nClass Times\nAsynchronous\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course offers a broad introduction to the field of Psychology, covering various sub-disciplines and emphasizing the scientific study of behavior and cognition. Students will gain a solid understanding of the scientific process, major psychological theories, and the correct usage of psychological terminology. The curriculum fosters critical evaluation skills for examining psychological research findings and highlights practical applications of psychological concepts in daily life. Emphasizing contemporary insights, the course focuses on the scientific method in measuring human behavior, with a student-centric approach that encourages active engagement and self-knowledge.\n\n\n\n\nTextbook: We will an open source (this means free) textbook throughout the semester. The link to the textbook is included below. A PDF version of the text is uploaded to myCourses. ¬†\nSpielman, R. M., Jenkins, W., & Lovett, M. (2020). Psychology 2e. https://openstax.org/details/books/psychology-2e\nOther Required Readings: All additional readings (if necessary) will be posted to the course website.\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\n\n\n\nLecture focus\n\nThe research cycle and where statistics fits\nReproducible workflows (R, RStudio, RMarkdown/Quarto)\nIntro to tidyverse workflow\nStats anxiety & growth mindset\n\nLab\n\nInstall/load R packages\nLoad a dataset (built-in + open source)\nCreate a first plot with ggplot2\n\nReadings\n\nIs Statistics Hard? ‚Äî Wickham & Grolemund, R for Data Science (R4DS) Ch. 1‚Äì2\nAPA: Principles for Translating Statistics to Psychology Students (APA Guidelines)\n\nAssignment\n\nMini data exploration report (import, summarize, plot)\n\n\n\n\n\nLecture focus\n\nWhy regression first?\nVisualizing relationships (scatterplots, grouping)\nThinking in terms of variation & prediction\n\nLab\n\nggplot2 layering: geom_point, geom_smooth\nFaceting and grouping variables\n\nReadings\n\nR4DS Ch. 3, 5\nGelman & Hill (2007) Ch. 2 (Regression as a general method)\n\nAssignment\n\nRecreate 2 plots from lecture with a dataset of your choice\n\n\n\n\n\nLecture focus\n\nModel equation & interpretation of intercept, slope\nEffect size & confidence intervals\nResiduals & assumptions\n\nLab\n\nFit lm() models\nInterpret coefficients & plot regression lines\nDiagnostic plots\n\nReadings\n\nR4DS Ch. 23 (Model basics)\nField, A. (2018) Discovering Statistics Using R, Ch. 7 (sections on simple regression)\n\nAssignment\n\nReport a simple regression with APA-style results\n\n\n\n\n\nLecture focus\n\nAdding predictors: partial slopes\nStandardized coefficients\nCategorical predictors (dummy coding)\n\nLab\n\nlm() with multiple predictors\nModel interpretation with summary()\nCompare models using anova()\n\nReadings\n\nR4DS Ch. 24\nField Ch. 8 (multiple regression basics)\n\nAssignment\n\nMultiple regression report on a dataset you choose\n\n\n\n\n\nLecture focus\n\nInteraction terms\nCentering predictors\nModeration interpretation\n\nLab\n\nInteraction plots with ggplot2\nemmeans for marginal means\n\nReadings\n\nField Ch. 9 (interactions)\nHayes (2018) Ch. 1‚Äì2 (Intro to moderation)\n\nAssignment\n\nAnalyze a moderation model & interpret the interaction\n\n\n\n\n\nLecture focus\n\nWhen outcomes are binary\nOdds ratios & log odds\nModel fit statistics\n\nLab\n\nglm() with family = binomial\nInterpreting odds ratios\nROC curves\n\nReadings\n\nField Ch. 19 (logistic regression)\nPeng, Lee, & Ingersoll (2002) An Introduction to Logistic Regression Analysis\n\nAssignment\n\nLogistic regression report\n\n\n\n\n\nLecture focus\n\nANOVA = regression with categorical predictors\nDummy & effect coding\nPost-hoc tests & contrasts\n\nLab\n\nCompare lm() & aov() outputs\nemmeans for pairwise comparisons\n\nReadings\n\nField Ch. 10‚Äì11 (ANOVA & ANCOVA)\nR4DS Ch. 25 (Categorical variables)\n\nAssignment\n\nANOVA with APA report\n\n\n\n\n\nLecture focus\n\nAdjusting for covariates\nAssumptions & interpretation\n\nLab\n\nFit ANCOVA models\nVisualize adjusted means\n\nReadings\n\nField Ch. 12 (ANCOVA)\nGelman & Hill Ch. 9 (controlling for variables)\n\nAssignment\n\nANCOVA report\n\n\n\n\n\nLecture focus\n\nResidual plots\nNormality, homoscedasticity\nRobust regression options\n\nLab\n\ncheck_model() from performance package\nHandling outliers & transformations\n\nReadings\n\nField Ch. 4 (assumptions)\nWilcox (2012) Ch. 2 (robust methods intro)\n\nAssignment\n\nDiagnostic report on your own dataset\n\n\n\n\n\nLecture focus\n\nMCAR, MAR, MNAR\nMultiple imputation\nComplete case analysis & its dangers\n\nLab\n\nnaniar package for missingness visualization\nmice for imputation\n\nReadings\n\nEnders (2010) Ch. 1‚Äì2 (missing data theory)\nvan Buuren (2018) Ch. 3 (practical imputation)\n\nAssignment\n\nMissing data analysis & imputation\n\n\n\n\n\nLecture focus\n\nWhy random effects?\nRepeated measures within regression\nRandom intercepts & slopes\n\nLab\n\nlme4: lmer() basics\nInterpretation & visualization with sjPlot\n\nReadings\n\nGelman & Hill Ch. 11‚Äì12\nWinter (2013) Linear Mixed Effects Models in R\n\nAssignment\n\nMixed model analysis on a repeated measures dataset\n\n\n\n\n\nLecture focus\n\nDirect & indirect effects\nBootstrapping mediation\nConceptual link to SEM\n\nLab\n\nmediation package\nlavaan for path models\n\nReadings\n\nHayes (2018) Ch. 3‚Äì4 (mediation)\nR4DS Ch. 26 (model building)\n\nAssignment\n\nMediation analysis report\n\n\n\n\n\nLecture focus\n\nWhy power matters\nPower for regression & ANOVA\nPlanning sample sizes\n\nLab\n\npwr package\nSimulation-based power\n\nReadings\n\nCohen (1988) Ch. 1‚Äì2 (effect sizes & power)\nLakens (2021) Sample Size Justification\n\nAssignment\n\nPower analysis for your final project\n\n\n\n\n\nLecture focus\n\nTroubleshooting models\nRefining visualizations & write-up\n\nLab\n\nPeer review final project drafts\n\nReadings\n\nNo new readings ‚Äî review past materials\n\nAssignment\n\nSubmit draft project\n\n\n\n\n\nLecture focus\n\nCommunicating results to non-statistical audiences\nTranslating skills to the workplace\n\nLab\n\nStudent presentations\nClass reflection: ‚ÄúWhat I‚Äôll take forward‚Äù\n\nReadings\n\nNo new readings\n\nFinal Deliverable\n\nFully reproducible RMarkdown/Quarto report with:\n\nIntroduction & research question\nMethods\nRegression-based analysis\nAPA-style results\nVisualizations\nReferences\n\n\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. Due to the accelerated nature of the course, the late penalty will be more severe. There will be a 50% deduction on the first day. Work will not be accepted beyond 24 hours after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nEach course that you are involved in will have differing opinions and goals regarding generative AI (i.e., ChatGPT, Gemini, Perplexity, Claude, etc.). In this course you are allowed to use these as a tool. You can use prompts such as ‚ÄúTeach me about (insert psych topic here) and give me an example that might apply to me.‚Äù If you do use generative AI, I would like for you to disclose that information just so I can have a sense of how it is being used. If I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email."
  },
  {
    "objectID": "labs/lab-10.html#objective",
    "href": "labs/lab-10.html#objective",
    "title": "Lab 10: Multiple Regression",
    "section": "Objective:",
    "text": "Objective:\nThis lab focuses on connecting what we have learned in class to the peer reviewed articles that you may be reading.",
    "crumbs": [
      "Labs",
      "Lab 10"
    ]
  },
  {
    "objectID": "labs/lab-10.html#instructions",
    "href": "labs/lab-10.html#instructions",
    "title": "Lab 10: Multiple Regression",
    "section": "Instructions:",
    "text": "Instructions:\nIdentify articles in the scientific literature that perform quantitative analyses (no reviews or meta-analyses).\nFind 2 articles: one that includes a t-test and another that includes multiple regression.\nIn your document, I would like to see:\n\nThe article citations and a designation of whether it is the t-test or multiple regression\nThe extracted text from the article that describes the test they are performing (not necessarily just the results, but their justification).\nThe articles main research question\nHow the analysis (t-test or multiple regression) adds to the ‚Äúanswer‚Äù for the main research question\nReflection on how challenging/easy finding each test was",
    "crumbs": [
      "Labs",
      "Lab 10"
    ]
  },
  {
    "objectID": "labs/lab-10.html#submission",
    "href": "labs/lab-10.html#submission",
    "title": "Lab 10: Multiple Regression",
    "section": "Submission:",
    "text": "Submission:\nPlease submit a document (Word or Google Doc) that includes the information above, as well as the PDFs of the 2 research papers that you identified.",
    "crumbs": [
      "Labs",
      "Lab 10"
    ]
  },
  {
    "objectID": "labs/lab-9.html",
    "href": "labs/lab-9.html",
    "title": "Lab 9: Model Selection & Variability",
    "section": "",
    "text": "We are going to try a lab that doesn‚Äôt involve writing/running any code in R! But you can still use R to answer the questions (or put things into word if you prefer). Remember to knit and turn in a Word Doc. YOU WILL JUST NEED TO SUBMIT A WORD DOC OR GOOGLE DOC.\nObjective: This lab is designed to develop the crucial skill of translating a behavioral science research question into an appropriate statistical model, and vice-versa. Instead of relying on a fixed decision tree, we will practice linking the substance of a question and the structure of the data to the choice of an analytic method. The goal is to foster statistical reasoning, where the model serves the scientific inquiry.\nInstructions: This lab has two parts. For each scenario, provide the requested information, focusing on clear and concise justifications. Please submit your completed lab as a single document.",
    "crumbs": [
      "Labs",
      "Lab 9"
    ]
  },
  {
    "objectID": "labs/lab-9.html#part-1-from-research-question-to-statistical-model",
    "href": "labs/lab-9.html#part-1-from-research-question-to-statistical-model",
    "title": "Lab 9: Model Selection & Variability",
    "section": "Part 1: From Research Question to Statistical Model",
    "text": "Part 1: From Research Question to Statistical Model\nFor each of the following scenarios, you are given a description of a research goal, similar to what might be in an intro.\n\nIdentify the most appropriate statistical model from the options we have covered so far (T-test (i.e., Independent, Dependent, Single Sample), One-Way ANOVA, or Simple Linear Regression).\nWrite a brief (2-3 sentences) justification for your choice. Your justification must reference:\n\nThe nature of the predictor variable (e.g., categorical with two levels, continuous).\nThe nature of the outcome variable.\nWhat the key research question is asking for (e.g., a mean difference, a predictive relationship, a linear trend).\n\n\n\n\nScenario A\n\n‚ÄúPrevious research suggests that individuals with major depressive disorder (MDD) show deficits in cognitive control. However, it is unclear if this deficit is present in those with sub-threshold depressive symptoms. To address this, we recruited two independent groups of young adults: one group meeting formal criteria for MDD (n=50) and a control group with no history of psychiatric disorders (n=50). We hypothesized that the MDD group would show lower performance on the Stroop task, a measure of cognitive control, compared to the control group.‚Äù\n\n\n1. Statistical Model:\n2. Justification:\n\n\n\nScenario B\n\n‚ÄúSleep continuity is vital for well-being, yet its direct relationship with daily mood in non-clinical populations is not well-characterized. We conducted a study to examine whether the number of times a person wakes up during the night predicts their self-reported mood the following morning. We collected data from 100 university students, measuring their number of nocturnal awakenings via a wrist-worn device and their morning mood on a 100-point scale. We expect that a higher number of awakenings will be associated with a lower mood score.‚Äù\n\n\n1. Statistical Model:\n2. Justification:\n\n\n\nScenario C\n\n‚ÄúParental expressed emotion is a key factor in the home environment. We are interested in whether there are differences in academic achievement among adolescents from three distinct home environments, characterized by low, moderate, or high levels of expressed parental criticism. We categorized 150 adolescents into one of these three groups based on a structured family interview and obtained their grade point average (GPA) for the academic year.‚Äù\n\n\n1. Statistical Model:\n2. Justification:\n\n\n\nScenario D\n\n‚ÄúA core symptom of social anxiety disorder is the avoidance of social situations. To test a new intervention, we conducted a randomized controlled trial where participants were assigned to either a 12-week mindfulness-based therapy group or a psychoeducation control group. At the end of the trial, we measured the number of social events each participant attended in the final week. We hypothesize that the mindfulness group will attend a greater number of social events on average than the control group.‚Äù\n\n\n1. Statistical Model:\n2. Justification:\n\n\n\nScenario E\n\n‚ÄúIt is well-established that age is related to cognitive function, but the specific trajectory is of interest. To explore this, we gathered a cross-sectional sample of 200 adults ranging from age 20 to 80. Each participant completed a standardized test of working memory. Our primary goal is to model the linear relationship between a person‚Äôs age and their working memory score to understand the rate of change across the lifespan.‚Äù\n\n\n1. Statistical Model:\n2. Justification:\n\n\n\nScenario F\n\n‚ÄúChronic stress during adolescence can impact physiological regulation. We are interested in whether adolescents who report experiencing high, medium, or low levels of chronic life stress show differences in their morning cortisol levels, a key biomarker of the stress response system. We collected saliva samples from 90 adolescents who were categorized into one of the three stress groups based on a validated questionnaire.‚Äù\n\n\n1. Statistical Model:\n2. Justification:",
    "crumbs": [
      "Labs",
      "Lab 9"
    ]
  },
  {
    "objectID": "labs/lab-9.html#part-2-from-statistical-model-to-research-question",
    "href": "labs/lab-9.html#part-2-from-statistical-model-to-research-question",
    "title": "Lab 9: Model Selection & Variability",
    "section": "Part 2: From Statistical Model to Research Question",
    "text": "Part 2: From Statistical Model to Research Question\nFor each of the following scenarios, you are given the statistical output and a brief description of the variables.\n\nInfer and write out the specific research question that this analysis was likely designed to answer.\nExplain which parts of the output led you to your conclusion.\n\n\n\nScenario G\n\nData Description: A dataset includes bdi_score (Beck Depression Inventory score, continuous) and sleep_hours (average hours of sleep per night, continuous).\nStatistical Output:\n\nCall:\nlm(formula = bdi_score ~ sleep_hours, data = df)\n\nCoefficients:\n(Intercept)  sleep_hours\n     35.50        -2.50\n\n1. Inferred Research Question:\n2. Explanation:\n\n\n\nScenario H\n\nData Description: A dataset includes anxiety_score (a continuous measure of anxiety) and treatment_group (a categorical variable with two levels: ‚ÄúCBT‚Äù and ‚ÄúWaitlist‚Äù).\nStatistical Output:\n\nTwo Sample t-test\ndata:  anxiety_score by treatment_group\nt = -4.5, df = 98, p-value &lt; 0.001\nalternative hypothesis: true difference in means is not equal to 0\nmean in group CBT    mean in group Waitlist\n             15.2                      25.8\n\n1. Inferred Research Question:\n2. Explanation:\n\n\n\nScenario I\n\nData Description: A dataset includes perfectionism_score (a continuous measure from a personality questionnaire) and procrastination_index (a continuous score based on a behavioral task).\nStatistical Output:\n\nCall:\nlm(formula = procrastination_index ~ perfectionism_score, data = df)\n\nCoefficients:\n      (Intercept)  perfectionism_score\n            -5.22                 0.85\n\n1. Inferred Research Question:\n2. Explanation:\n\n\n\nScenario J\n\nData Description: A dataset includes adhd_symptoms (a continuous symptom count) and school_type (a categorical variable: ‚ÄúPublic,‚Äù ‚ÄúPrivate,‚Äù or ‚ÄúCharter‚Äù).\nStatistical Output:\n\nOne-way analysis of means\ndata:  adhd_symptoms by school_type\n\nF = 5.67, num df = 2, denom df = 147, p-value = 0.004\n\n1. Inferred Research Question:\n2. Explanation:\n\n\n\nScenario K\n\nData Description: A dataset includes pain_rating (a patient‚Äôs self-reported pain on a 0-10 scale) and condition (a categorical variable: ‚ÄúAcupuncture‚Äù or ‚ÄúSham Procedure‚Äù).\nStatistical Output:\n\nTwo Sample t-test\ndata:  pain_rating by condition\nt = 2.8, df = 78, p-value = 0.006\nalternative hypothesis: true difference in means is not equal to 0\nmean in group Acupuncture  mean in group Sham Procedure\n                    4.1                       6.2\n\n1. Inferred Research Question:\n2. Explanation:",
    "crumbs": [
      "Labs",
      "Lab 9"
    ]
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 4 (.Rmd)\nDownload Sleep Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#instructions",
    "href": "labs/lab-4.html#instructions",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "",
    "text": "Here are the things that you will need for this lab:\n\nDownload Lab 4 (.Rmd)\nDownload Sleep Data (.csv)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#scenario-and-data",
    "href": "labs/lab-4.html#scenario-and-data",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Scenario and Data",
    "text": "Scenario and Data\nA researcher at the university‚Äôs sleep center is interested in the factors that affect daytime sleepiness and attention in college students. They collected survey data from a sample of students.\nThe data highlighted above contains the following variables (and more):\n\nESS1 - ESS8: (Continuous) The student‚Äôs responses to each item on the Epworth Sleepiness Scale, a measure of general daytime sleepiness. Higher scores indicate greater sleepiness. NOTE: You will need to calculate a total score which is a sum of all 8 items.\nashs1 - ashs33: (Continuous) The student‚Äôs responses to each item on the Adolescent Sleep Hygiene Scale. Higher scores indicate better sleep habits (e.g., consistent bedtime, quiet environment). The original data collection did not have an item 25 (so you won‚Äôt see one in your data).\n\nNOTE: You will need to reverse score all items except¬†#27. You will also need to calculate a total mean score with these items.\n\nattention1r - attention5r: (Categorical) An indication of whether they passed (1) or failed (0) the attention check item. A proxy for their attention during the survey. NOTE: Calculate a total attention score as a sum of all 5 items.\nage: (Continuous) The student‚Äôs age in years.\nroommate: (Categorical) Whether the student has a roommate or not (‚ÄúYes‚Äù, ‚ÄúNo‚Äù).\n\n1 = ‚ÄúYes‚Äù and 2 = ‚ÄúNo‚Äù",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#task-1-compute-scores-for-scales",
    "href": "labs/lab-4.html#task-1-compute-scores-for-scales",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Task 1: Compute scores for scales",
    "text": "Task 1: Compute scores for scales\nBe sure to compute the appropriate total scores for the ESS, ASHS and Attention variables.\n\n\n\n\n\n\nImportant\n\n\n\nThere are a couple attention items that are in the ASHS section which can get a little confusing when trying to reverse code and getting total scores.\n\n\nOnce completed, only include students who have ‚Äúpassed‚Äù the attention check (i.e., having a score of 4 or higher on the attention sum total).\nhint: use dplyr and filter",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#task-2-roommates-and-daytime-sleepiness-a-group-comparison",
    "href": "labs/lab-4.html#task-2-roommates-and-daytime-sleepiness-a-group-comparison",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Task 2: Roommates and Daytime Sleepiness (A Group Comparison)",
    "text": "Task 2: Roommates and Daytime Sleepiness (A Group Comparison)\nThe Research Question: ‚ÄúDo students who have a roommate report different levels of daytime sleepiness compared to students who do not have a roommate?‚Äù\nYour Steps:\n\nIdentify & Model:\n\nWhat is the predictor (IV) and what is the outcome (DV)?\nAre they categorical or continuous?\nBased on this, what is the appropriate model family? Write out the model in R formula syntax (outcome ~ predictor).\n\nDescribe & Visualize:\n\nCalculate the mean and standard deviation of ess_score for both groups (those with and without a roommate).\nCreate a boxplot to visualize the distribution of ess_score for each group. Make sure your plot is clearly labeled.\n\nAnalyze:\n\nRun the appropriate statistical test in R to determine if there is a significant difference between the groups.\n\nInterpret & Conclude:\n\nWhat is the p-value from your test?\nBased on the test and your descriptive statistics, write a one-sentence conclusion that directly answers the research question.\nCritical Thinking: This is an observational study. Can you conclude that having a roommate causes a change in sleepiness? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#bonus-sleep-habits-and-age-an-association",
    "href": "labs/lab-4.html#bonus-sleep-habits-and-age-an-association",
    "title": "Lab 4: Inferential Stats Basics",
    "section": "Bonus: Sleep Habits and Age (An Association)",
    "text": "Bonus: Sleep Habits and Age (An Association)\nThis question is not required. But you will get some bonus points if you decide to do it!\nThe Research Question: ‚ÄúIs there an association between a student‚Äôs sleep habits and their age?‚Äù\nYour Steps:\n\nIdentify & Model:\n\nWhat is the predictor (IV) and what is the outcome (DV)?\nAre they categorical or continuous?\nBased on this, what is the appropriate model family? Write out the model in R formula syntax.\n\nVisualize:\n\nCreate a scatterplot to visualize the relationship between ashs_score (sleep habits) and age.\nAdd a line of best fit to the plot. Make sure your plot is clearly labeled.\n\nAnalyze:\n\nRun the appropriate statistical test in R to determine if there is a significant association between the two variables.\n\nInterpret & Conclude:\n\nWhat is the correlation coefficient (r) and the p-value from your test?\nBased on these results, write a one-sentence conclusion that describes the nature and significance of the relationship.\n\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/final-proj.html",
    "href": "labs/final-proj.html",
    "title": "Final Project",
    "section": "",
    "text": "The goal of the final project is to apply your knowledge of data analysis skills that we have learned in this course. You will begin by having a research question that you will attempt to answer with an open dataset. Then you will highlight the process, and report the appropriate analyses. All information should be self-contained and 100% reproducible with the file/folder that you have uploaded.\n\n\nWe will be breaking the final project up into sections to help structure the data analytic process.\nPart 1 (Due 11/16): Identify 5 datasets that you could work with for the final project\n\nThese cannot be data that we have used in class before\nData can be from your mentor/lab, but cannot be directly used for your thesis (I just don‚Äôt want a 1 to 1 copy from this to your thesis)\n\nPart 2 (Due 11/23): Narrow down the datasets and generate a testable research question/hypothesis\n\nThis should also include the analyses that you would like to perform\n\nPart 3 (Due 12/08): Share your data and analyses in a brief presentation to the group\n\nYou will also submit a written report that includes your data analytic plan and the results.",
    "crumbs": [
      "Projects",
      "Final Project"
    ]
  },
  {
    "objectID": "labs/final-proj.html#instructions",
    "href": "labs/final-proj.html#instructions",
    "title": "Final Project",
    "section": "",
    "text": "The goal of the final project is to apply your knowledge of data analysis skills that we have learned in this course. You will begin by having a research question that you will attempt to answer with an open dataset. Then you will highlight the process, and report the appropriate analyses. All information should be self-contained and 100% reproducible with the file/folder that you have uploaded.\n\n\nWe will be breaking the final project up into sections to help structure the data analytic process.\nPart 1 (Due 11/16): Identify 5 datasets that you could work with for the final project\n\nThese cannot be data that we have used in class before\nData can be from your mentor/lab, but cannot be directly used for your thesis (I just don‚Äôt want a 1 to 1 copy from this to your thesis)\n\nPart 2 (Due 11/23): Narrow down the datasets and generate a testable research question/hypothesis\n\nThis should also include the analyses that you would like to perform\n\nPart 3 (Due 12/08): Share your data and analyses in a brief presentation to the group\n\nYou will also submit a written report that includes your data analytic plan and the results.",
    "crumbs": [
      "Projects",
      "Final Project"
    ]
  },
  {
    "objectID": "labs/final-proj.html#part-1-due-1116",
    "href": "labs/final-proj.html#part-1-due-1116",
    "title": "Final Project",
    "section": "Part 1 (Due 11/16)",
    "text": "Part 1 (Due 11/16)\nFor the first part of your final project, you will need to identify five potential datasets that you could use to answer a research question. These datasets cannot be ones that we have used in class previously. While you may use data from your mentor or lab, the project you submit for this course cannot be a direct copy of your thesis work.\n‚ÄãWhen searching for datasets, consider the following resources:\n\nOpen Access Repositories: There are several online repositories that house freely accessible datasets. Some of these that are specific to psychology include PsychArchives and PsyArXiv. The Open Science Framework (OSF) is another excellent resource for finding datasets across various disciplines, including psychology.‚Äã\n\n\n\nUniversity and Government-Funded Collections: Many universities and government agencies maintain data repositories. The Inter-university Consortium for Political and Social Research (ICPSR), sponsored by the University of Michigan, is a large archive of social and behavioral science data. The U.S. government also has many open datasets on topics like education and substance abuse that can be useful for psychological research.\nhttps://datasetsearch.research.google.com/\nhttps://github.com/awesomedata/awesome-public-datasets\nhttps://guides.library.unt.edu/health-data-analytics/open-datasets\nhttps://ldbase.org/\nhttps://midus.wisc.edu/\n\nDocument Submission: Please submit a document that has the following information for each dataset:\n\nSource of data (include links)\nBrief description (2-3 sentences) of the data (i.e., what is it measuring)\nSample Size\nBrief rationale for why you think it would be a good choice for this project (3-5 sentences)",
    "crumbs": [
      "Projects",
      "Final Project"
    ]
  },
  {
    "objectID": "labs/final-proj.html#part-2-due-1123",
    "href": "labs/final-proj.html#part-2-due-1123",
    "title": "Final Project",
    "section": "Part 2 (Due 11/23)",
    "text": "Part 2 (Due 11/23)\nFor the second part of the project, you will select one of the five datasets you identified in Part 1 and develop a testable research question/hypothesis. Your research question should be specific and able to be answered using the data in your chosen dataset.\n‚ÄãYour proposal for Part 2 should include the following sections:\n\nIntroduction: Briefly introduce the dataset you have chosen and the general topic you will be investigating. Be sure to include 3+ citations to support your investigation\nResearch Question and Hypothesis: State your research question clearly and concisely. If applicable, formulate a specific, testable hypothesis that you will evaluate with your data analysis.\nProposed Analyses: Describe the statistical analyses you plan to use to test your hypothesis/research question. Your analyses must include at least 2 tests that we have gone over in class. One of these tests must be a regression.\n\n\n\n\n\n\n\nNote\n\n\n\nIf your selected dataset has greater than 400 participants, you will need to create a random subset that has N = 400 for your analyses",
    "crumbs": [
      "Projects",
      "Final Project"
    ]
  },
  {
    "objectID": "labs/final-proj.html#part-3-due-128---in-class",
    "href": "labs/final-proj.html#part-3-due-128---in-class",
    "title": "Final Project",
    "section": "Part 3 (Due 12/8 - In Class)‚Äã",
    "text": "Part 3 (Due 12/8 - In Class)‚Äã\nThe final part of the project consists of a brief presentation to the class and a written report of your data analysis plan and results.\n\nPresentation‚Äã\nYour presentation should be a brief overview of your project. It should be well-organized and engaging. This can take the form of a slideshow (5 slides maximum), or any other way that you would like to convey your message. Be sure to include the following:\n\nIntroduction: Briefly introduce your research question and why it is important.\nMethods: Describe the dataset you used and the statistical analyses you performed. Reminder: Your analyses must include at least 2 tests that we have gone over in class. One of these tests must be a regression.\nResults: Present your main findings, using graphs and tables to help illustrate your results.\nDiscussion: Interpret your results and discuss their implications.\n\n\n\nWritten Report\n\n\n\n\n\n\nImportant\n\n\n\n12 point font, 1 inch margins, double-spaced, 5 page minimum (excluding tables, figures, references and anything else that isn‚Äôt your writing), 7 page maximum\n\n\nYour written report should be a comprehensive summary of your project. It should be well-structured and include the following sections:\n\n‚ÄãIntroduction: Provide an overview of your research problem and state your research question and hypothesis. Include 3+ citations\n‚ÄãMethods: Detail the data you used, including its source and any cleaning or preparation steps you took. You should also describe the statistical methods you used in enough detail that another researcher could replicate your analyses.\n‚ÄãResults: Present the results of your analyses in a clear and organized manner. Use tables and figures (APA formatting or whatever field is relevant) to display your results, and be sure to include relevant statistical information (e.g., p-values, confidence intervals, effect sizes).\nDiscussion: Interpret your findings in the context of your research question. Discuss the limitations of your study and suggest directions for future research.\n‚ÄãConclusion: Briefly summarize your main findings and their significance.\n\nYour final submission should be a single folder that is 100% reproducible, meaning that all of your data and code should be included and organized in a way that someone else could easily re-run your analyses.",
    "crumbs": [
      "Projects",
      "Final Project"
    ]
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html",
    "href": "labs/lab-2_data-wrangling.html",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "",
    "text": "We have made it to Lab #2! We are going to keep practicing the skills we started using in the last week, except with using some new data. Before, we were using pre-installed data, but that won‚Äôt be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 2: Data Wrangling Beginnings\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nHere is a .Rmd file that you should be able to download and use as well.\n\nDownload Lab 2 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 2 - Wrangling Intro"
    ]
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html#instructions",
    "href": "labs/lab-2_data-wrangling.html#instructions",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "",
    "text": "We have made it to Lab #2! We are going to keep practicing the skills we started using in the last week, except with using some new data. Before, we were using pre-installed data, but that won‚Äôt be the case IRL. When working with your own data, you will want to create a workflow of cleaning and wrangling your data in a reproducible way. These steps will likely occur for every new dataset that you work with.\nPlease complete the exercises below. Create a new .Rmd file and include the following at the top:\n---\ntitle: \"Lab 2: Data Wrangling Beginnings\"\nauthor: \"Your Name Here\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\nYou should then be able to copy/paste everything below into your document.\nHere is a .Rmd file that you should be able to download and use as well.\n\nDownload Lab 2 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 2 - Wrangling Intro"
    ]
  },
  {
    "objectID": "labs/lab-2_data-wrangling.html#scenario-and-goal",
    "href": "labs/lab-2_data-wrangling.html#scenario-and-goal",
    "title": "Lab 2: Data Wrangling Beginnings",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nCongratulations, you‚Äôve just collected data for a study on ‚ÄúPersonality‚Äù! You administered a 10-item personality questionnaire, where participants responded on a 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree). This measure is called the ‚ÄúTen Item Personality Inventory‚Äù (TIPI) and more information about the measure can be found here: TIPI Scale Info. Please refer to this page and documents to help with scoring the data and getting familiar with the measure.\nHowever, the raw data from the survey software is messy. Your goal in this lab is to import, clean, and score the data to prepare it for analysis. This process of turning raw data into usable data is called data wrangling, and it‚Äôs what researchers spend most of their time doing.\nYou will learn to: * Import a CSV file. * Rename variables for clarity. * Filter out participants based on data quality checks. * Reverse-score negatively worded items. * Compute a composite score for a psychological scale.\n\n\nGetting Data\nBe aware of your file structure and how things are organized. For some refreshers, take a look at the Resources and rstats.wtf\n\nDownload your data\nDownload Data from Drive (CSV)\nDownload Questionnaire From Drive (DOC)\n\n\n\nExercise 1: Importing and Inspecting the Data\nFirst, you need to load the appropriate packages and import your data. Use the tidyverse, rio, and here libraries.\n# Load the appropriate libraries.   \n\n# Write your import code here:   \n  ## This will look like:     \n  # your_data_name &lt;- import(here(\"path\", \"to\", \"file\", \"filename.csv))    \n\n\n# Use glimpse() to get a first look at the raw_data. \n# Write your code here:  \nQuestion 1: How many participants (rows) are in the raw, imported dataset?\n‚ùìYour Answer: [Type your answer here]\n\n\n\nExercise 2: Renaming Variables for Clarity\nThe column names are a mixture of naming conventions. Let‚Äôs rename them to be consistent and convey the appropriate information.\nFirst, let‚Äôs take a look at what the names are. You can do this by using View(), but let‚Äôs use the names() function to list out all the column names.\nnames(Whatever_you_Named_your_data)\nThis will give you your list of names. You can see which ones we may want to rename. What does Q85 even mean? Thanks Qualtrics. Review the documentation for the survey to get a sense of what the questions are asking to properly rename the variables.\nFor now, let‚Äôs update the names as follows. It is helpful to keep everything lowercase to make it easier to type (but this is a personal preference), and make sure there aren‚Äôt any spaces in your variable names:\n\nID -&gt; id\nProgress -&gt; progress\nDuration (in seconds) -&gt; duration\nConsent -&gt; consent\nQ85 -&gt; sex_orient\nQ85_6_TEXT -&gt; sex_orient_txt\nSleep Quality -&gt; sleep_qual\nHours of Sleep -&gt; sleep_hours\n\n# Task: Use the rename() function to change the variable names as listed above.\n# Create a new object called `renamed_data`.\n# Hint: The syntax is: new_object &lt;- old_object %&gt;% rename(new_name_1 = old_name_1, new_name_2 = old_name_2)\n\n# Write your code here:\n# This part is a placeholder as the actual column names from the URL will differ.\n# Be sure to update the following template with the info from your own data\nrenamed_data &lt;- raw_data %&gt;%\n  rename(participant_id = country, \n         grit_1 = year,\n         grit_2 = population)\n         # ... and so on for the other variables\n\n# Print the first few rows of your new `renamed_data` object to check your work.\nhead(renamed_data)\n\n\n\nExercise 3: Filtering for Data Quality\nOur survey includes variables that allow us to see how long they took and what percentage they completed. We should remove participants who did not finish the survey, as well as those who finished it too quickly.\nThis will be done using the filter() function (more about filter). Use filter to keep participants where their progress is equal to 100. You will also want to remove participants who completed the survey in less than 7 minutes (note: the Duration variable is in seconds).\n# Create a new object called `filtered_data`.\n\n# Example code:\n# filtered_data &lt;- renamed_data %&gt;%\n#   filter(Progress == 100) %&gt;% \n#   filter(Duration ==, &lt;, &gt; 1000)\nQuestion 2: How many participants remain from your original dataset? How many participants did you remove with your filters?\n‚ùìYour Answer: [Type your answer here]\n\n\n\nExercise 4: Reverse-Scoring Items\nIn a lot of psychological research, we need to reverse score variables. They are often worded in a negative/positive way compared to the rest of the items. Review the TIPI documentation to see what items need to be reverse scored.\nFor example, Item 2 is a item that should reflect ‚ÄúAgreeableness‚Äù, but the rated words are ‚ÄúCritical, quarrelsome‚Äù. Therefore low score on this item would reflect high amounts of Agreeableness.\nThe formula for reverse scoring an item is: (Maximum Possible Value + 1) - Original Score. So, for the TIPI, it‚Äôs 8 - TIPI_2.\nTo create/compute a new variable we use the mutate() function (more about mutate). I like to remember this function name because we are ‚Äúmutating‚Äù the data and introducing another ‚Äúgrowth‚Äù or something extra that wasn‚Äôt there before.\n# Task: Use the mutate() function to create new, reverse-scored variables.\n# Use a new name to indicate which items are reverse-scored.\n# Create a new object called `scored_data`.\n# Hint: The syntax is: \n  # new_object &lt;- old_object %&gt;% \n  #   mutate(new_variable = computation, \n  #          new_variable2 = computation)\n\n\n# Exmple code:\n# scored_data &lt;- filtered_data %&gt;%\n#   mutate(TIPI_2r = 8 - TIPI_2)\n\n\n\n# Print the first few rows, showing only the original and new reverse-scored item to check your work.\n\n# scored_data %&gt;% select(TIPI_2, TIPI_2r) %&gt;% head()\nQuestion 3: If a participant‚Äôs original score on TIPI_4 was a 6, what would their score be on the new TIPI_4r variable?\n‚ùìYour Answer: [Type your answer here]\n\n\n\nExercise 5: Computing and Finalizing the Scored File\nNow we are ready to compute the final score! There are individual subscales for each of the 5 factors of the Big 5 Personality Inex. Compute the 5 scales. Remember to use the reverse-scored items (TIPI_2r), not the original one.s\n# Task 1: Use mutate() to calculate the total grit score.\n# Sum the items corresponding to each scale.\n# Call the new variables 'extra', 'agree', 'consc', 'emo', 'open.\n# Overwrite your `scored_data` object with this new version.\n\n# Task 2: Create a final, clean dataset.\n# Use select() to keep only the 'id' and Big 5 scale columns.\n# Call this object `final_data`.\n# Conceptual code:\n# final_data &lt;- scored_data %&gt;%\n#   select(id, agree, ...)\n\n\n\n# Task 3: Calculate the mean and standard deviation of each of the subscale scores.\nQuestion 4: What would be the highest possible Emotional Stability score a participant could get? What would be the lowest?\n‚ùìYour Answer: [Type your answer here]\nQuestion 5: Report the mean‚Äôs and standard deviations of each of the subscale scores\n‚ùìYour Answer:\n\nExtraversion:\nAgreeableness:\nConscientiousness:\nEmotional Stability:\nOpenness to Experience:\n\n\n\n\nExercise 6: Visualize Relationships\nWe often want to see the relationship between 2 variables. This is often done using a scatterplot. Select 2 scales that you would like to see the relationship between. Use the code from the previous lab/class to create a scatterplot of the relationship. Take a look at this cheat sheet to help with ggplot2!\n# Using ggplot and the scored data you have, generate a scatterplot. It can be as simple or as fancy as you would like (try putting a title and changing the axis names)\n\n\n\n# Use the cheat sheet and other materials to put a straight line to the data (Hint: add another layer with a smooth geom)\nQuestion 6.1: Visually inspect the chart you have and describe the relationship below. Be sure to include the two variables and an estimate of your correlation in your answer.\n‚ùìYour Answer:\n# Compute a correltion for your variables\n# Hint: use the `cor.test()` function. You will need to specify the variable names as `name_of_data$name_of_variable`\n  \n  # Example\n    # cor.test(starwars$height, starwars$mass)\nQuestion 6.2: Calculate the correlation coefficient for your two variables of interest (refer here for more info). Report the correlation, and reflect on how close or how far away your initial estimate was. Do your best here. I recognize that we haven‚Äôt really gone over this just yet.\n‚ùìYour Answer:\n\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 2 - Wrangling Intro"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html",
    "href": "labs/lab-5_cor.html",
    "title": "Lab 5: Correlations",
    "section": "",
    "text": "We are going to investigate what is most highly related to the number of Spotify streams in this Popular Music dataset. This data was taken from: https://www.kaggle.com/datasets/ahmadrazakashif/spotify-popularity-songs\nHere are the things that you will need for this lab:\n\nDownload Spotify Data (.csv)\nDownload Lab 5 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 5 - Correlation"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html#instructions",
    "href": "labs/lab-5_cor.html#instructions",
    "title": "Lab 5: Correlations",
    "section": "",
    "text": "We are going to investigate what is most highly related to the number of Spotify streams in this Popular Music dataset. This data was taken from: https://www.kaggle.com/datasets/ahmadrazakashif/spotify-popularity-songs\nHere are the things that you will need for this lab:\n\nDownload Spotify Data (.csv)\nDownload Lab 5 (.Rmd)\n\nWhen you are finished, click the Knit button to turn your work into an HTML document. You will submit both this .Rmd file and the üß∂knitted .html file.",
    "crumbs": [
      "Labs",
      "Lab 5 - Correlation"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html#scenario-and-goal",
    "href": "labs/lab-5_cor.html#scenario-and-goal",
    "title": "Lab 5: Correlations",
    "section": "Scenario and Goal",
    "text": "Scenario and Goal\nWe have been asked by an up and coming music artist to use our advanced data analytic skills to see what has been related to the most popular songs. They have provided us with all of this data for recent popular songs that have been streamed the most.\nOur goal is to identify which variable is most related to higher streams. These variables that they are looking at are things like danceability, instrumentalness, etc.\n\nVariables of Interest\n\nstreams: The number of streams for the individual song\nPercentage Variables: These variables reflect a rating from 0-100 on the intensity related to that variable\n\ndanceability_%\nvalence_%\nenergy_%\nacousticness_%\ninstrumentalness_%\nliveness_%\nspeechiness_%",
    "crumbs": [
      "Labs",
      "Lab 5 - Correlation"
    ]
  },
  {
    "objectID": "labs/lab-5_cor.html#lab-exercises",
    "href": "labs/lab-5_cor.html#lab-exercises",
    "title": "Lab 5: Correlations",
    "section": "Lab Exercises",
    "text": "Lab Exercises\nImport your data and use the clean_names() function to make the variables a little nicer looking\nStart by creating a correlation table (make sure it looks nice and not just an output from R using cor()).\nExamine the correlation table and identify the two largest effects with the outcome (streams).\nVisualize the two correlations that you have identified.\nChoose one of the relationships that you visualized and write the results in APA format.\nEnd of Lab. Don‚Äôt forget to Knit! üß∂",
    "crumbs": [
      "Labs",
      "Lab 5 - Correlation"
    ]
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12 - Logistic Regression & More",
    "section": "",
    "text": "Download Cards Against Humanity Data (.csv)\nDownload Categorical data (.xlsx)\n\n\n\n\nüíª Categorical & Logistic Regression\n\n\n\nLego Logistic Regression\n\n\n\nPart 1 of Final Project\nüìãLab 11 - Categories & Regression\nüìñChapter 14.2 & 14.3 - ST\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 12 - Logistic Reg."
    ]
  },
  {
    "objectID": "weeks/week-12.html#data-for-today",
    "href": "weeks/week-12.html#data-for-today",
    "title": "Week 12 - Logistic Regression & More",
    "section": "",
    "text": "Download Cards Against Humanity Data (.csv)\nDownload Categorical data (.xlsx)",
    "crumbs": [
      "Weekly Materials",
      "Week 12 - Logistic Reg."
    ]
  },
  {
    "objectID": "weeks/week-12.html#slides",
    "href": "weeks/week-12.html#slides",
    "title": "Week 12 - Logistic Regression & More",
    "section": "",
    "text": "üíª Categorical & Logistic Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 12 - Logistic Reg."
    ]
  },
  {
    "objectID": "weeks/week-12.html#in-class-activity",
    "href": "weeks/week-12.html#in-class-activity",
    "title": "Week 12 - Logistic Regression & More",
    "section": "",
    "text": "Lego Logistic Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 12 - Logistic Reg."
    ]
  },
  {
    "objectID": "weeks/week-12.html#for-next-time",
    "href": "weeks/week-12.html#for-next-time",
    "title": "Week 12 - Logistic Regression & More",
    "section": "",
    "text": "Part 1 of Final Project\nüìãLab 11 - Categories & Regression\nüìñChapter 14.2 & 14.3 - ST\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 12 - Logistic Reg."
    ]
  },
  {
    "objectID": "weeks/week-9.html",
    "href": "weeks/week-9.html",
    "title": "Week 9 - Model Creation",
    "section": "",
    "text": "We will focus on refamiliarizing ourselves with the process of regression (and maybe a little bit of ANOVA). Activities will include collecting some data, building regression models from the ground up, looking at the LEGO dataset (maybe), and further connecting our research questions to the types of analyses that we are going to be doing.\n\n\n\nDownload LEGO data (.csv)\nStroop Task\nStroop Task Data\n\n\n\n\nüíª Models & Variability\n\n\n\n\nIt‚Äôs in the slides this time\n\n\n\n\nüìãLab 9 - Models & Research Questions\nüìñChapter 15.3 - 15.5 - LSR\nüìñChapter 8 - IMS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#stuff-for-today",
    "href": "weeks/week-9.html#stuff-for-today",
    "title": "Week 9 - Model Creation",
    "section": "",
    "text": "Download LEGO data (.csv)\nStroop Task\nStroop Task Data",
    "crumbs": [
      "Weekly Materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#slides",
    "href": "weeks/week-9.html#slides",
    "title": "Week 9 - Model Creation",
    "section": "",
    "text": "üíª Models & Variability",
    "crumbs": [
      "Weekly Materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#in-class-activity",
    "href": "weeks/week-9.html#in-class-activity",
    "title": "Week 9 - Model Creation",
    "section": "",
    "text": "It‚Äôs in the slides this time",
    "crumbs": [
      "Weekly Materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-9.html#for-next-time",
    "href": "weeks/week-9.html#for-next-time",
    "title": "Week 9 - Model Creation",
    "section": "",
    "text": "üìãLab 9 - Models & Research Questions\nüìñChapter 15.3 - 15.5 - LSR\nüìñChapter 8 - IMS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "üìñChapter 15.3 - 15.5 - LSR\nüìñChapter 8 - IMS\n\n\n\nüíª Multiple Regression\n\n\n\nMany Much Variable Regression\n\n\n\nüìãLab 10 - Multiple Regression\nüìñChapter 9 - IMS\nüìñChapter 8.3 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 10 - Multiple Reg."
    ]
  },
  {
    "objectID": "weeks/week-10.html#prepare",
    "href": "weeks/week-10.html#prepare",
    "title": "Week 10",
    "section": "",
    "text": "üìñChapter 15.3 - 15.5 - LSR\nüìñChapter 8 - IMS",
    "crumbs": [
      "Weekly Materials",
      "Week 10 - Multiple Reg."
    ]
  },
  {
    "objectID": "weeks/week-10.html#slides",
    "href": "weeks/week-10.html#slides",
    "title": "Week 10",
    "section": "",
    "text": "üíª Multiple Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 10 - Multiple Reg."
    ]
  },
  {
    "objectID": "weeks/week-10.html#in-class-activity",
    "href": "weeks/week-10.html#in-class-activity",
    "title": "Week 10",
    "section": "",
    "text": "Many Much Variable Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 10 - Multiple Reg."
    ]
  },
  {
    "objectID": "weeks/week-10.html#for-next-time",
    "href": "weeks/week-10.html#for-next-time",
    "title": "Week 10",
    "section": "",
    "text": "üìãLab 10 - Multiple Regression\nüìñChapter 9 - IMS\nüìñChapter 8.3 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 10 - Multiple Reg."
    ]
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 07 - Regression",
    "section": "",
    "text": "Chapter 14.1.1 - 14.1.4 - ST\nChapter 7.1 - 7.2.4 - IMS\nChapter 8.1.1 & 8.1.2 - MSR\n\n\n\n\nüíª Intro to Regression\n\n\n\nPredicting Stuff with Regression\n\n\n\n\nNO CLASS 10/13/25\nüìãMidterm Project\nüìñRead Chapter 5 & 14- ST\nüìñRead Chapter 7.2.5 - IMS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 7 - Regression"
    ]
  },
  {
    "objectID": "weeks/week-7.html#prepare",
    "href": "weeks/week-7.html#prepare",
    "title": "Week 07 - Regression",
    "section": "",
    "text": "Chapter 14.1.1 - 14.1.4 - ST\nChapter 7.1 - 7.2.4 - IMS\nChapter 8.1.1 & 8.1.2 - MSR",
    "crumbs": [
      "Weekly Materials",
      "Week 7 - Regression"
    ]
  },
  {
    "objectID": "weeks/week-7.html#slides",
    "href": "weeks/week-7.html#slides",
    "title": "Week 07 - Regression",
    "section": "",
    "text": "üíª Intro to Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 7 - Regression"
    ]
  },
  {
    "objectID": "weeks/week-7.html#in-class-activity",
    "href": "weeks/week-7.html#in-class-activity",
    "title": "Week 07 - Regression",
    "section": "",
    "text": "Predicting Stuff with Regression",
    "crumbs": [
      "Weekly Materials",
      "Week 7 - Regression"
    ]
  },
  {
    "objectID": "weeks/week-7.html#for-next-time",
    "href": "weeks/week-7.html#for-next-time",
    "title": "Week 07 - Regression",
    "section": "",
    "text": "NO CLASS 10/13/25\nüìãMidterm Project\nüìñRead Chapter 5 & 14- ST\nüìñRead Chapter 7.2.5 - IMS\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 7 - Regression"
    ]
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to the course! I am very excited to get to work with you this semester on our journey into statistics. During our first class, we will review the syllabus and the plan for the course, followed by walking through the structure of each of the classes.\nWe‚Äôll then dive right into our primary tool, R. This session will go over installing R and RStudio, navigating the interface, understanding R projects, and learning the foundational syntax of the R language and the tidyverse, including data types and basic functions.\n\n\n\nInstall R and R-Studio (https://posit.co/download/rstudio-desktop/)\nBring Laptop\n\n\n\n\nüíª Getting Started - Syllabus\nüíªGetting Started - Data\n\n\n\nGetting Comfy with R\n\n\n\nüìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "",
    "text": "Install R and R-Studio (https://posit.co/download/rstudio-desktop/)\nBring Laptop",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#slides",
    "href": "weeks/week-1.html#slides",
    "title": "Week 1",
    "section": "",
    "text": "üíª Getting Started - Syllabus\nüíªGetting Started - Data",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#in-class-activity",
    "href": "weeks/week-1.html#in-class-activity",
    "title": "Week 1",
    "section": "",
    "text": "Getting Comfy with R",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-1.html#for-next-time",
    "href": "weeks/week-1.html#for-next-time",
    "title": "Week 1",
    "section": "",
    "text": "üìãLab 1 - Foundations of a Data Workflow\nüìñRead Chapter 1 & 2 - ST\nüìñRead Chapter 2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 1 - Getting Comfy w/ R"
    ]
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 06",
    "section": "",
    "text": "Cards Against Humanity Data (.csv)\nWeek 6 Class Activity Data (.csv)\n\n\n\n\n\nChapter 9 & 10 - ST\nChapter 13 - LSR\n\n\n\n\nüíª Comparing Means\n\n\n\nWalk along comparing means\n\n\n\nüìãLab 6 - Still Comparing Means\nüìñChapter 14.1.1 - 14.1.4 - ST\nüìñChapter 7.1 - 7.2.4 - IMS\nüìñChapter 8.1.1 & 8.1.2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#materialsdata",
    "href": "weeks/week-6.html#materialsdata",
    "title": "Week 06",
    "section": "",
    "text": "Cards Against Humanity Data (.csv)\nWeek 6 Class Activity Data (.csv)",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#prepare",
    "href": "weeks/week-6.html#prepare",
    "title": "Week 06",
    "section": "",
    "text": "Chapter 9 & 10 - ST\nChapter 13 - LSR",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#slides",
    "href": "weeks/week-6.html#slides",
    "title": "Week 06",
    "section": "",
    "text": "üíª Comparing Means",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#in-class-activity",
    "href": "weeks/week-6.html#in-class-activity",
    "title": "Week 06",
    "section": "",
    "text": "Walk along comparing means",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "weeks/week-6.html#for-next-time",
    "href": "weeks/week-6.html#for-next-time",
    "title": "Week 06",
    "section": "",
    "text": "üìãLab 6 - Still Comparing Means\nüìñChapter 14.1.1 - 14.1.4 - ST\nüìñChapter 7.1 - 7.2.4 - IMS\nüìñChapter 8.1.1 & 8.1.2 - MSR\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Weekly Materials",
      "Week 6 - Comparing"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 640: Graduate Statistics",
    "section": "",
    "text": "This page contains an outline of the topics, content, and preparation for the semester. This schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\nImportant\n\n\n\nReadings on the schedule will need to be completed prior to the course they are listed for. We will build on the concepts you read about in that specific class period, so it is important that you have read.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nPrepare\nSlides\nLabs\n\n\n\n\n1\n08-25\nGetting set up + R foundations\nInstall R/RStudio; Bring a laptop\nüíª Getting Started - Syllabus\nüíªGetting Started - Data\nLab 1 - Intro to Data Workflow\n\n\n2\n09-01\nLABOR DAY\nChapter 1 & 2 - ST\nChapter 2 - MSR\nLABOR DAY\nLab 2 - Data Wrangling\n\n\n3\n09-08\nDescriptives, Visualizations + Communication\nChapter 5 - LSR\nChapter 1 & 3 - R4DS\nüíª Data Wrangling\nüíª Describe & Visualize\nLab 3\n\n\n4\n09-15\nDesign, Sampling + Inference\nChapter 2 - IMS\nChapter 3 - MSR\nChapter 7 - ST\nüíª Design & Inference\nLab 4 - Intro to Inference\nStatistical Check\n\n\n5\n09-22\nCorrelation + Effect Sizes\nChapter 5.1 & 13 - ST\nChapter 11 - LSR\nüíª Correlation & ES\nLab 5 - Correlation & ES\n\n\n6\n09-29\nComparing Groups\nChapter 9 & 10 - ST\nChapter 13 - LSR\nüíªComparing Means\nLab 6 - Compare Means\n\n\n7\n10-06\nSimple Linear Regression\nChapter 14.1.1 - 14.1.4 - ST\nChapter 7.1 - 7.2.4 - IMS\nChapter 8.1.1 & 8.1.2 - MSR\nüíªIntro to Regression\nMIDTERM PROJECT\n\n\n8\n10-13\nFALL BREAK\nWork on your midterm project\n\n\n\n\n9\n10-20\nVariability & Model Fit\nChapter 5 & 14- ST\nChapter 7.2.5 - IMS\nüíª Models & Variability\nLab 9 - Models & Research Questions\n\n\n10\n10-27\nMultiple Regression I: Adding Predictors\nChapter 15.3 - 15.5 - LSR\nChapter 8 - IMS\nüíª Multiple Regression\nLab 10 - Multiple Regression\n\n\n11\n11-03\nMultiple Regression II: Categorical Predictors\nChapter 9 - IMS\nChapter 8.3 - MSR\nüíª Regression with Categories\nLab 11 - Categories & Regression\n\n\n12\n11-10\nAssumptions + Model Diagnostics\nChapter 7.3 - IMS\nChapter 14.5 - ST\nChapter 8.1.4 - MSR\nChapter 15.8 - LSR\nüíªCategories,Logistic & Diagnostic\nLab 12\nFinal Project Part 1\n\n\n13\n11-17\nExpanding Regression\nChapter 14.2 & 14.3 - ST\nüíª Moderation\n\n\n\n14\n11-24\nModel Building + Comparison\nChapter 15.8 - 15.10 - LSR\n\n\n\n\n15\n12-01\nMaking R Work for You\nChapter 17 & 18 - ST\n\n\n\n\n16\n12-08\nWrapping Up + Workshop\n\n\n\n\n\n\n\nIntroduction to Modern Statistics (2e) ‚Äì&gt; IMS\nLearning Statistics with R ‚Äì&gt; LSR\nR for Data Science (2e) ‚Äì&gt; R4DS\nModern Statistics with R (2e) ‚Äì&gt; MSR\nStatistical Thinking ‚Äì&gt; ST\nAn Introduction to Statistical Learning (2e) ‚Äì&gt; ISL\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) ‚Äì&gt; DA",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "resources/startingwithR.html",
    "href": "resources/startingwithR.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "To get started with using the statistical software, we first must install it! Here is a guide that was put together to help with the installation process. Throughout this guide, you will install R followed by R-Studio (a program to make R more user friendly).¬†\nWe will go over this during the first day of class, so this guide is just to use as reference.¬†\nThings needed:\n\nComputer\nInternet Connection\nA coffee or preferred beverage usually helps!\n\n\n\nInformation taken from ‚ÄúHands-On Programming with R‚Äù\nR is maintained by an international team of developers who make the language available through the web page ofThe Comprehensive R Archive Network. The top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows or Mac.\n\n\nTo install R on Windows, click the ‚ÄúDownload R for Windows‚Äù link.Then click the ‚Äúbase‚Äù link. Next, click the first link at the top of the new page. This link should say something like ‚ÄúDownload R 4.3.1 for Windows,‚Äù except the 4.3.1 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you‚Äôll need to have all of the appropriate administration privileges to install new software on your machine.\n\n\n\nTo install R on a Mac, click the ‚ÄúDownload R for Mac‚Äô‚Äô link. Next, click on the ‚ÄúR-4.3.1-arm64.pkg‚Äù package link (or the package link for the most current release of R that is appropriate for your computer). An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I‚Äôve never found a reason to change them. If your computer requires a password before installing new programs, you‚Äôll need it here.\n\n\n\n\nR isn‚Äôt a program that you can open and start using, like Microsoft Word or Internet Explorer. Instead, R is a computer language, like C, C++, or UNIX. You use R by writing commands in the R language and asking your computer to interpret them. In the old days, people ran R code in a UNIX terminal window‚Äîas if they were hackers in a movie from the 1980s. Now almost everyone uses R with an application called RStudio, and I recommend that you do, too.\nGo ahead and try to open R without using R-Studio. You will get something like this:"
  },
  {
    "objectID": "resources/startingwithR.html#installing-r-r-studio",
    "href": "resources/startingwithR.html#installing-r-r-studio",
    "title": "Getting Started with R",
    "section": "",
    "text": "To get started with using the statistical software, we first must install it! Here is a guide that was put together to help with the installation process. Throughout this guide, you will install R followed by R-Studio (a program to make R more user friendly).¬†\nWe will go over this during the first day of class, so this guide is just to use as reference.¬†\nThings needed:\n\nComputer\nInternet Connection\nA coffee or preferred beverage usually helps!\n\n\n\nInformation taken from ‚ÄúHands-On Programming with R‚Äù\nR is maintained by an international team of developers who make the language available through the web page ofThe Comprehensive R Archive Network. The top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows or Mac.\n\n\nTo install R on Windows, click the ‚ÄúDownload R for Windows‚Äù link.Then click the ‚Äúbase‚Äù link. Next, click the first link at the top of the new page. This link should say something like ‚ÄúDownload R 4.3.1 for Windows,‚Äù except the 4.3.1 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you‚Äôll need to have all of the appropriate administration privileges to install new software on your machine.\n\n\n\nTo install R on a Mac, click the ‚ÄúDownload R for Mac‚Äô‚Äô link. Next, click on the ‚ÄúR-4.3.1-arm64.pkg‚Äù package link (or the package link for the most current release of R that is appropriate for your computer). An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I‚Äôve never found a reason to change them. If your computer requires a password before installing new programs, you‚Äôll need it here.\n\n\n\n\nR isn‚Äôt a program that you can open and start using, like Microsoft Word or Internet Explorer. Instead, R is a computer language, like C, C++, or UNIX. You use R by writing commands in the R language and asking your computer to interpret them. In the old days, people ran R code in a UNIX terminal window‚Äîas if they were hackers in a movie from the 1980s. Now almost everyone uses R with an application called RStudio, and I recommend that you do, too.\nGo ahead and try to open R without using R-Studio. You will get something like this:"
  },
  {
    "objectID": "resources/startingwithR.html#r-studio-download-and-install",
    "href": "resources/startingwithR.html#r-studio-download-and-install",
    "title": "Getting Started with R",
    "section": "R-Studio: Download and Install",
    "text": "R-Studio: Download and Install\nRStudio is an application like Microsoft Word‚Äîexcept that instead of helping you write in English, RStudio helps you write in R. We will use RStudio throughout because it makes working with R SO much easier. Plus there are a lot of additional functionalities that RStudio has that will expand what you can do (e.g., RMarkdown). Also, the RStudio interface looks the same for the various operating systems which will make teaching and your experience with the material a lot easier.\nRStudio (the company) has recently changed their name to Posit. To download RStudio, you can navigate to the Posit download page for ‚ÄúRStudio Desktop‚Äù. We have already completed Step 1 (you could have just come here to download it, but it is helpful to know where to get the latest versions and materials)! All you have to do is select the box under ‚Äú2: Install RStudio‚Äù to download. It should recognize the operating system that you are using, but if it does not, you will just need to scroll down the page to identify the appropriate installer.\nNow you are all set and ready to go! Nice job following the instructions and getting R and RStudio on your computer. Next you can begin to customize and get used to using RStudio. Remember, this is not something that is scary or a thing you can ‚Äúbreak‚Äù. When in doubt, check out Google or reach out to the professor!"
  },
  {
    "objectID": "resources/startingwithR.html#setting-things-up",
    "href": "resources/startingwithR.html#setting-things-up",
    "title": "Getting Started with R",
    "section": "Setting things up",
    "text": "Setting things up\nHere are some things that I am going to suggest to make your experience with R as good as we possibly can. Some of the suggestions here are related to your workflow while others are direct settings within R‚Ä¶and some are both. We are all complex creatures.¬†\nA lot of my suggestions will come from ‚ÄúWhat They Forgot to Teach You About R‚Äù. As I use other sites or things, I will do my best to have links to the original.\nThis list will continue to develop and expand. It is a work in progress (just like most of us)\n\nStart R with a blank slate each time Link\nNavigate to Tools &gt; Global Options\nBy default, R Studio saves all of the objects in your environment. In general, this is not ideal, because it means that you may have taken steps interactively that are not documented in your code.\n\nThis would be like when you are baking, and you follow the recipe, but then you add in some cinnamon and nutmeg which the recipe doesn‚Äôt call for. You also measure out some extra chocolate chips and brown sugar, but you end up not using that. The cookies come out fantastic and you want to make them again. You open up your kitchen and the cinnamon, nutmeg, chocolate chips and brown sugar are all there, but nothing says that you need them in your recipe. We don‚Äôt want to keep all the old information. We only want what is in the recipe (after we update it to include the extra spices).\n\n\nDecorate\nNavigate to Tools &gt; Global Options &gt; Appearance\nThis is all yours! Take ownership and find a cool theme that you like. Make it look nice and how you want it.\n\nRight now I am rocking the ‚ÄúChaos‚Äù theme with my fonts a little larger because apparently I am getting older."
  },
  {
    "objectID": "slides/lec-6_mean.html#today",
    "href": "slides/lec-6_mean.html#today",
    "title": "Week 06: Comparing Means",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nHIGHLIGHT THE USE OF THE rm() FUNCTION TO GET RID OF THINGS IN YOUR ENVIRONMENT\n\n# File management\nlibrary(here)\n# for dplyr, ggplot2\nlibrary(tidyverse)\n# Pretty tables\nlibrary(sjPlot)\nlibrary(ggstatsplot)\n# making tests easier\nlibrary(lsr) ## NEW\n# Getting marginal means\nlibrary(emmeans)\n\n#Remove Scientific Notation \noptions(scipen=999)"
  },
  {
    "objectID": "slides/lec-6_mean.html#but-firstdegrees-of-freedom",
    "href": "slides/lec-6_mean.html#but-firstdegrees-of-freedom",
    "title": "Week 06: Comparing Means",
    "section": "but first‚Ä¶Degrees of Freedom",
    "text": "but first‚Ä¶Degrees of Freedom\nDegrees of Freedom: the number of values in the final calculation of a statistic that are free to vary\nExample: Drawing a triangle\n‚ùìQuestion: If you have a sample of 5 scores and you know the mean is 3, how many of those scores can you freely change?"
  },
  {
    "objectID": "slides/lec-6_mean.html#one-sample-t-test",
    "href": "slides/lec-6_mean.html#one-sample-t-test",
    "title": "Week 06: Comparing Means",
    "section": "One Sample t-test",
    "text": "One Sample t-test\nt-tests were developed by William Sealy Gosset, who was a chemist studying the grains used in making beer. (He worked for Guinness.)\n\nSpecifically, he wanted to know whether particular strains of grain made better or worse beer than the standard.\nHe developed the t-test, to test small samples of beer against a population with an unknown standard deviation.\n\nProbably had input from Karl Pearson and Ronald Fisher\n\nPublished this as ‚ÄúStudent‚Äù because Guinness didn‚Äôt want these tests tied to the production of beer."
  },
  {
    "objectID": "slides/lec-6_mean.html#example",
    "href": "slides/lec-6_mean.html#example",
    "title": "Week 06: Comparing Means",
    "section": "Example",
    "text": "Example\nFor examples today, we will use a dataset from Cards Against Humanity‚Äôs Pulse of the Nation survey (https://thepulseofthenation.com/)\n\nCards Against Humanity Data (.csv)\n\n\n## We are using read_csv() this time\n## import() was doing something strange with missing values\ncah &lt;- read_csv(here(\"files\", \"data\", \"CAH.csv\")) %&gt;% \n  janitor::clean_names() \n\nhead(cah)\n\n# A tibble: 6 √ó 16\n     id income gender   age age_range political_affiliation education  ethnicity\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;      &lt;chr&gt;    \n1     1   8000 Female    64 55-64     Democrat              College d‚Ä¶ White    \n2     2  68000 Female    56 55-64     Democrat              High scho‚Ä¶ Black    \n3     3  46000 Male      63 55-64     Independent           Some coll‚Ä¶ White    \n4     4  51000 Male      48 45-54     Republican            High scho‚Ä¶ White    \n5     5 100000 Female    32 25-34     Democrat              Some coll‚Ä¶ White    \n6     6  54000 Female    64 55-64     Democrat              Some coll‚Ä¶ White    \n# ‚Ñπ 8 more variables: marital_status &lt;chr&gt;, climate_change &lt;chr&gt;,\n#   transformers &lt;dbl&gt;, books &lt;dbl&gt;, ghosts &lt;chr&gt;, spending &lt;chr&gt;,\n#   choice &lt;chr&gt;, shower_pee &lt;chr&gt;"
  },
  {
    "objectID": "slides/lec-6_mean.html#cohens-d",
    "href": "slides/lec-6_mean.html#cohens-d",
    "title": "Week 06: Comparing Means",
    "section": "Cohen‚Äôs D",
    "text": "Cohen‚Äôs D\nCohen suggested one of the most common effect size estimates‚Äîthe standardized mean difference‚Äîuseful when comparing a group mean to a population mean or two group means to each other.\n\\[\\delta = \\frac{\\mu_1 - \\mu_0}{\\sigma} \\approx d = \\frac{\\bar{X}-\\mu}{\\hat{\\sigma}}\\]\nCohen‚Äôs d is in the standard deviation (Z) metric."
  },
  {
    "objectID": "slides/lec-6_mean.html#students-t-test",
    "href": "slides/lec-6_mean.html#students-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Student‚Äôs t-test",
    "text": "Student‚Äôs t-test\n\\[ H_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2 \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#welchs-t-test",
    "href": "slides/lec-6_mean.html#welchs-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Welch‚Äôs t-test",
    "text": "Welch‚Äôs t-test\n\\[ H_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2 \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#cool-visualizations",
    "href": "slides/lec-6_mean.html#cool-visualizations",
    "title": "Week 06: Comparing Means",
    "section": "Cool Visualizations",
    "text": "Cool Visualizations\nThe library ggstatsplot has some wonderful visualizations of various tests\n\n\nCode\nggstatsplot::ggbetweenstats(   \n  data  = cah,   \n  x     = ghosts,   \n  y     = books,   \n  title = \"Distribution of books by belief in ghosts\" )"
  },
  {
    "objectID": "slides/lec-6_mean.html#paired-samples-t-test",
    "href": "slides/lec-6_mean.html#paired-samples-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Paired Samples \\(t\\)-Test",
    "text": "Paired Samples \\(t\\)-Test\nChapter 13.5 - Learning Stats with R\nAlso called ‚ÄúDependent Samples t-test‚Äù\n\nWe have been testing means between two independent samples. Participants may be randomly assigned to the separate groups\n\nThis is limited to those types of study designs, but what if we have repeated measures?\n\nWe will then need to compare scores across people‚Ä¶the samples we are comparing now depend on one another and are paired"
  },
  {
    "objectID": "slides/lec-6_mean.html#review-of-the-t-test-process",
    "href": "slides/lec-6_mean.html#review-of-the-t-test-process",
    "title": "Week 06: Comparing Means",
    "section": "Review of the t-test process",
    "text": "Review of the t-test process\n\nCollect Sample and define hypotheses\nSet alpha level\nDetermine the sampling distribution (\\(t\\) distribution for now)\nIdentify the critical value that corresponds to alpha and df\nCalculate test statistic for sample collected\nInspect & compare statistic to critical value; Calculate probability"
  },
  {
    "objectID": "slides/lec-6_mean.html#determining-t-crit",
    "href": "slides/lec-6_mean.html#determining-t-crit",
    "title": "Week 06: Comparing Means",
    "section": "Determining \\(t\\)-crit",
    "text": "Determining \\(t\\)-crit\nCan look things up using a t-table where you need the degrees of freedom and the alpha\nBut we have R to do those things for us:\n\n#the qt() function is for a 1 tailed test, so we are having to divide it in half to get both tails \n\nalpha &lt;- 0.05 \nn &lt;- nrow(ex1) \nt_crit &lt;- qt(alpha/2, n-1) \nt_crit\n\n[1] -2.570582"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-t",
    "href": "slides/lec-6_mean.html#calculating-t",
    "title": "Week 06: Comparing Means",
    "section": "Calculating t",
    "text": "Calculating t\nLet‚Äôs get all of the information for the sample we are focusing on (difference scores):\n\nd &lt;- mean(ex1$diff_score) \nd \n\n[1] -1.166667\n\nsd_diff &lt;- sd(ex1$diff_score) \nsd_diff\n\n[1] 4.167333"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-t-1",
    "href": "slides/lec-6_mean.html#calculating-t-1",
    "title": "Week 06: Comparing Means",
    "section": "Calculating t",
    "text": "Calculating t\nNow we can calculate our \\(t\\)-statistic: \\[t_{df=n-1} = \\frac{\\bar{D}}{\\frac{sd_{diff}}{\\sqrt{n}}}\\]\n\nt_stat &lt;- d/(sd_diff/(sqrt(n))) \nt_stat  \n\n[1] -0.6857474\n\n#Probability of this t-statistic  \np_val &lt;- pt(t_stat, n-1)*2 \np_val\n\n[1] 0.5233677"
  },
  {
    "objectID": "slides/lec-6_mean.html#make-a-decision",
    "href": "slides/lec-6_mean.html#make-a-decision",
    "title": "Week 06: Comparing Means",
    "section": "Make a decision",
    "text": "Make a decision\nHypotheses:\n\n\\(H_0:\\) There is no difference in ratings of happiness between the rooms ( \\(\\mu = 0\\) )\n\\(H_1:\\) There is a difference in ratings of happiness between the rooms ( \\(\\mu \\neq 0\\) )\n\n\n\n\n\n\n\n\n\n\n\\(alpha\\)\n\\(t-crit\\)\n\\(t-statistic\\)\n\\(p-value\\)\n\n\n\n\n0.05\n\\(\\pm\\) -2.57\n-0.69\n0.52\n\n\n\nWhat can we conclude??"
  },
  {
    "objectID": "slides/lec-6_mean.html#lets-look-at-the-data",
    "href": "slides/lec-6_mean.html#lets-look-at-the-data",
    "title": "Week 06: Comparing Means",
    "section": "Let‚Äôs Look at the data",
    "text": "Let‚Äôs Look at the data\nResearch Question: Is there a difference between school nights and weekend nights for amount of time slept?\nOnly looking at the variables that we are potentially interested in:\n\nstate_school %&gt;%    \n  select(id, Gender, Ageyears, Sleep_Hours_Schoolnight, Sleep_Hours_Non_Schoolnight) %&gt;%    \n  head() #look at first few observations\n\n# A tibble: 6 √ó 5\n     id Gender Ageyears Sleep_Hours_Schoolnight Sleep_Hours_Non_Schoolnight\n  &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;                   &lt;dbl&gt;                       &lt;dbl&gt;\n1     1 Female       16                     8                            13\n2     2 Male         17                     8                             9\n3     3 Female       19                     8                             7\n4     4 Male         17                     8                             9\n5     5 Male         16                     8.5                           5\n6     6 Female       11                    11                            12"
  },
  {
    "objectID": "slides/lec-6_mean.html#doing-the-test-in-r-one-sample",
    "href": "slides/lec-6_mean.html#doing-the-test-in-r-one-sample",
    "title": "Week 06: Comparing Means",
    "section": "Doing the test in R: One Sample",
    "text": "Doing the test in R: One Sample\nSince we have calculated the difference scores, we can basically just do a one-sample t-test with the lsr library\n\noneSampleTTest(sleep_state_school$sleep_diff, mu = 0)\n\n\n   One sample t-test \n\nData variable:   sleep_state_school$sleep_diff \n\nDescriptive statistics: \n            sleep_diff\n   mean         -1.866\n   std dev.      2.741\n\nHypotheses: \n   null:        population mean equals 0 \n   alternative: population mean not equal to 0 \n\nTest results: \n   t-statistic:  -9.106 \n   degrees of freedom:  178 \n   p-value:  &lt;.001 \n\nOther information: \n   two-sided 95% confidence interval:  [-2.27, -1.462] \n   estimated effect size (Cohen's d):  0.681"
  },
  {
    "objectID": "slides/lec-6_mean.html#doing-the-test-in-r-paired-sample",
    "href": "slides/lec-6_mean.html#doing-the-test-in-r-paired-sample",
    "title": "Week 06: Comparing Means",
    "section": "Doing the test in R: Paired Sample",
    "text": "Doing the test in R: Paired Sample\nMaybe we want to keep things separate and don‚Äôt want to calculate separate values. We can use pairedSamplesTTest() instead!\nBut this isn‚Äôt working and is making me mad‚Ä¶\n\nlsr::pairedSamplesTTest(\n  formula = ~ Sleep_Hours_Schoolnight + Sleep_Hours_Non_Schoolnight,\n  data = sleep_state_school\n)"
  },
  {
    "objectID": "slides/lec-6_mean.html#doing-the-test-in-r-classic-edition",
    "href": "slides/lec-6_mean.html#doing-the-test-in-r-classic-edition",
    "title": "Week 06: Comparing Means",
    "section": "Doing the test in R: Classic Edition",
    "text": "Doing the test in R: Classic Edition\nAs you Google around to figure things out, you will likely see folks using t.test()\n\nt.test(x = sleep_state_school$Sleep_Hours_Schoolnight,    \n       y = sleep_state_school$Sleep_Hours_Non_Schoolnight,\n       paired = TRUE )\n\n\n    Paired t-test\n\ndata:  sleep_state_school$Sleep_Hours_Schoolnight and sleep_state_school$Sleep_Hours_Non_Schoolnight\nt = -9.1062, df = 178, p-value &lt; 0.00000000000000022\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.270281 -1.461563\nsample estimates:\nmean difference \n      -1.865922"
  },
  {
    "objectID": "slides/lec-6_mean.html#reporting-t-test",
    "href": "slides/lec-6_mean.html#reporting-t-test",
    "title": "Week 06: Comparing Means",
    "section": "Reporting \\(t\\)-test",
    "text": "Reporting \\(t\\)-test\nThe first sentence usually conveys some descriptive information about the sample you were comparing (e.g., pre & post test).\nThen you identify the type of test you conducted and what was determined (be sure to include the ‚Äústat block‚Äù here as well with the t-statistic, df, p-value, CI and Effect size).\nFinish it up by putting that into person words and saying what that means."
  },
  {
    "objectID": "slides/lec-6_mean.html#what-is-anova-lsr-ch.-14",
    "href": "slides/lec-6_mean.html#what-is-anova-lsr-ch.-14",
    "title": "Week 06: Comparing Means",
    "section": "What is ANOVA? (LSR Ch. 14)",
    "text": "What is ANOVA? (LSR Ch. 14)\n\nANOVA stands for Analysis of Variance\nComparing means between two or more groups (usually 3 or more)\n\nContinuous outcome and grouping variable with 2 or more levels\n\nUnder the larger umbrella of general linear models\n\nANOVA is basically a regression with only categorical predictors\n\nLikely the most widely used tool in Psychology"
  },
  {
    "objectID": "slides/lec-6_mean.html#different-types-of-anova",
    "href": "slides/lec-6_mean.html#different-types-of-anova",
    "title": "Week 06: Comparing Means",
    "section": "Different Types of ANOVA",
    "text": "Different Types of ANOVA\n\n\nOne-Way ANOVA\n\nTwo-Way ANOVA\nRepeated Measures ANOVA\nANCOVA\nMANOVA"
  },
  {
    "objectID": "slides/lec-6_mean.html#one-way-anova",
    "href": "slides/lec-6_mean.html#one-way-anova",
    "title": "Week 06: Comparing Means",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\nGoal: Inform of differences among the levels of our variable of interest (Omnibus Test)\n\nBut cannot tell us more than that‚Ä¶\n\nHypotheses:\n\\[ H_0: it\\: is\\: true\\: that\\: \\mu_1 = \\mu_2 = \\mu_3 =\\: ...\\mu_k  \\\\  H_1: it\\: is\\: \\boldsymbol{not}\\: true\\: that\\: \\mu_1 = \\mu_2 = \\mu_3 =\\: ...\\mu_k \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#waitmeans-or-variance",
    "href": "slides/lec-6_mean.html#waitmeans-or-variance",
    "title": "Week 06: Comparing Means",
    "section": "Wait‚Ä¶Means or Variance?",
    "text": "Wait‚Ä¶Means or Variance?\nWe are using the variance to create a ratio (within group versus between group variance) to determine differences in means\n\nWe are not directly investigating variance, but operationalize variance to create the ratio:\n\n\\[ F_{df_b, \\: df_w} = \\frac{MS_{between}}{MS_{within}} \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#anova-assumptions",
    "href": "slides/lec-6_mean.html#anova-assumptions",
    "title": "Week 06: Comparing Means",
    "section": "ANOVA: Assumptions",
    "text": "ANOVA: Assumptions\n\nIndependence\n\nObservations between and within groups should be independent. No autocorrelation\n\nHomogeneity of Variance\n\nThe variances within each group should be roughly equal\n\nLevene‚Äôs test ‚Äì&gt; Welch‚Äôs ANOVA for unequal variances\n\n\nNormality\n\nThe data within each group should follow a normal distribution\n\nShapiro-Wilk test ‚Äì&gt; can transform the data or use non-parametric tests"
  },
  {
    "objectID": "slides/lec-6_mean.html#review-of-the-nhst-process",
    "href": "slides/lec-6_mean.html#review-of-the-nhst-process",
    "title": "Week 06: Comparing Means",
    "section": "Review of the NHST process",
    "text": "Review of the NHST process\n\nCollect Sample and define hypotheses\nSet alpha level\nDetermine the sampling distribution (will be using \\(F\\)-distribution now)\nIdentify the critical value\nCalculate test statistic for sample collected\nInspect & compare statistic to critical value; Calculate probability"
  },
  {
    "objectID": "slides/lec-6_mean.html#steps-to-calculating-f-ratio",
    "href": "slides/lec-6_mean.html#steps-to-calculating-f-ratio",
    "title": "Week 06: Comparing Means",
    "section": "Steps to calculating F-ratio",
    "text": "Steps to calculating F-ratio\n\nCapture variance both between and within groups\nVariance to Sum of Squares\nDegrees of Freedom\nMean squares values\nF-Statistic"
  },
  {
    "objectID": "slides/lec-6_mean.html#capturing-variance",
    "href": "slides/lec-6_mean.html#capturing-variance",
    "title": "Week 06: Comparing Means",
    "section": "Capturing Variance",
    "text": "Capturing Variance\nWe have calculated variance before!\n\\[ Var = \\frac{1}{N}\\sum(x_i - \\bar{x})^2 \\]\nNow we have to take into account the variance between and within the groups:\n\\[ Var(Y) = \\frac{1}{N} \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y})^2 \\]\n\nNotice that we have the summation across each group ( \\(G\\) ) and the person in the group ( \\(N_k\\) )"
  },
  {
    "objectID": "slides/lec-6_mean.html#variance-to-sum-of-squares",
    "href": "slides/lec-6_mean.html#variance-to-sum-of-squares",
    "title": "Week 06: Comparing Means",
    "section": "Variance to Sum of Squares",
    "text": "Variance to Sum of Squares\nTotal Sum of Squares - Adding up the sum of squares instead of getting the average (notice the removal of \\(\\frac{1}{N}\\))\n\\[ SS_{total} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y})^2 \\]\nCan be broken up to see what is the variation between the groups AND the variation within the groups\n\\[ SS_{total}=SS_{between}+SS_{within} \\]\n\nThis gets us closer to understanding the difference between means"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---between",
    "href": "slides/lec-6_mean.html#sum-of-squares---between",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Between",
    "text": "Sum of Squares - Between\nThe difference between the group mean and grand mean\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 \\]\n\n\n\nGroup\nGroup Mean \\(\\bar{Y_k}\\)\nGrand Mean \\(\\bar{Y}\\)\n\n\n\n\nCool\n32\n41.8\n\n\nUncool\n56.5\n41.8"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---between-1",
    "href": "slides/lec-6_mean.html#sum-of-squares---between-1",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Between",
    "text": "Sum of Squares - Between\nThe difference between the group mean and grand mean\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 \\]\n\n\n\n\n\n\n\n\n\n\n\nGroup\nGroup Mean \\(\\bar{Y_k}\\)\nGrand Mean \\(\\bar{Y}\\)\nSq. Dev.\nN\nWeighted Sq. Dev.\n\n\n\n\nCool\n32\n41.8\n96.04\n3\n288.12\n\n\nUncool\n56.5\n41.8\n216.09\n2\n432.18"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---between-2",
    "href": "slides/lec-6_mean.html#sum-of-squares---between-2",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Between",
    "text": "Sum of Squares - Between\nThe difference between the group mean and grand mean\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 \\]\nNow we can sum the Weighted Squared Deviations together to get our Sum of Squares Between:\n\nssb &lt;- 288.12 + 432.18 \nssb\n\n[1] 720.3"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---within",
    "href": "slides/lec-6_mean.html#sum-of-squares---within",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Within",
    "text": "Sum of Squares - Within\nThe difference between the individual and their group mean\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 \\]\n\n\n\nName\nGrumpiness \\(Y_{ik}\\)\nGroup Mean \\(\\bar{Y_K}\\)\n\n\n\n\nFrodo\n20\n32\n\n\nSam\n55\n32\n\n\nBandit\n21\n32\n\n\nDolores U.\n91\n56.5\n\n\nDustin\n22\n56.5"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---within-1",
    "href": "slides/lec-6_mean.html#sum-of-squares---within-1",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Within",
    "text": "Sum of Squares - Within\nThe difference between the individual and their group mean\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 \\]\n\n\n\nName\nGrumpiness \\(Y_{ik}\\)\nGroup Mean \\(\\bar{Y_K}\\)\nSq. Dev\n\n\n\n\nFrodo\n20\n32\n144\n\n\nSam\n55\n32\n529\n\n\nBandit\n21\n32\n121\n\n\nDolores U.\n91\n56.5\n1190.25\n\n\nDustin\n22\n56.5\n1190.25\n\n\n\n\n\nCode\nscore &lt;- c(20, 55, 21, 91, 22) \ngroup_m &lt;- c(32, 32, 32, 56.5, 56.5) \nsq_dev &lt;- (score - group_m)^2"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares---within-2",
    "href": "slides/lec-6_mean.html#sum-of-squares---within-2",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares - Within",
    "text": "Sum of Squares - Within\nThe difference between the individual and their group mean\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 \\] Now we can sum the Squared Deviations together to get our Sum of Squares Within:\n\nsum(sq_dev)\n\n[1] 3174.5"
  },
  {
    "objectID": "slides/lec-6_mean.html#sum-of-squares-2",
    "href": "slides/lec-6_mean.html#sum-of-squares-2",
    "title": "Week 06: Comparing Means",
    "section": "Sum of Squares",
    "text": "Sum of Squares\nCan start to have an idea of what this looks like\n\\[ SS_{between} = \\sum^G_{k=1}N_k(\\bar{Y_k} - \\bar{Y})^2 = 720.3 \\]\n\\[ SS_{within} = \\sum^G_{k=1}\\sum^{N_k}_{i=i}(Y_{ik} - \\bar{Y_k})^2 = 3174.5 \\]\nNext we have to take into account the degrees of freedom"
  },
  {
    "objectID": "slides/lec-6_mean.html#degrees-of-freedom",
    "href": "slides/lec-6_mean.html#degrees-of-freedom",
    "title": "Week 06: Comparing Means",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nSince we have 2 types of variations that we are examining, this needs to be reflected in the degrees of freedom\n\nTake the number of groups and subtract 1\n\\(df_{between} = G - 1\\)\nTake the total number of observations and subtract the number of groups\n\\(df_{within} = N - G\\)"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-mean-squares",
    "href": "slides/lec-6_mean.html#calculating-mean-squares",
    "title": "Week 06: Comparing Means",
    "section": "Calculating Mean Squares",
    "text": "Calculating Mean Squares\nNext we convert our summed squares value into a ‚Äúmean squares‚Äù\nThis is done by dividing by the respective degrees of freedom\n\\[ MS_b = \\frac{SS_b}{df_b} \\]\n\\[ MS_W = \\frac{SS_w}{df_w} \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-mean-squares---example",
    "href": "slides/lec-6_mean.html#calculating-mean-squares---example",
    "title": "Week 06: Comparing Means",
    "section": "Calculating Mean Squares - Example",
    "text": "Calculating Mean Squares - Example\nLet‚Äôs take a look at how this applies to our example: \\[ MS_b = \\frac{SS_b}{G-1} = \\frac{720.3}{2-1} = 720.3 \\]\n\\[ MS_W = \\frac{SS_w}{N-G} = \\frac{3174.5}{5-2} = 1058.167  \\]"
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-the-f-statistic",
    "href": "slides/lec-6_mean.html#calculating-the-f-statistic",
    "title": "Week 06: Comparing Means",
    "section": "Calculating the F-Statistic",
    "text": "Calculating the F-Statistic\n\\[F = \\frac{MS_b}{MS_w}\\]\nIf the null hypothesis is true, \\(F\\) has an expected value close to 1 (numerator and denominator are estimates of the same variability)\nIf it is false, the numerator will likely be larger, because systematic, between-group differences contribute to the variance of the means, but not to variance within group."
  },
  {
    "objectID": "slides/lec-6_mean.html#calculating-f-statistic-example",
    "href": "slides/lec-6_mean.html#calculating-f-statistic-example",
    "title": "Week 06: Comparing Means",
    "section": "Calculating F-statistic: Example",
    "text": "Calculating F-statistic: Example\n\\[F = \\frac{MS_b}{MS_w} = \\frac{720.3}{1058.167} = 0.68\\]\nLink to probability calculator"
  },
  {
    "objectID": "slides/lec-6_mean.html#contrastspost-hoc-tests",
    "href": "slides/lec-6_mean.html#contrastspost-hoc-tests",
    "title": "Week 06: Comparing Means",
    "section": "Contrasts/Post-Hoc Tests",
    "text": "Contrasts/Post-Hoc Tests\nPerformed when there is a significant difference among the groups to examine which groups are different\n\nContrasts: When we have a priori hypotheses\nPost-hoc Tests: When we want to test everything"
  },
  {
    "objectID": "slides/lec-6_mean.html#tables",
    "href": "slides/lec-6_mean.html#tables",
    "title": "Week 06: Comparing Means",
    "section": "Tables",
    "text": "Tables\nOften times the output will be in the form of a table and then it is often reported this way in the manuscript\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\ndf\nSum of Squares\nMean Squares\nF-statistic\np-value\n\n\n\n\nGroup\n\\(G-1\\)\n\\(SS_b\\)\n\\(MS_b = \\frac{SS_b}{df_b}\\)\n\\(F = \\frac{MS_b}{MS_w}\\)\n\\(p\\)\n\n\nResidual\n\\(N-G\\)\n\\(SS_w\\)\n\\(MS_w = \\frac{SS_w}{df_w}\\)\n\n\n\n\nTotal\n\\(N-1\\)\n\\(SS_{total}\\)"
  },
  {
    "objectID": "slides/lec-6_mean.html#in-text",
    "href": "slides/lec-6_mean.html#in-text",
    "title": "Week 06: Comparing Means",
    "section": "In-Text",
    "text": "In-Text\n\nA one-way analysis of variance was used to test for differences in the [variable of interest/outcome variable] as a function of [whatever the factor is]. Specifically, differences in [variable of interest] were assessed for the [list different levels and be sure to include (M= , SD= )] . The one-way ANOVA revealed a significant/nonsignificant effect of [factor] on scores on the [variable of interest] (F(dfb, dfw) = f-ratio, p = p-value, Œ∑2 = effect size).\nPlanned comparisons were conducted to compare expected differences among the [however many groups] means. Planned contrasts revealed that participants in the [one of the conditions] had a greater/fewer [variable of interest] and then include the p-value. This same type of sentence is repeated for whichever contrasts you completed. Descriptive statistics were reported in Table 1."
  },
  {
    "objectID": "slides/lec-6_mean.html#books-by-marital-status",
    "href": "slides/lec-6_mean.html#books-by-marital-status",
    "title": "Week 06: Comparing Means",
    "section": "Books by Marital Status",
    "text": "Books by Marital Status\nWe can examine how many books (continuous) by marital status (7 categories: Married, Divorced, In a relationship, Other, Separated, Widowed, Single)\nVISUALIZE!\n\nggbetweenstats(\n  data  = cah,\n  x     = marital_status,\n  y     = books,\n  title = \"Distribution of books across marital status\"\n)"
  },
  {
    "objectID": "slides/lec-6_mean.html#family-wise-error",
    "href": "slides/lec-6_mean.html#family-wise-error",
    "title": "Week 06: Comparing Means",
    "section": "Family-wise error",
    "text": "Family-wise error\nThese pairwise comparisons can quickly grow in number as the number of Groups increases. With 3 (k) Groups, we have k(k-1)/2 = 3 possible pairwise comparisons.\nAs the number of groups in the ANOVA grows, the number of possible pairwise comparisons increases dramatically."
  },
  {
    "objectID": "slides/lec-6_mean.html#what-is-a-two-way-anova",
    "href": "slides/lec-6_mean.html#what-is-a-two-way-anova",
    "title": "Week 06: Comparing Means",
    "section": "What is a Two-Way ANOVA?",
    "text": "What is a Two-Way ANOVA?\nExamines the impact of 2 nominal/categorical variables on a continuous outcome\nWe can now examine:\n\nThe impact of variable 1 on the outcome (Main Effect)\nThe impact of variable 2 on the outcome (Main Effect)\nThe interaction¬†of variable 1 & 2 on the outcome (Interaction Effect)\n\nThe effect of variable 1 depends on the level of variable 2"
  },
  {
    "objectID": "slides/lec-6_mean.html#main-effect-interactions",
    "href": "slides/lec-6_mean.html#main-effect-interactions",
    "title": "Week 06: Comparing Means",
    "section": "Main Effect & Interactions",
    "text": "Main Effect & Interactions\nMain Effect: Basically a one-way ANOVA\n\nThe effect of variable 1 is the same across all levels of variable 2\n\nInteraction:\n\nAble to examine the effect of variable 1 across different levels of variable 2\nBasically speaking, the effect of variable 1 on our outcome DEPENDS on the levels of variable 2"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#from-squirrels-to-significance-a-guide-to-research-design-inference",
    "href": "slides/lec-4_design-inference.html#from-squirrels-to-significance-a-guide-to-research-design-inference",
    "title": "Week 04: Design & Inference",
    "section": "From Squirrels to Significance: A Guide to Research Design & Inference",
    "text": "From Squirrels to Significance: A Guide to Research Design & Inference\nWeek 4"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-core-challenge",
    "href": "slides/lec-4_design-inference.html#the-core-challenge",
    "title": "Week 04: Design & Inference",
    "section": "The Core Challenge",
    "text": "The Core Challenge\n\nLast week: We learned to describe and visualize patterns in our sample.\nThe Rest of the Course: We want to make claims about the population.\nThe Problem: How do we know if a pattern we see in our sample (e.g., a difference between groups) is a ‚Äúreal‚Äù effect or just random sampling error?\nThe Solution: We build a statistical model to test our question against the backdrop of randomness."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-journey-of-a-research-question",
    "href": "slides/lec-4_design-inference.html#the-journey-of-a-research-question",
    "title": "Week 04: Design & Inference",
    "section": "The Journey of a Research Question",
    "text": "The Journey of a Research Question\n\nAll research starts with a question about the world.\nBut how do we get from a messy, real-world question to a clean, statistical answer?\n\nOur Journey Today:\n\nPart 1: From Concept to Data (How do we measure what we care about?)\nPart 2: The Blueprint for Claims (How do we structure our study?)\nPart 3: From Design to Model (How do we analyze our data?)"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-first-most-important-choice",
    "href": "slides/lec-4_design-inference.html#the-first-most-important-choice",
    "title": "Week 04: Design & Inference",
    "section": "The First & Most Important Choice",
    "text": "The First & Most Important Choice\n\nBefore we can analyze anything, we need data. This means turning an abstract concept into a concrete, measurable variable.\nThis process is called operationalization.\nYour operationalization is your argument for what a concept means in the context of your study."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-squirrel-gang",
    "href": "slides/lec-4_design-inference.html#the-squirrel-gang",
    "title": "Week 04: Design & Inference",
    "section": "The Squirrel Gang",
    "text": "The Squirrel Gang\nLet‚Äôs imagine a new study. Our research question is:\nDoes being aggressively attacked by a campus squirrel for your sandwich increase a student‚Äôs acute stress?\n\nPredictor: squirrel_incident (Attacked vs.¬†Not Attacked).\nOutcome: acute_stress.\n\nBut what is ‚Äúacute stress‚Äù? As the researcher, how do you measure it?\n\n\n\nTurn to the person/people next to you and identify how you would define and measure ‚Äústress‚Äù."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#how-would-you-measure-stress",
    "href": "slides/lec-4_design-inference.html#how-would-you-measure-stress",
    "title": "Week 04: Design & Inference",
    "section": "How Would You Measure ‚ÄúStress‚Äù?",
    "text": "How Would You Measure ‚ÄúStress‚Äù?\n\n\n\n\n\n\n\n\n\nMethod of Measurement\nHow It Works\nData Generated\nWhat It Really Measures\n\n\nSubjective Self-Report\n‚ÄúOn a scale of 0-100, how stressed do you feel right now?‚Äù\nContinuous (0-100)\nThe feeling of stress.\n\n\nAutonomic Arousal\nMeasure heart rate in beats per minute (BPM).\nContinuous (e.g., 115 BPM)\nThe body‚Äôs alarm for stress.\n\n\nCognitive Impairment\n‚ÄúCount backward from 1,084 by 7s.‚Äù Measure speed & accuracy.\nContinuous (# of errors)\nThe brain‚Äôs processing under stress.\n\n\nCoded Facial Expression\nAnalyze video for micro-expressions of fear or anger.\nCategorical or Ordinal\nThe face‚Äôs expression of stress."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-two-big-claims",
    "href": "slides/lec-4_design-inference.html#the-two-big-claims",
    "title": "Week 04: Design & Inference",
    "section": "The Two Big Claims",
    "text": "The Two Big Claims\nNow that we know what we‚Äôre measuring, let‚Äôs talk about how we structure the study. Your design determines the kind of claim you can make.\n\nAn Associational Claim: Two variables are related.\n\n‚ÄúPeople who experience squirrel attacks tend to report higher stress.‚Äù\n\nA Causal Claim: A change in one variable causes a change in another.\n\n‚ÄúThe experience of a squirrel attack causes an increase in stress.‚Äù"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-3-rules-of-causality",
    "href": "slides/lec-4_design-inference.html#the-3-rules-of-causality",
    "title": "Week 04: Design & Inference",
    "section": "The 3 Rules of Causality",
    "text": "The 3 Rules of Causality\nTo earn the right to say ‚ÄúX causes Y,‚Äù you must demonstrate three things:\n\nCovariance: X and Y are related.\nTemporal Precedence: The cause (X) must happen before the effect (Y).\nInternal Validity: There are no other plausible explanations (we‚Äôve ruled out confounds)."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-confounding-variable-problem",
    "href": "slides/lec-4_design-inference.html#the-confounding-variable-problem",
    "title": "Week 04: Design & Inference",
    "section": "The Confounding Variable Problem",
    "text": "The Confounding Variable Problem\nA confound is a ‚Äúthird variable‚Äù that creates a spurious relationship between your two variables. This is the #1 threat to causal claims.\n\nClassic Example: Ice cream sales are positively correlated with drowning deaths.\nThe Confound: Summer heat! Hot weather causes both more ice cream sales and more swimming."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-gold-standard-for-defeating-confounds-the-experiment",
    "href": "slides/lec-4_design-inference.html#the-gold-standard-for-defeating-confounds-the-experiment",
    "title": "Week 04: Design & Inference",
    "section": "The Gold Standard for Defeating Confounds: The Experiment",
    "text": "The Gold Standard for Defeating Confounds: The Experiment\nA True Experiment is the most powerful tool for establishing causality. It has two magic ingredients:\n\nManipulation: The researcher actively manipulates the Independent Variable (IV).\nRandom Assignment: Every participant has an equal chance of being in any condition. This breaks the links to potential confounds by distributing them evenly across groups."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#key-design-dimensions",
    "href": "slides/lec-4_design-inference.html#key-design-dimensions",
    "title": "Week 04: Design & Inference",
    "section": "Key Design Dimensions",
    "text": "Key Design Dimensions\n\nBetween-Subjects: Different groups of people get different conditions. We compare Group A vs.¬†Group B.\nWithin-Subjects: The same group of people experiences all conditions. We compare people to themselves.\nCross-Sectional: All data is collected at a single point in time. (Fails temporal precedence).\nLongitudinal: Data is collected from the same people over multiple time points. (Establishes temporal precedence)."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#descriptives-vs.-inference",
    "href": "slides/lec-4_design-inference.html#descriptives-vs.-inference",
    "title": "Week 04: Design & Inference",
    "section": "Descriptives vs.¬†Inference",
    "text": "Descriptives vs.¬†Inference\n\n\nMoving from simply describing our data\nWith means and standard deviations\n\nTo drawing conclusions about the population\nUsing inferential statistics"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#probability---understanding-randomness",
    "href": "slides/lec-4_design-inference.html#probability---understanding-randomness",
    "title": "Week 04: Design & Inference",
    "section": "Probability - Understanding Randomness",
    "text": "Probability - Understanding Randomness\nThere are several possible interpretations of probability but they (almost) completely agree on the mathematical rules probability must follow:\n\\(P(A)\\) = Probablity of event A\n0 ‚â§ \\(P(A)\\) ‚â§ 1"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-law-of-large-numbers",
    "href": "slides/lec-4_design-inference.html#the-law-of-large-numbers",
    "title": "Week 04: Design & Inference",
    "section": "The Law of Large Numbers",
    "text": "The Law of Large Numbers\nAs more observations are collected, the proportion of occurrences with a particular outcome, \\(pÃÇ_n\\), converges to the probability of that outcome, \\(p\\).\nExample:\n\nAs the sample size increases, the sample mean tends to get closer to the population mean\nAnd as the sample size approaches infinity ‚ôæÔ∏è, the sample mean approaches the population mean"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#statistics-probability-inference",
    "href": "slides/lec-4_design-inference.html#statistics-probability-inference",
    "title": "Week 04: Design & Inference",
    "section": "Statistics, Probability & Inference",
    "text": "Statistics, Probability & Inference\n\nThink about seeing statistics posted on the news\n\nOften times polling companies survey a large sample to then make a statement about the population\n\nWe assume the sample is representative of the larger population, but how representative?\n\nThis is where probability theory comes in\n\nProbability theory provides tools to assess how likely sample results are if they differ from the true population parameter"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#role-of-probability-theory",
    "href": "slides/lec-4_design-inference.html#role-of-probability-theory",
    "title": "Week 04: Design & Inference",
    "section": "Role of Probability Theory",
    "text": "Role of Probability Theory"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#probability---the-2-main-realms",
    "href": "slides/lec-4_design-inference.html#probability---the-2-main-realms",
    "title": "Week 04: Design & Inference",
    "section": "Probability - The 2 main realms",
    "text": "Probability - The 2 main realms\n\n\nFrequentist\nProbability is a long-run frequency of an event\n\nBayesian\nProbability of an event as the degree of belief"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-universal-language-of-models",
    "href": "slides/lec-4_design-inference.html#the-universal-language-of-models",
    "title": "Week 04: Design & Inference",
    "section": "The Universal Language of Models",
    "text": "The Universal Language of Models\n\nYour measurement and design choices create the blueprint for your analysis. They lead you directly to the correct statistical model.\nAll models we learn this semester can be expressed in R with a simple formula:\n\nOutcome ~ Predictor"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#a-decision-tree-for-your-model",
    "href": "slides/lec-4_design-inference.html#a-decision-tree-for-your-model",
    "title": "Week 04: Design & Inference",
    "section": "A Decision Tree for Your Model üå≥",
    "text": "A Decision Tree for Your Model üå≥\n\n\nIf your goal is to‚Ä¶ COMPARE GROUPS:\n\nPredictor (IV) is Categorical\nOutcome (DV) is Continuous\nüëâ You are in the t-test / ANOVA family of models.\nThe model looks like: Continuous_Outcome ~ Categorical_Predictor\n\n\nIf your goal is to‚Ä¶ ASSESS AN ASSOCIATION:\n\nPredictor (IV) is Continuous\nOutcome (DV) is Continuous\nüëâ You are in the Correlation / Regression family of models.\nThe model looks like: Continuous_Outcome ~ Continuous_Predictor"
  },
  {
    "objectID": "slides/lec-4_design-inference.html#data-to-models-to-inference-nhst",
    "href": "slides/lec-4_design-inference.html#data-to-models-to-inference-nhst",
    "title": "Week 04: Design & Inference",
    "section": "Data to Models to Inference (NHST)",
    "text": "Data to Models to Inference (NHST)\nSo we have a model, like: depression_score ~ therapy_group. How do we test it?\nWe use the Null Hypothesis Significance Testing (NHST) framework:\n\nThe Null Hypothesis \\(H_0\\) : A statement that the predictor has no relationship with the outcome in the population. It is the ‚Äúnull model.‚Äù\n\n\\(H_0\\) : In the population, there is no difference in depression scores between the therapy and control groups. therapy_group does not predict depression_score.\n\nThe Alternative Hypothesis \\(H_A\\) : Our research hypothesis. The predictor does have a relationship with the outcome.\n\n\\(H_A\\) : In the population, there is a difference. therapy_group does predict depression_score."
  },
  {
    "objectID": "slides/lec-4_design-inference.html#the-p-value",
    "href": "slides/lec-4_design-inference.html#the-p-value",
    "title": "Week 04: Design & Inference",
    "section": "The p-value",
    "text": "The p-value\nThe p-value tells us how surprising our sample data would be if the null hypothesis (the ‚Äúno relationship‚Äù model) were true for the population.\nIt‚Äôs a measure of the incompatibility between our data and the null model.\n\nA small p-value (p&lt;.05) suggests that our data are incompatible with the null model. We have evidence to reject the null model and conclude that our predictor is likely related to the outcome.\n\nThe statistical test you run (t.test, cor.test, lm) is just the engine that calculates the p-value for your specific model. The logic is always the same."
  },
  {
    "objectID": "slides/template-seasons.html#quarto",
    "href": "slides/template-seasons.html#quarto",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets",
    "href": "slides/template-seasons.html#bullets",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations",
    "href": "slides/template-seasons.html#latex-equations",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables",
    "href": "slides/template-seasons.html#tables",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks",
    "href": "slides/template-seasons.html#callout-blocks",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-1",
    "href": "slides/template-seasons.html#quarto-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-1",
    "href": "slides/template-seasons.html#bullets-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-1",
    "href": "slides/template-seasons.html#latex-equations-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-1",
    "href": "slides/template-seasons.html#tables-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-1",
    "href": "slides/template-seasons.html#callout-blocks-1",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-2",
    "href": "slides/template-seasons.html#quarto-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-2",
    "href": "slides/template-seasons.html#bullets-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-2",
    "href": "slides/template-seasons.html#latex-equations-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-2",
    "href": "slides/template-seasons.html#tables-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-2",
    "href": "slides/template-seasons.html#callout-blocks-2",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/template-seasons.html#quarto-3",
    "href": "slides/template-seasons.html#quarto-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "slides/template-seasons.html#bullets-3",
    "href": "slides/template-seasons.html#bullets-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code\n\n\nlm(mpg ~ disp, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122"
  },
  {
    "objectID": "slides/template-seasons.html#latex-equations-3",
    "href": "slides/template-seasons.html#latex-equations-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "LaTeX Equations",
    "text": "LaTeX Equations\nMathJax rendering of equations to HTML\n\\[\\begin{gather*}\na_1=b_1+c_1\\\\\na_2=b_2+c_2-d_2+e_2\n\\end{gather*}\\]\n\\[\\begin{align}\na_{11}& =b_{11}&\n  a_{12}& =b_{12}\\\\\na_{21}& =b_{21}&\n  a_{22}& =b_{22}+c_{22}\n\\end{align}\\]"
  },
  {
    "objectID": "slides/template-seasons.html#tables-3",
    "href": "slides/template-seasons.html#tables-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Tables",
    "text": "Tables\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText"
  },
  {
    "objectID": "slides/template-seasons.html#callout-blocks-3",
    "href": "slides/template-seasons.html#callout-blocks-3",
    "title": "PSYC 640 - Graduate Statistics",
    "section": "Callout Blocks",
    "text": "Callout Blocks\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\n\nTip With Caption\n\n\nThis is an example of a callout with a caption."
  },
  {
    "objectID": "slides/lec-11_categor.html#today",
    "href": "slides/lec-11_categor.html#today",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶"
  },
  {
    "objectID": "slides/lec-11_categor.html#regression",
    "href": "slides/lec-11_categor.html#regression",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Regression",
    "text": "Regression\n3 main reasons for using regression:\n\nAs a description (what is the average salary for men and women?)\nAs part of causal inference (Does being a woman result in a lower salary?)\nFor prediction (‚ÄúWhat happens if‚Ä¶‚Äù questions)"
  },
  {
    "objectID": "slides/lec-11_categor.html#multiple-regression",
    "href": "slides/lec-11_categor.html#multiple-regression",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Multiple Regression",
    "text": "Multiple Regression\nWe may want to include additional predictors into our model to best explain the variance in an outcome:\n\\[ Y_i = b_0 + b_1X_{1i} + b_2X_{2i} + ... + b_nX_{ni}+ e_i \\]"
  },
  {
    "objectID": "slides/lec-11_categor.html#reporting-standardized-or-unstandardized",
    "href": "slides/lec-11_categor.html#reporting-standardized-or-unstandardized",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Reporting Standardized or Unstandardized?",
    "text": "Reporting Standardized or Unstandardized?\nINTERPRET b:\n\nWhen the variables are measured in a meaningful metric\nTo compare the relative effects of different predictors in the same sample\n\nINTERPRET Œ≤:\n\nWhen the variables are not measured in a meaningful metric\nTo compare effects across samples or studies"
  },
  {
    "objectID": "slides/lec-11_categor.html#multiple-regression-example",
    "href": "slides/lec-11_categor.html#multiple-regression-example",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Multiple Regression: Example",
    "text": "Multiple Regression: Example\nPreviously, we predicted the # of Transformers movies someone watched by their age, income and # of books read\n\ncah_data &lt;- import(here(\"files\", \"data\", \n                        \"CAH.csv\")) %&gt;% \n  mutate(across(where(is.character), ~na_if(., \"\")))\n\nThe regression equation would look something like this:\n\\[\nY = b_0 + b_1X_1 + b_2X_2 + b_3X_3 + e\n\\]"
  },
  {
    "objectID": "slides/lec-11_categor.html#categorical-predictors",
    "href": "slides/lec-11_categor.html#categorical-predictors",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Categorical Predictors",
    "text": "Categorical Predictors\nTypically identified by a grouping variable that may be a character\n\nglimpse(cah_data$political_affiliation)\n\n chr [1:1000] \"Democrat\" \"Democrat\" \"Independent\" \"Republican\" \"Democrat\" ...\n\n\nNeed to change the variable from character to factor which will assign a number to each group\n\ncah_data &lt;- cah_data %&gt;%\n  mutate(\n    pol = as.factor(political_affiliation),\n    ghosts = as.factor(ghosts)\n    )\n\nglimpse(cah_data$pol)\n\n Factor w/ 3 levels \"Democrat\",\"Independent\",..: 1 1 2 3 1 1 2 3 3 1 ..."
  },
  {
    "objectID": "slides/lec-11_categor.html#dummy-coding",
    "href": "slides/lec-11_categor.html#dummy-coding",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Dummy Coding",
    "text": "Dummy Coding\nNumerical placeholders used to represent categorical variables\nTaking a categorical variable with \\(k\\) levels (e.g., Democratic, Independent, Republican) into \\(k-1\\) binary variables.\n\n\n\npolitical_affiliation\nbecomes\nInd (binary1)\nRep (binary2)\n\n\n\n\nDemocrat\n‚Äì&gt;\n0\n0\n\n\nIndependent\n‚Äì&gt;\n1\n0\n\n\nRepublican\n‚Äì&gt;\n0\n1\n\n\n‚Ä¶\n\n‚Ä¶\n‚Ä¶"
  },
  {
    "objectID": "slides/lec-11_categor.html#categorical-regression",
    "href": "slides/lec-11_categor.html#categorical-regression",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Categorical Regression",
    "text": "Categorical Regression\nGoing back to our Transformers dataset, let‚Äôs see how our political affiliation variable can predict # of transformers movies\nUsually you have to create the separate dummy variables, but not in R\n\ncat1 &lt;- lm(transformers ~ pol,\n           data = cah_data)\n\nYou can also double check the dummy/contrast coding\n\ncontrasts(cah_data$pol)\n\n            Independent Republican\nDemocrat              0          0\nIndependent           1          0\nRepublican            0          1"
  },
  {
    "objectID": "slides/lec-11_categor.html#categories-in-action",
    "href": "slides/lec-11_categor.html#categories-in-action",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Categories in Action",
    "text": "Categories in Action\nGoal: Gain greater familiarity with dummy coding and categorical predictors\nScenario: We are researchers examining the impact of a new intervention on reducing the vocalization ‚Äú6Ô∏è‚É£7Ô∏è‚É£‚Äù in the youths. We have done classroom observations to collect data on how many times students say ‚Äú6Ô∏è‚É£7Ô∏è‚É£‚Äù after receiving the intervention. This is the data you have in front of you. Youths have been randomly assigned to one of 3 groups, and we need to determine which had the biggest impact.\n\n\n\n\n\n\nNote\n\n\nYou will submit one Rmd file for the whole group. Be sure to include all group member‚Äôs names."
  },
  {
    "objectID": "slides/lec-11_categor.html#categories-in-action-using-r",
    "href": "slides/lec-11_categor.html#categories-in-action-using-r",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Categories in Action: Using R",
    "text": "Categories in Action: Using R\nNow that we have the data entered appropriately, let‚Äôs double check, and include some additional variables!\nImport dataset, confirm predictions, include pre-scores to see how that changes interpretation\n\n\n\n\n\n\nWarning\n\n\nDr.¬†Haraden is going to start opening up R and doing a follow-along thing. You have been warned"
  },
  {
    "objectID": "slides/lec-11_categor.html#status",
    "href": "slides/lec-11_categor.html#status",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "6Ô∏è‚É£7Ô∏è‚É£ Status",
    "text": "6Ô∏è‚É£7Ô∏è‚É£ Status\nIn our last example, we were able to see how these categorical variables could predict a continuous variable. This is perfect for linear regression.\nWhat if we want to see if students have ‚Äúrecovered‚Äù from 6Ô∏è‚É£7Ô∏è‚É£?\nWe would then ask: ‚Äú‚ÄúWhich participants dropped below the clinical threshold for 6Ô∏è‚É£7Ô∏è‚É£ at follow-up? Now, our outcome is either recovered or not recovered.‚Äù"
  },
  {
    "objectID": "slides/lec-11_categor.html#recovery-status",
    "href": "slides/lec-11_categor.html#recovery-status",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Recovery Status",
    "text": "Recovery Status\nNow we have a binary outcome; Yes/No recovery\nWhat happens when we fit a linear regression? What are the chances of someone with a pre-score of 12 recovering by the follow-up?\n\n\nCode\ncat_reg &lt;- import(here(\"files\", \"data\", \n                       \"cat_reg_complete.xlsx\")) %&gt;% \n  janitor::clean_names() %&gt;% \n  # 1 = recovered; 0 = not recovered\n  mutate(recover = if_else(post_score &gt; 12, 0, 1))\n\ncat_reg %&gt;% \n  ggplot(aes(pre_score, recover)) +\n  geom_jitter(width = 0, height = 0.05, alpha = 0.5) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(\n    title = \"Pre-Score predicting Recovery\"\n  )"
  },
  {
    "objectID": "slides/lec-11_categor.html#probability-to-odds-to-log-odds",
    "href": "slides/lec-11_categor.html#probability-to-odds-to-log-odds",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Probability to Odds to Log-Odds",
    "text": "Probability to Odds to Log-Odds\nProbability (p): The chance of an event happening. Ranges from 0 to 1\nOdds: The ratio of the probability of an event happening to it not happening.\n\n\\(Odds = \\frac{p}{1-p}\\)\nRanges from 0 to ‚àû. An odds of 4 means the event is 4 times more likely to happen than not.\n\nLog-Odds (logit): The natural log of the odds\n\n\\(Logit(p) = ln(\\frac{p}{1-p})\\)\nRanges from -‚àû to +‚àû\n\n\n\n\n\n\n\nImportant\n\n\nThis step transforms our bounded outcome variable (0/1) to an unbound one!"
  },
  {
    "objectID": "slides/lec-11_categor.html#generalized-linear-model-glm",
    "href": "slides/lec-11_categor.html#generalized-linear-model-glm",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Generalized Linear Model (GLM)",
    "text": "Generalized Linear Model (GLM)\nA generalization of a linear model (duh) that is used when the response variable has a non-normal error distribution\nMost commonly used when there is a binary (0-1) or count variable as the outcome (we will focus on the binary)\nUltimately, we are trying to identify the probability of the outcome taking the value 1 (‚Äúsuccess‚Äù) that is being modeled in relation to the predictor variables"
  },
  {
    "objectID": "slides/lec-11_categor.html#odds-ratios-or",
    "href": "slides/lec-11_categor.html#odds-ratios-or",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Odds Ratios (OR)",
    "text": "Odds Ratios (OR)\nOR &gt; 1: The predictor increases the odds of the outcome. (e.g., OR of 2.5 means the odds of believing in ghosts are 2.5 times higher).\nOR &lt; 1: The predictor decreases the odds of the outcome. (e.g., OR of 0.4 means the odds of believing in ghosts are 60% lower).\nOR = 1: The predictor has no effect on the odds of the outcome."
  },
  {
    "objectID": "slides/lec-11_categor.html#visualization",
    "href": "slides/lec-11_categor.html#visualization",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Visualization",
    "text": "Visualization\nExtract the model implied probabilities for each individual\n\nprobs &lt;- broom::augment(ln1, type.predict = \"response\")\n\nPlotting the predicted probabilities\n\nprobs %&gt;% \nggplot(aes(age, .fitted)) +\n  geom_line(color = \"blue\", linewidth = 1.5) +\n  labs(\n    title = \"Predicted Probability of Believing in Ghosts by Age\",\n    subtitle = \"Holding # of Books and Transformers Movies at their mean\",\n    x = \"Age (years)\",\n    y = \"Predicted Probability of Believing in Ghosts\"\n  ) +\n  ylim(0, 1) + # Keep the y-axis bounded at 0 and 1\n  theme_minimal()"
  },
  {
    "objectID": "slides/lec-11_categor.html#logistic-regression-summary",
    "href": "slides/lec-11_categor.html#logistic-regression-summary",
    "title": "Week 11: Categorical Predictors & Logistic Regression",
    "section": "Logistic Regression: Summary",
    "text": "Logistic Regression: Summary\n\n\n\n\n\n\n\n\nFeature\nLinear Regression\nLogistic Regression\n\n\n\n\nOutcome Variable\nContinuous\nCategorical (Binary)\n\n\nEquation\n\\(Y=Œ≤_0+Œ≤_1X\\)\n\\(ln‚Å°(\\frac{p}{1-p})=Œ≤_0+Œ≤_1X\\)\n\n\nKey Interpretation\n\\(\\beta_1\\) is the change in the mean of Y\n\\(\\exp(\\beta_1)\\) is theodds ratio\n\n\nR Function\nlm()\nglm(..., family=\"binomial\")"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#today",
    "href": "slides/lec-10_multiple-reg.html#today",
    "title": "Week 10: Multiple Regression",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nhttps://bsky.app/profile/andrew.heiss.phd/post/3ly6hqr3mtk2z"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#regression",
    "href": "slides/lec-10_multiple-reg.html#regression",
    "title": "Week 10: Multiple Regression",
    "section": "Regression",
    "text": "Regression\n3 main reasons for using regression:\n\nAs a description (what is the average salary for men and women?)\nAs part of causal inference (Does being a woman result in a lower salary?)\nFor prediction (‚ÄúWhat happens if‚Ä¶‚Äù questions)"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#explaining-variance",
    "href": "slides/lec-10_multiple-reg.html#explaining-variance",
    "title": "Week 10: Multiple Regression",
    "section": "Explaining Variance",
    "text": "Explaining Variance"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#model-interpretation",
    "href": "slides/lec-10_multiple-reg.html#model-interpretation",
    "title": "Week 10: Multiple Regression",
    "section": "Model Interpretation",
    "text": "Model Interpretation\nOnce we have a model, we will be able to interpret the coefficients. For a bivariate regression, this was fairly straightforward\nWe would look to the beta (effect size) and interpret it as: for every 1 unit increase in our X variable, there will be beta units increase in our Y variable."
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#regressions",
    "href": "slides/lec-10_multiple-reg.html#regressions",
    "title": "Week 10: Multiple Regression",
    "section": "Regressions",
    "text": "Regressions\nWe may want to include additional predictors into our model to best explain the variance in an outcome:\n\\[ Y_i = b_0 + b_1X_{1i} + b_2X_{2i} + ... + b_nX_{ni}+ e_i \\]"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#fire-data-example",
    "href": "slides/lec-10_multiple-reg.html#fire-data-example",
    "title": "Week 10: Multiple Regression",
    "section": "Fire Data Example",
    "text": "Fire Data Example\nWe have been contracted by the county to examine their Fire Department. We have been provided with the data below, and asked to examine what may be related to how expensive a fire costs.\n\n\nCode\n# --- Step 1: Simulate the Data ---\nset.seed(123) # for reproducibility\nn &lt;- 300 # number of fires\n\n# Create three distinct groups for fire size\nfire_sizes &lt;- sample(c(\"Small\", \"Medium\", \"Large\"), n, replace = TRUE, prob = c(0.4, 0.3, 0.3))\n\n# Simulate our variables based on fire size\nfire_data &lt;- tibble(size = factor(fire_sizes, levels = c(\"Small\", \"Medium\", \"Large\"))) %&gt;%\n  mutate(\n    # The bigger the fire, the more trucks are sent.\n    num_trucks = case_when(\n      size == \"Small\"  ~ round(rnorm(n(), 2, 0.5)),\n      size == \"Medium\" ~ round(rnorm(n(), 5, 1)),\n      size == \"Large\"  ~ round(rnorm(n(), 9, 1.5))\n    ),\n    # For a given size, more trucks -&gt; less damage (the true effect)\n    # But bigger size -&gt; more damage (the confounding effect)\n    damage_amount = case_when(\n      size == \"Small\"  ~ 20 - 2 * num_trucks + rnorm(n(), 0, 5),\n      size == \"Medium\" ~ 80 - 3 * num_trucks + rnorm(n(), 0, 8),\n      size == \"Large\"  ~ 150 - 4 * num_trucks + rnorm(n(), 0, 12)\n    )\n  ) %&gt;%\n  # ensure no negative values\n  filter(num_trucks &gt; 0, damage_amount &gt; 0)\n\n\n\nglimpse(fire_data)\n\nRows: 300\nColumns: 3\n$ size          &lt;fct&gt; Small, Medium, Large, Medium, Medium, Small, Large, Medi‚Ä¶\n$ num_trucks    &lt;dbl&gt; 2, 6, 10, 6, 6, 2, 11, 5, 6, 9, 6, 10, 10, 6, 2, 6, 2, 2‚Ä¶\n$ damage_amount &lt;dbl&gt; 17.65717, 50.53150, 126.92287, 69.08090, 69.22461, 18.92‚Ä¶"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#reporting-standardized-or-unstandardized",
    "href": "slides/lec-10_multiple-reg.html#reporting-standardized-or-unstandardized",
    "title": "Week 10: Multiple Regression",
    "section": "Reporting Standardized or Unstandardized?",
    "text": "Reporting Standardized or Unstandardized?\nINTERPRET b:\n\nWhen the variables are measured in a meaningful metric\nTo compare the relative effects of different predictors in the same sample\n\nINTERPRET Œ≤:\n\nWhen the variables are not measured in a meaningful metric\nTo compare effects across samples or studies"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#goldilocks-problem",
    "href": "slides/lec-10_multiple-reg.html#goldilocks-problem",
    "title": "Week 10: Multiple Regression",
    "section": "Goldilocks Problem",
    "text": "Goldilocks Problem\nModels that are underfit, overfit or just-right"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#another-example-computer-time-frustration",
    "href": "slides/lec-10_multiple-reg.html#another-example-computer-time-frustration",
    "title": "Week 10: Multiple Regression",
    "section": "Another Example: Computer time & Frustration",
    "text": "Another Example: Computer time & Frustration\n\n\nCode\n# Step 1: Simulate the Data \nn &lt;- 150 # Number of students\n\n# Simulate total daily computer use in hours\ncomputer_use &lt;- rnorm(n, mean = 6, sd = 1.5)\n\n# Simulate hours spent on stats homework, now as a whole number\nstats_homework &lt;- round(0.7 * computer_use + rnorm(n, 0, 1))\n# Ensure no negative values after rounding\nstats_homework[stats_homework &lt; 0] &lt;- 0\nstats_homework[stats_homework &gt; computer_use] &lt;- 1\n\n# Simulate frustration level (driven mostly by stats homework)\n# Scale of 1-100\nfrustration &lt;- 10 + (2 * computer_use) + (8 * stats_homework) + rnorm(n, 0, 10)\n\n# Create a dataframe and clean up any impossible values\nstudent_data &lt;- tibble(\n  frustration = frustration,\n  computer_use = computer_use,\n  stats_homework = stats_homework\n) %&gt;%\n  filter(frustration &gt; 0, computer_use &gt; 0)\n\n# Bin the 'stats_homework' variable\nstudent_data &lt;- student_data %&gt;%\n  mutate(\n    stats_homework_bin = cut(stats_homework,\n                           breaks = quantile(stats_homework, probs = seq(0, 1, by = 1/3)),\n                           include.lowest = TRUE,\n                           labels = c(\"Low\", \"Medium\", \"High\"))\n  )\n\n\nWe have collected data on graduate students and their weekly frustration levels. Data that were also collected included the amount of time they were spending on their computer as well as the amount of statistics homework that they had."
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#model-assumptions-frustration",
    "href": "slides/lec-10_multiple-reg.html#model-assumptions-frustration",
    "title": "Week 10: Multiple Regression",
    "section": "Model Assumptions: Frustration",
    "text": "Model Assumptions: Frustration\n\ncheck_model(frus.lm2)"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#model-selection---stepwise",
    "href": "slides/lec-10_multiple-reg.html#model-selection---stepwise",
    "title": "Week 10: Multiple Regression",
    "section": "Model Selection - Stepwise",
    "text": "Model Selection - Stepwise\n\nBackward elimination\n\nStart with the full model (all potential predictors)\nPredictors eliminated one-at-a-time from the model until we cannot improve the model any further\n\nForward selection\n\nStart with nothing in the model\nContinue to add predictors one-at-a-time until we cannot find any predictors that improve the model any further"
  },
  {
    "objectID": "slides/lec-10_multiple-reg.html#model-selection",
    "href": "slides/lec-10_multiple-reg.html#model-selection",
    "title": "Week 10: Multiple Regression",
    "section": "Model Selection",
    "text": "Model Selection\nALWAYS start with theory and previous work\nYou should NEVER just go into data with just a lot of predictors and backward selection in mind. üß®"
  },
  {
    "objectID": "slides/lec-9_models.html#today",
    "href": "slides/lec-9_models.html#today",
    "title": "Week 09: Model Selection & Variability",
    "section": "Today‚Ä¶",
    "text": "Today‚Ä¶\nRegression & Model Selection"
  },
  {
    "objectID": "slides/lec-9_models.html#example---lego-data",
    "href": "slides/lec-9_models.html#example---lego-data",
    "title": "Week 09: Model Selection & Variability",
    "section": "Example - LEGO Data",
    "text": "Example - LEGO Data\n\nlego &lt;- import(here(\"files\", \"data\", \"LEGO_data.csv\")) %&gt;% \n  janitor::clean_names()\n\ndescribe(lego)\n\n                 vars  n     mean       sd   median  trimmed      mad      min\nset_name*           1 59    30.00    17.18    30.00    30.00    22.24     1.00\nset_number          2 59 37023.29 25089.50 31167.00 35693.88 30827.70 10294.00\nnumber_of_pieces    3 59  2416.58  2384.39  1503.00  2073.37  1906.62   104.00\nprice               4 59   218.19   214.72   129.99   189.81   163.09     9.99\n                      max range skew kurtosis      se\nset_name*           59.00    58 0.00    -1.26    2.24\nset_number       76974.00 66680 0.55    -1.21 3266.37\nnumber_of_pieces 10001.00  9897 1.32     1.37  310.42\nprice              999.99   990 1.28     1.48   27.95"
  },
  {
    "objectID": "slides/lec-9_models.html#regression-coefficient-b_1",
    "href": "slides/lec-9_models.html#regression-coefficient-b_1",
    "title": "Week 09: Model Selection & Variability",
    "section": "Regression coefficient, \\(b_{1}\\)",
    "text": "Regression coefficient, \\(b_{1}\\)\nCalculating the slope\n\\[\\Large b_{1} = \\frac{cov_{XY}}{s_{x}^{2}}\\]\n\n# Covariance\ncov(lego$number_of_pieces, lego$price)\n\n[1] 469162.5\n\n# Variance of # of Pieces\nvar(lego$number_of_pieces)\n\n[1] 5685305"
  },
  {
    "objectID": "slides/lec-9_models.html#regression-coefficient-b_1-1",
    "href": "slides/lec-9_models.html#regression-coefficient-b_1-1",
    "title": "Week 09: Model Selection & Variability",
    "section": "Regression coefficient, \\(b_{1}\\)",
    "text": "Regression coefficient, \\(b_{1}\\)\n\\[\\Large b_{1} = \\frac{cov_{XY}}{s_{x}^{2}} = r_{xy} \\frac{s_{y}}{s_{x}}\\]\n\n#SD of # of Pieces\nsd(lego$number_of_pieces) \n\n[1] 2384.388\n\n# SD of Price\nsd(lego$price) \n\n[1] 214.7205\n\n# Correlation\ncor(lego$number_of_pieces, lego$price)\n\n[1] 0.9163742"
  },
  {
    "objectID": "slides/lec-9_models.html#regression-coefficient-b_0",
    "href": "slides/lec-9_models.html#regression-coefficient-b_0",
    "title": "Week 09: Model Selection & Variability",
    "section": "Regression Coefficient, \\(b_0\\)",
    "text": "Regression Coefficient, \\(b_0\\)\nCalculating the Intercept:\n\\[\\Large b_0 = \\bar{Y} - b_1\\bar{X}\\]\nThe intercept adjusts the location of the regression line to ensure that it runs through the point \\(\\large (\\bar{X}, \\bar{Y}).\\)\n\nmean(lego$number_of_pieces)\n\n[1] 2416.576\n\nmean(lego$price)\n\n[1] 218.1936"
  },
  {
    "objectID": "slides/lec-9_models.html#what-is-the-regression-model",
    "href": "slides/lec-9_models.html#what-is-the-regression-model",
    "title": "Week 09: Model Selection & Variability",
    "section": "What is the Regression Model?",
    "text": "What is the Regression Model?\nUsing the calculations, identify what the linear model would be."
  },
  {
    "objectID": "slides/lec-9_models.html#what-is-the-regression-model-1",
    "href": "slides/lec-9_models.html#what-is-the-regression-model-1",
    "title": "Week 09: Model Selection & Variability",
    "section": "What is the Regression Model?",
    "text": "What is the Regression Model?\nUsing the calculations, identify what the linear model would be.\nYou hear about 3 new sets coming out that you are interested in. Since you have this regression model, you can calculate the total price for each. How much money do you need to save (excluding taxes) to buy all 3 sets?\n\n\n\nSet 1: 1031 pieces\nSet 2: 357\nSet 3: 4154"
  },
  {
    "objectID": "slides/lec-9_models.html#explaining-variance",
    "href": "slides/lec-9_models.html#explaining-variance",
    "title": "Week 09: Model Selection & Variability",
    "section": "Explaining Variance",
    "text": "Explaining Variance"
  },
  {
    "objectID": "slides/lec-9_models.html#stroop-data-modeling",
    "href": "slides/lec-9_models.html#stroop-data-modeling",
    "title": "Week 09: Model Selection & Variability",
    "section": "Stroop Data Modeling",
    "text": "Stroop Data Modeling\nResearch Question: Sleep Quality is negatively related to the Stroop Effect. Lower sleep quality will predict a greater Stroop effect.\nData Set (I hope I entered all the data in appropriately)"
  },
  {
    "objectID": "slides/lec-9_models.html#linear-regression",
    "href": "slides/lec-9_models.html#linear-regression",
    "title": "Week 09: Model Selection & Variability",
    "section": "Linear Regression",
    "text": "Linear Regression\nUse the information and let‚Äôs do it in R instead of on the board\nVisualize the relationship\nRun a linear regression"
  },
  {
    "objectID": "slides/lec-9_models.html#model-fit",
    "href": "slides/lec-9_models.html#model-fit",
    "title": "Week 09: Model Selection & Variability",
    "section": "Model Fit",
    "text": "Model Fit\nTake a look at the \\(R^2\\) value\nIs there any other data that we have that could impact overall Stroop Effects?\nAfter including it in the model, we can examine the change in \\(R^2\\)\nWhat would happen if we put the random number variable in there?"
  },
  {
    "objectID": "slides/lec-9_models.html#selecting-a-model",
    "href": "slides/lec-9_models.html#selecting-a-model",
    "title": "Week 09: Model Selection & Variability",
    "section": "Selecting a Model",
    "text": "Selecting a Model\nOne of the most daunting tasks can be identifying the ‚Äúright‚Äù statistical model for the data you have\nYou may see flowcharts like this:"
  },
  {
    "objectID": "slides/lec-9_models.html#example-t-test-vs.-anova-vs.-regression",
    "href": "slides/lec-9_models.html#example-t-test-vs.-anova-vs.-regression",
    "title": "Week 09: Model Selection & Variability",
    "section": "Example: t-test vs.¬†ANOVA vs.¬†Regression",
    "text": "Example: t-test vs.¬†ANOVA vs.¬†Regression\nThis might be something that we are considering between. How do we pick the ‚Äúright‚Äù one?\nStart with some data where we have 2 groups and we identify a 2 point difference in the groups scores\n\nset.seed(2025)\n\n# Two independent groups with equal variances\nn0 &lt;- 80; n1 &lt;- 80\nmu0 &lt;- 12; mu1 &lt;- 10      # true mean difference = -2\nsigma &lt;- 3\ny0 &lt;- rnorm(n0, mu0, sigma)\ny1 &lt;- rnorm(n1, mu1, sigma)\n\n# Put that in a data frame\ndat &lt;- data.frame(\n  dep = c(y0, y1),\n  group01 = c(rep(0, n0), rep(1, n1))\n) %&gt;% \n  mutate(group = factor(group01, levels = c(0,1), labels = c(\"control\",\"treatment\")))"
  },
  {
    "objectID": "previous-years.html",
    "href": "previous-years.html",
    "title": "Previous Years",
    "section": "",
    "text": "This course has been taught for a number of years, but this instructor has only started teaching it in Fall 2023. Below are previous iterations of the course in case you would like to check out how it has progressed!",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "previous-years.html#overview",
    "href": "previous-years.html#overview",
    "title": "Previous Years",
    "section": "",
    "text": "This course has been taught for a number of years, but this instructor has only started teaching it in Fall 2023. Below are previous iterations of the course in case you would like to check out how it has progressed!",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "previous-years.html#fall-2023",
    "href": "previous-years.html#fall-2023",
    "title": "Previous Years",
    "section": "Fall 2023",
    "text": "Fall 2023\nWebsite",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "previous-years.html#fall-2024",
    "href": "previous-years.html#fall-2024",
    "title": "Previous Years",
    "section": "Fall 2024",
    "text": "Fall 2024\nWebsite",
    "crumbs": [
      "Previous Years"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nWednesdays 9 - 11am or By Appointment\n\n\nClass Times\nMondays 8:00 - 10:50am\n\n\nClass Location\nWallace - 4640\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course is the introduction to statistics for graduate students. The goal of the course is to provide a grounding in statistical concepts, methods and application to research. I aim to increase student‚Äôs confidence in using these techniques and introducing them to R. Topics will range from including mathematical conceptualizations to practical application with various techniques ranging from descriptive statistics to regression.\n\n\n\n\nWe will be using R for all data wrangling, visualization, and analysis. You may use another statistical program in this course, but I will only be providing examples in R. Students must have the latest version of R and it is strongly recommended that students also download the RStudio GUI, both can be found here. Both types of software are free.\nWe will primarily be referring to chapters in the following textbooks:\n\nIntroduction to Modern Statistics (2e) (Cetinkaya-Rundel & Hardin, 2024)\nLearning Statistics with R (Navarro)\nR for Data Science (2e) (Wickham, √áetinkaya-Rundel, & Grolemund, 2023)\nModern Statistics with R (2e) (Thullin, 2025)\nStatistical Thinking (Poldrack, 2024)\nAn Introduction to Statistical Learning (2e) (James, Witten, Hastie & Tibshirani, 2023)\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) (Judd, McClelland, & Ryan, 2017)\n\nThese textbooks are available for free online and able to be downloaded. You may choose to purchase a paper copy if you wish, but it is not required.\nAll additional readings will be provided by the instructor.\n\n\n\n\n\n\nImportant\n\n\n\nNote: Readings on the schedule will need to be completed prior to the course they are listed for. We will build on the concepts you read about in that specific class period, so it is important that you have read.\n\n\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\nEvaluation and Grading\nYour grade is a reflection of your consistent effort, active engagement with the material, and ability to apply new concepts. The components are designed to build on one another, leading to a comprehensive understanding of data analysis.\n\n\n\n\n\n\n\nComponent\nWeight\n\n\nWeekly Labs\n30%\n\n\nJournal Entries\n10%\n\n\nParticipation & Engagement\n15%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n25%\n\n\n\nWeekly Labs\nThese are hands-on R assignments that directly reinforce the concepts from the week‚Äôs class. They are your primary opportunity to practice coding, build models, and interpret results. Labs will be submitted as R Markdown files, and your lowest score will be dropped. Labs will be due the Sunday night (11:59pm) before the next class.\nJournal Entries\nEach week, you will submit a short, reflective journal entry. This is a space for metacognition‚Äîthinking about your own learning. Prompts will include questions like, ‚ÄúWhat was the clearest concept this week, and why did it click?‚Äù or ‚ÄúWhat was the ‚Äòmuddiest‚Äô point for you, and what question would you ask about it?‚Äù. They can also take the form of just a general reflection. I want to get to know you and your learning throughout this process. This can also include anything related to your personal life or mental health that you would like for me to know, such as whether you are struggling to balance classes and research, having trouble creating a workspace at home, or whether you can balance time spent on campus and off. This can also be completely random things, like a news article you can‚Äôt stop thinking about, or a favorite TV show, movie or book that you just love (especially if it is LOTR or Cosmere related). The content of what you write has no impact on your grade. In addition, what you write will be kept confidential.\nThe purpose of this ‚Äúassignment‚Äù is to help facilitate communication between you and me. I have found other instructors using this and I would like to be able to develop supportive relationships with students, so I decided to implement this. Other instructors reported that they found that many students were more comfortable discussing questions and concerns in their journal assignments rather than through email.\nIn-Class Engagement & Activities\nOur class is a workshop, and your active participation is key. This portion of your grade is earned by being present and engaged. This includes participating in group discussions, engaging with the readings, working with peers on problems, and completing the small, hands-on coding exercises we‚Äôll do together or in small groups in class. This is a low-stress grade based on your consistent effort and collaboration during our classes.\nMidterm Project\nThis is a comprehensive analysis of a dataset I will provide. You will be asked to clean and visualize the data, formulate a research question, build an appropriate regression model, check its assumptions, and write a concise report of your findings. This project assesses your mastery of the first half of the course and will be due before the first class after Fall Break.\nFinal Project\nFor your final project, you will choose a dataset (either your own research data or from a list of options), develop your own research questions, and conduct a full analysis from start to finish. You will present your work in a short, manuscript-style report and a brief ‚Äúlightning talk‚Äù to the class in our final meeting. This is your capstone assignment to demonstrate your independent data analysis skills.\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. There will be a 15% deduction on the first day. And a 5% increase for each day beyond the deadline. Work will not be accepted beyond 5 days after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nYou may use generative AI tools (such as ChatGPT, Grammarly, or CoPilot) as a support for your work in this course. However:\n\nYou must personally review, edit, and take ownership of all submitted work.\nAny use of AI must be acknowledged in a brief note at the end of the assignment (e.g., ‚ÄúI used ChatGPT to generate initial bullet points for my resume, which I then revised and expanded.‚Äù) as well as being properly cited (RIT Library Citation Infoguide)\nAI tools may not be used to generate entire assignments without your input or to misrepresent your work. Submitting unedited or minimally edited AI output as your own is considered academic dishonesty.\nIn professional contexts, you will be expected to present work that is authentically your own ‚Äî this course is practice for that.\n\nIf I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment. Your information may also be submitted to the university as a Breach of Academic Integrity.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#psyc-640-graduate-statistics",
    "href": "syllabus.html#psyc-640-graduate-statistics",
    "title": "Syllabus",
    "section": "",
    "text": "Professor\nDustin Haraden, PhD\n\n\nEmail/Office\ndxhgsh@rit.edu; Eastman Hall - 3378\n\n\nOffice Hours\nWednesdays 9 - 11am or By Appointment\n\n\nClass Times\nMondays 8:00 - 10:50am\n\n\nClass Location\nWallace - 4640\n\n\n\nFor a PDF copy of the syllabus: Download File\n\n\nThis course is the introduction to statistics for graduate students. The goal of the course is to provide a grounding in statistical concepts, methods and application to research. I aim to increase student‚Äôs confidence in using these techniques and introducing them to R. Topics will range from including mathematical conceptualizations to practical application with various techniques ranging from descriptive statistics to regression.\n\n\n\n\nWe will be using R for all data wrangling, visualization, and analysis. You may use another statistical program in this course, but I will only be providing examples in R. Students must have the latest version of R and it is strongly recommended that students also download the RStudio GUI, both can be found here. Both types of software are free.\nWe will primarily be referring to chapters in the following textbooks:\n\nIntroduction to Modern Statistics (2e) (Cetinkaya-Rundel & Hardin, 2024)\nLearning Statistics with R (Navarro)\nR for Data Science (2e) (Wickham, √áetinkaya-Rundel, & Grolemund, 2023)\nModern Statistics with R (2e) (Thullin, 2025)\nStatistical Thinking (Poldrack, 2024)\nAn Introduction to Statistical Learning (2e) (James, Witten, Hastie & Tibshirani, 2023)\nData Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond (3rd ed.) (Judd, McClelland, & Ryan, 2017)\n\nThese textbooks are available for free online and able to be downloaded. You may choose to purchase a paper copy if you wish, but it is not required.\nAll additional readings will be provided by the instructor.\n\n\n\n\n\n\nImportant\n\n\n\nNote: Readings on the schedule will need to be completed prior to the course they are listed for. We will build on the concepts you read about in that specific class period, so it is important that you have read.\n\n\n\nCourse Goals\n\nBuild confidence in statistical reasoning & analysis.\nApply regression-based methods to real-world research questions.\nDevelop practical R skills for data wrangling, visualization, and reporting.\nProduce a portfolio-ready, reproducible final analysis.\n\n\nEvaluation and Grading\nYour grade is a reflection of your consistent effort, active engagement with the material, and ability to apply new concepts. The components are designed to build on one another, leading to a comprehensive understanding of data analysis.\n\n\n\n\n\n\n\nComponent\nWeight\n\n\nWeekly Labs\n30%\n\n\nJournal Entries\n10%\n\n\nParticipation & Engagement\n15%\n\n\nMidterm Project\n20%\n\n\nFinal Project\n25%\n\n\n\nWeekly Labs\nThese are hands-on R assignments that directly reinforce the concepts from the week‚Äôs class. They are your primary opportunity to practice coding, build models, and interpret results. Labs will be submitted as R Markdown files, and your lowest score will be dropped. Labs will be due the Sunday night (11:59pm) before the next class.\nJournal Entries\nEach week, you will submit a short, reflective journal entry. This is a space for metacognition‚Äîthinking about your own learning. Prompts will include questions like, ‚ÄúWhat was the clearest concept this week, and why did it click?‚Äù or ‚ÄúWhat was the ‚Äòmuddiest‚Äô point for you, and what question would you ask about it?‚Äù. They can also take the form of just a general reflection. I want to get to know you and your learning throughout this process. This can also include anything related to your personal life or mental health that you would like for me to know, such as whether you are struggling to balance classes and research, having trouble creating a workspace at home, or whether you can balance time spent on campus and off. This can also be completely random things, like a news article you can‚Äôt stop thinking about, or a favorite TV show, movie or book that you just love (especially if it is LOTR or Cosmere related). The content of what you write has no impact on your grade. In addition, what you write will be kept confidential.\nThe purpose of this ‚Äúassignment‚Äù is to help facilitate communication between you and me. I have found other instructors using this and I would like to be able to develop supportive relationships with students, so I decided to implement this. Other instructors reported that they found that many students were more comfortable discussing questions and concerns in their journal assignments rather than through email.\nIn-Class Engagement & Activities\nOur class is a workshop, and your active participation is key. This portion of your grade is earned by being present and engaged. This includes participating in group discussions, engaging with the readings, working with peers on problems, and completing the small, hands-on coding exercises we‚Äôll do together or in small groups in class. This is a low-stress grade based on your consistent effort and collaboration during our classes.\nMidterm Project\nThis is a comprehensive analysis of a dataset I will provide. You will be asked to clean and visualize the data, formulate a research question, build an appropriate regression model, check its assumptions, and write a concise report of your findings. This project assesses your mastery of the first half of the course and will be due before the first class after Fall Break.\nFinal Project\nFor your final project, you will choose a dataset (either your own research data or from a list of options), develop your own research questions, and conduct a full analysis from start to finish. You will present your work in a short, manuscript-style report and a brief ‚Äúlightning talk‚Äù to the class in our final meeting. This is your capstone assignment to demonstrate your independent data analysis skills.\nGrade Scheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\n\n\n\n\nPercentage\n93+\n90-92\n87-89\n83-86\n80-82\n77-79\n73-76\n70-72\n60-69\n&lt;60\n\n\n\n\n\n\n\n\n\n\n‚ÄúA Wizard is never late, nor are they early. They arrive precisely when they mean to.‚Äù üßô‚Äç‚ôÇÔ∏è\n\nThanks Gandalf. Super helpful. Unfortunately, we are not wizards and late penalties will be applied to work that is not on time. There will be a 15% deduction on the first day. And a 5% increase for each day beyond the deadline. Work will not be accepted beyond 5 days after the deadline.\n\n\n\nRIT is committed to providing academic adjustments to students with disabilities. If you would like to request academic adjustments such as testing modifications due to a disability, please contact the Disability Services Office. Contact information for the DSO and information about how to request adjustments can be found at www.rit.edu/dso. After you receive academic adjustment approval, it is imperative that you contact me as early as possible so that we can work out whatever arrangement is necessary.\n\n\n\nAs an instructor, I¬†have a mandatory reporting responsibility¬†as a part of¬†my role. It is my goal that you feel comfortable sharing information related to your life experiences in classroom discussions, in your written work, and in our one-on-one meetings. I will seek to keep the information you share private to the greatest extent possible. However, I am required to¬†report information I¬†receive¬†regarding sexual misconduct or information about a crime that may have occurred during your time at RIT.¬†\n\n\n\nRIT is committed to providing a safe learning environment, free of harassment and discrimination as articulated in our university policies located on our governance website. RIT‚Äôs policies require faculty to share information about incidents of gender-based discrimination and harassment with RIT‚Äôs Title IX coordinator or deputy coordinators when incidents are stated to them directly. The information you provide to a non-confidential resource which includes faculty will be relayed only as necessary for the Title IX Coordinator to investigate and/or seek resolution. Even RIT Offices and employees who cannot guarantee confidentiality will maintain your privacy to the greatest extent possible.\nIf an individual discloses information during a public awareness event, a protest, during a class project, or advocacy event, RIT is not obligated to investigate based on this public disclosure. RIT may however use this information to further educate faculty, staff and students about prevention efforts and available resources.\nIf you would like to report an incident of gender based discrimination or harassment directly you may do so by using the online Sexual Harassment, Discrimination and Sexual Misconduct Reporting or anonymously by using the Compliance and Ethics Hotline. If you have a concern related to gender-based discrimination and/or harassment and prefer to have a confidential discussion, assistance is available from any of RIT‚Äôs confidential resources (listed below).\n\nRIT Counseling and Psychological Services\n\n585-475-2261 (V)\n585-475-6897 (TTY)\nwww.rit.edu/counseling\n\nNTID Counseling and Academic Advising\n\n585-475-6400\nwww.ntid.rit.edu/counselingdept\n\nRIT Student Health Center\n\n585-475-2255 (V)\nwww.rit.edu/studentaffairs/studenthealth\n\nCenter for Religious Life\n\n585-475-2137\nwww.rit.edu/studentaffairs/religion\n\nRIT Ombuds Office\n\n585-475-7357\n585-475-6424\n585-286-4677 (VP)\nwww.rit.edu/ombuds/contact-us\n\n\n\n\n\nAs an institution of higher learning, RIT expects students to behave honestly and ethically at all times, especially when submitting work for evaluation in conjunction with any course or degree requirement. The Department of Psychology encourages all students to become familiar with the RIT Honor Code and with RIT‚Äôs Academic Integrity Policy. RIT‚Äôs policy on academic integrity requires the instructor to investigate of any suspected breach of academic integrity. If the preponderance of evidence indicates a breach of academic integrity, the student who did so may incur a consequence up to and including failure for the entire course.\nAbout Generative AI\nYou may use generative AI tools (such as ChatGPT, Grammarly, or CoPilot) as a support for your work in this course. However:\n\nYou must personally review, edit, and take ownership of all submitted work.\nAny use of AI must be acknowledged in a brief note at the end of the assignment (e.g., ‚ÄúI used ChatGPT to generate initial bullet points for my resume, which I then revised and expanded.‚Äù) as well as being properly cited (RIT Library Citation Infoguide)\nAI tools may not be used to generate entire assignments without your input or to misrepresent your work. Submitting unedited or minimally edited AI output as your own is considered academic dishonesty.\nIn professional contexts, you will be expected to present work that is authentically your own ‚Äî this course is practice for that.\n\nIf I suspect that the work that you have turned in is using AI, we will have to have a conversation to determine the next steps. Turning in AI work is considered plagiarism, and you may be asked to re-do the assignment, or possibly receive a 0 on the assignment. Your information may also be submitted to the university as a Breach of Academic Integrity.\n\n\n\nRIT is committed to the safety of the RIT community and beyond. Because the situation is still in a rapid state of change, checking the RIT Ready website, and specifically the RIT Safety Plan for the most up to date information is recommended: https://www.rit.edu/ready/rit-safety-plan.\n\n\n\nI have provided this syllabus as a guide to our course and have made every attempt to provide an accurate overview of the course. However, as instructor, I reserve the right to modify this document during the semester, if necessary, to ensure that we achieve course learning objectives. You will receive advance notice of any changes to the syllabus through myCourses/email.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-plan",
    "href": "syllabus.html#course-plan",
    "title": "Syllabus",
    "section": "Course Plan",
    "text": "Course Plan\nThis is subject to change and instructor will inform the students as soon as possible.\n\nWeek 1 ‚Äî Getting Started with R & Tidy Data\n\nWe‚Äôll dive right into our primary tool, R. This session covers installing R and RStudio, navigating the interface, understanding R projects, and learning the foundational syntax of the R language and the tidyverse, including data types and basic functions.\n\nWeek 2 ‚Äî LABOR DAY (NO CLASS)\n\nContinue to develop skills and comfort in R. You will be provided with readings and other practice problems, and maybe a video lecture.\n\nWeek 3 ‚Äî Describing, Visualizing & Communicating\n\nWhat is in our data? We‚Äôll learn how to calculate descriptive statistics (e.g., mean, median, standard deviation) and master the ‚Äúgrammar of graphics‚Äù to create compelling, publication-quality plots with ggplot2. We will also introduce R Markdown for creating reproducible reports.\n\nWeek 4 ‚Äî Designing Studies & Sampling\n\nThis is a conceptual week focusing on the foundations of research. We‚Äôll discuss different research designs (experimental, correlational), sampling methods, the distinction between a sample and a population, and the fundamental logic of null hypothesis significance testing (NHST).\n\nWeek 5 ‚Äî Correlations & Effect Sizes\n\nWe‚Äôll quantify the relationship between two continuous variables using covariance and correlation. We will also introduce the concept of effect sizes as a standardized way to describe the magnitude of a relationship, moving beyond a simple ‚Äúyes/no‚Äù significance test. ‚ÄúHow strong is the association?‚Äù\n\nWeek 6 ‚Äî Comparing Groups\n\nWe‚Äôll explore classic methods for comparing group means, including independent and paired-samples t-tests. We‚Äôll conduct these tests in R and learn how to interpret their output. This will serve as our first formal hypothesis-testing tool.\n\nWeek 7 ‚Äî Building to Regression: Variability & Model Fit\n\nWe‚Äôll introduce the core logic of the General Linear Model by partitioning variance. Concepts like sums of squares will be introduced to help us understand how a model ‚Äúexplains‚Äù variance in an outcome variable. We will introduce R2 as a fundamental measure of model fit. ‚ÄúHow much of the outcome can we explain?‚Äù\n\n\n\n\nWeek 8 ‚Äî FALL BREAK (NO CLASS) üçÇ\n\n\n\nWeek 9 ‚Äî Simple Linear Regression\n\nThe formal introduction to the regression model: Yi‚Äã=Œ≤0‚Äã+Œ≤1‚ÄãXi‚Äã+œµi‚Äã. We will learn how to estimate the model‚Äôs parameters (intercept and slope), interpret their meaning, and assess overall model fit using the lm() function in R. ‚ÄúWhat is the exact formula for prediction?‚Äù\n\n\n\n\nWeek 10 ‚Äî Multiple Regression I: Adding Predictors\n\nWe‚Äôll expand our model to include multiple continuous predictors. Key topics include interpreting partial slopes (the effect of one predictor while controlling for others), understanding adjusted R2, and identifying issues like multicollinearity.\n\n\n\n\nWeek 11 ‚Äî Multiple Regression II: Categorical Predictors\n\nHow do we include groups (e.g., experimental conditions) in our regression model? We‚Äôll learn about dummy coding and indicator variables. This is where we will explicitly demonstrate that t-tests and ANOVA are simply special cases of regression.\n\n\n\n\nWeek 12 ‚Äî Assumptions + Model Diagnostics\n\nIs our model trustworthy? We will learn how to check the assumptions of ordinary least squares (OLS) regression, including linearity, normality of residuals, and homoscedasticity. We will use graphical methods in R to diagnose problems and discuss potential remedies.\n\n\n\n\nWeek 13 ‚Äî Expanding Regression\n\nTopics: We will explore ways to capture more complex relationships in our data. The primary focus will be on adding interaction terms to the model to test for moderation, but we may also touch on including non-linear relationships (e.g., quadratic terms) or talk about some mediation!\n\n\n\n\nWeek 14 ‚Äî Model Building + Comparison\n\nHow do we choose the best model? We will discuss practical strategies for building models, such as hierarchical regression, and learn how to use information criteria (like AIC and BIC) to compare different competing models.\n\n\n\n\nWeek 15 ‚Äî Making R work for you\n\nWe‚Äôve worked a whole lot with R, but what are some of the cool things that it can do. We will explore and organize what we have learned so far to solidify the use of R for reproducible workflows!\n\n\n\n\nWeek 16 ‚Äî Wrapping Up + Workshop\n\nThis final session will serve two purposes. First, it will be a dedicated workshop for you to get help and ask questions about your final projects. Second, we will have a course wrap-up, reviewing the major themes and discussing next steps for your statistical journey.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "class-activities/wk11_cat.html",
    "href": "class-activities/wk11_cat.html",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "",
    "text": "Download Week 10 Class ActivityFollow Along (.csv)\nData is taken from Cards Against Humanity - Pulse of the Nation\nDownload the data and move it to the correct folder so that you can access it in this activity.\nImport the data into your R file.\nFocus on having reproducible code! You will share your file with someone else. They should be able to run it.\n\n\n\nImport Data\nCheck descriptive statistics\nCreate a correlation plot for the continuous variables\nVisualize the relationship between # of Transformers Movies and Books\nConduct a multiple linear regression predict # of Transformers Movies.\nBriefly report the results\n\n\n\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "class-activities/wk11_cat.html#steps",
    "href": "class-activities/wk11_cat.html#steps",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "",
    "text": "Import Data\nCheck descriptive statistics\nCreate a correlation plot for the continuous variables\nVisualize the relationship between # of Transformers Movies and Books\nConduct a multiple linear regression predict # of Transformers Movies.\nBriefly report the results\n\n\n\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  },
  {
    "objectID": "class-activities/wk11_cat.html#steps-1",
    "href": "class-activities/wk11_cat.html#steps-1",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nIdentify your Outcome Variable and up to 3 predictor variables. Why did you choose your predictors?\nVisualize the relationship between 2 variables (with one being your Outcome)\nConduct a multiple linear regression to predict your outcome variable (3 predictors maximum)\nUse check_model to examine the model\nBriefly report the results"
  },
  {
    "objectID": "class-activities/wk11_cat.html#when-you-get-your-shared-files",
    "href": "class-activities/wk11_cat.html#when-you-get-your-shared-files",
    "title": "Week 10 Exercises - Multiple Regressions",
    "section": "When you get your shared files:",
    "text": "When you get your shared files:\n\nSave a Word doc in there that answers the following questions:\n\nYour Name:\nName of person who‚Äôs data/script you have:\nWere you able to run their code without modification?\nIf you did have to modify things, what did you have to do?\nOn a scale from 1 - 10 (10 being ‚Äúexcellent‚Äù), how would you rate the code that you received?"
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html",
    "href": "class-activities/wk3_desc-viz.html",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "",
    "text": "Goal: Work on importing data as well as being able to build a pipeline from descriptives to reporting to visualizing."
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#create-a-new-markdown-document",
    "href": "class-activities/wk3_desc-viz.html#create-a-new-markdown-document",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "Create a new Markdown Document",
    "text": "Create a new Markdown Document\n\nGo to File &gt; New File &gt; R Markdown\nProvide the title ‚ÄúDescribe & Visualize‚Äù and input your name as the author\nA script will open in the Source pane. Remove unnecessary code.\nGo to File &gt; Save and name it week3.Rmd. Make sure this saves in the same folder as all of your other stuff. Stay Organized!"
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#setting-it-up",
    "href": "class-activities/wk3_desc-viz.html#setting-it-up",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "Setting it up",
    "text": "Setting it up\n\nCreate a Code Chunk\nLoad the tidyverse, psych and sjPlot libraries (Install them if you need to)"
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#the-data",
    "href": "class-activities/wk3_desc-viz.html#the-data",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "The Data",
    "text": "The Data\nDownload Week 3 InClass Data (.csv)\nDownload the data and move it to the correct folder so that you can access it in this lab.\nYour dataset is from a larger study that was examining the overall impact of sleep on energy (and vice versa). Students in different areas across the country completed various questionnaires. The current data is a selection of overall sleep quality rating (0-100) and overall energy level (0-100) across all cities. You will be asked to examine these variables in a descriptive and visual way for your specific city.\nBreak up into your groups and work to visualize your assigned cities dataset.\n\n\n\nAlbuquerque\nChicago\nPittsburgh\n\n\nAtlanta\nDenver\nRochester\n\n\nBoston\nIthaca\nSacramento\n\n\nChampaign-Urbana\nMadison\nSeattle\n\n\n\nImport the data into your R file. I would suggest putting this line within the code chunk that you have your libraries in.\nFocus on having reproducible code! You may need to share your file with someone else. They should be able to run it."
  },
  {
    "objectID": "class-activities/wk3_desc-viz.html#questions",
    "href": "class-activities/wk3_desc-viz.html#questions",
    "title": "Week 3 Exercise - Describing & Visualizing",
    "section": "Questions",
    "text": "Questions\nWith the data that you have imported, follow the following steps and answer the questions along the way.\n\nNumber of Observations\n‚ùìAfter importing, how many total observations are there?\n‚úÖAnswer:\n\nThe dataset has all cities involved in the study. You only want to keep the data from your city. Create a new dataset that has only your city in it.\n\n\n\n\n\n\nTip\n\n\n\nWe‚Äôve used dplyr a lot to move our data around. Maybe it has something to do with select() or filter() or mutate()\n\n\n‚ùìHow many total observations are there in your new dataset (for your city)?\n‚úÖAnswer:\n\n\n\nCalculating Descriptives\nYou should now have 2 datasets (1 for the entire sample, and 1 for your city). Calculate and report the mean and standard deviation for your city. Then calcullate and report the mean and standard deviation for the whole sample.\n\n\n\nYour City\nTotal Sample\n\n\n\n\nSleep Mean:\nSleep Mean:\n\n\nSleep SD:\nSleep SD:\n\n\nEnergy Mean:\nEnergy Mean:\n\n\nEnergy SD:\nEnergy SD:\n\n\n\n‚ùìHow are the mean and standard deviations similar/different?\n‚úÖAnswer:\n\n\n\nReporting Descriptive Statistics\nNow that you have each of the pieces of information calculated for the entire sample and your specific city, you can report it in text. It is important to be able to report these basic descriptive statistics in a meaningful way, so we will practice it as often as possible. Here is an example:\n\nThe sample as a whole was relatively young (M = 19.22, SD = 3.45).\nThe average amount of drinks consumed was 3.37 (SD = 0.92).\n\n‚ùìReport the means and standard deviations in text for the two variables in your city sample.\n‚úÖAnswer:\n\n\n\nVisualizing\nWe have two variables and we would like to examine the relationship between them. Use a scatterplot to highlight the relationship between these two variables for your city.\nBe sure that your plot has a clear main title and clear labels for each axis.\n\n\n\n\n\n\nTip\n\n\n\nLook back to the lecture or past labs and pull in some of the ggplot code that you have! You can always re-use code.\n\n\n‚ùìDescribe the overall look of the data for your city.\n‚úÖAnswer:\n\nAs a class, we will review the different cities to see if we would be able to come to some broad conclusion.\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk4_beg-inf.html",
    "href": "class-activities/wk4_beg-inf.html",
    "title": "Week 4 Exercises - Intro to Inference",
    "section": "",
    "text": "Following Along with Professor\nDownload Week 4 Follow Along Data (.csv)\nDownload the data and move it to the correct folder so that you can access it in this activity.\nWe‚Äôve been hired as consultants for the university‚Äôs graduate school. They are concerned about student burnout and have given us some anonymous pilot data to explore potential factors. Our job is to be the data detectives.\nImport the data into your R file. I would suggest putting this line within the code chunk that you have your libraries in.\nFocus on having reproducible code! You may need to share your file with someone else. They should be able to run it.\n\n\n\nOn Your Own\nGoal: Work individually or in small groups to apply the concepts from today‚Äôs lecture and demo to a new dataset.\n\nObjectives:\n\nIdentify predictor and outcome variables from a research question.\nUse the ‚Äúdecision tree‚Äù to select the correct family of statistical models.\nCreate an appropriate visualization (ggplot).\nRun the correct statistical test (t.test or cor.test).\nWrite a one-sentence conclusion synthesizing the results.\n\n\n\nThe Scenario & Dataset\nA developmental psychology lab is exploring factors related to children‚Äôs well-being. They have collected pilot data from 100 children.\nDownload Child Well-Being Data (.csv)\nPlease download the child_wellbeing.csv file (above). It contains the following variables:\n\nchild_id: A unique identifier for each child.\nparenting_style: The primary parenting style observed in the home (Categorical: ‚ÄúAuthoritative‚Äù or ‚ÄúPermissive‚Äù).\nsleep_hours: The average number of hours the child sleeps per night (Continuous).\nanxiety_score: A score from 0-50 on a parent-report measure of the child‚Äôs anxiety (Continuous).\n\n\n\nInstructions:\n\nCreate a new R Markdown file titled week4_inclass.Rmd.\nLoad the appropriate libraries.\nLoad the child_wellbeing.csv dataset.\nFor each task below, write the R code and answer the questions.\n\n\n\nTask 1: Parenting Style and Anxiety\nThe Research Question: ‚ÄúDo children raised in homes with an authoritative parenting style have different anxiety levels than children in homes with a permissive style?‚Äù\nYour Steps:\n\nIdentify: What is the predictor (IV)? What is the outcome (DV)? Are they categorical or continuous?\nModel: Based on your answer, what is the correct model family (t-test/ANOVA or Correlation/Regression)? Write out the specific model using R formula syntax (outcome ~ predictor).\nVisualize: Create a boxplot to visualize the relationship between parenting_style and anxiety_score.\nAnalyze: Run the appropriate statistical test in R to test your model.\nConclude: Look at the p-value and the group means from your analysis. Write one clear sentence summarizing your finding (e.g., ‚ÄúWe found that children with authoritative parents had significantly higher/lower anxiety scores than children with permissive parents, p = ‚Ä¶‚Äù).\n\n\n\nTask 2: Sleep and Anxiety\nThe Research Question: ‚ÄúIs there an association between the average number of hours a child sleeps per night and their anxiety level?‚Äù\nYour Steps:\n\nIdentify: What is the predictor (IV)? What is the outcome (DV)? Are they categorical or continuous?\nModel: What is the correct model family? Write out the specific model using R formula syntax.\nVisualize: Create a scatterplot to visualize the relationship between sleep_hours and anxiety_score. Add a line of best fit.\nAnalyze: Run the appropriate statistical test in R.\nConclude: Look at the p-value and the correlation coefficient (r). Write one clear sentence summarizing your finding (e.g., ‚ÄúWe found a significant positive/negative association between hours of sleep and anxiety scores, r = ‚Ä¶, p = ‚Ä¶‚Äù).\n\n\n\nü§î Challenge Question (If you finish early)\nBased on the design of this study (it is observational), can the researcher conclude that permissive parenting causes higher anxiety? In one or two sentences, explain why or why not, and propose one possible confounding variable that could be influencing both parenting style and a child‚Äôs anxiety\n\nEnd of the document. Remember to Knit and upload the html and .Rmd to myCourses."
  },
  {
    "objectID": "class-activities/wk7_reg.html",
    "href": "class-activities/wk7_reg.html",
    "title": "Week 7 Exercises - Regressions",
    "section": "",
    "text": "Objective: To introduce the fundamentals of simple linear regression by collecting, visualizing, and modeling data. The core question we will explore is: Can we predict the price of a LEGO set from its number of pieces?\n\n\nFirst, go to the LEGO website and identify a set that you like. Navigate to this Google Form and submit the following information:\n\nName of the Set\nSet Number\n# of Pieces\nPrice\n\n\n\n\nNext, we inspect the data and check the descriptives.\n\n\n\nNow we can create a scatterplot between our variables of interest.\n\n\n\nFinally, we create the model and interpret the output.\n\n\n\n\nGiven our model, how much would a set with 1,031 pieces cost?\nNext year, a new set is expected to be released that has 250 pieces and cost $99. Where would this fit into our figure? What could explain this deviation from our model?"
  },
  {
    "objectID": "class-activities/wk7_reg.html#collect-the-data",
    "href": "class-activities/wk7_reg.html#collect-the-data",
    "title": "Week 7 Exercises - Regressions",
    "section": "",
    "text": "First, go to the LEGO website and identify a set that you like. Navigate to this Google Form and submit the following information:\n\nName of the Set\nSet Number\n# of Pieces\nPrice"
  },
  {
    "objectID": "class-activities/wk7_reg.html#inspect-data",
    "href": "class-activities/wk7_reg.html#inspect-data",
    "title": "Week 7 Exercises - Regressions",
    "section": "",
    "text": "Next, we inspect the data and check the descriptives."
  },
  {
    "objectID": "class-activities/wk7_reg.html#visualize",
    "href": "class-activities/wk7_reg.html#visualize",
    "title": "Week 7 Exercises - Regressions",
    "section": "",
    "text": "Now we can create a scatterplot between our variables of interest."
  },
  {
    "objectID": "class-activities/wk7_reg.html#run-the-model",
    "href": "class-activities/wk7_reg.html#run-the-model",
    "title": "Week 7 Exercises - Regressions",
    "section": "",
    "text": "Finally, we create the model and interpret the output."
  },
  {
    "objectID": "class-activities/wk7_reg.html#questions",
    "href": "class-activities/wk7_reg.html#questions",
    "title": "Week 7 Exercises - Regressions",
    "section": "",
    "text": "Given our model, how much would a set with 1,031 pieces cost?\nNext year, a new set is expected to be released that has 250 pieces and cost $99. Where would this fit into our figure? What could explain this deviation from our model?"
  },
  {
    "objectID": "class-activities/wk7_reg.html#steps",
    "href": "class-activities/wk7_reg.html#steps",
    "title": "Week 7 Exercises - Regressions",
    "section": "Steps:",
    "text": "Steps:\n\nImport Data\nCheck descriptive statistics\nCreate a correlation plot for the continuous variables\nVisualize the relationship between # of Transformers Movies and Books\nConduct a linear regression\nReport the results\n\n\nItems in the Data:\n\n\n\n\n\n\n\nVar Name\nInfo\n\n\n\n\nid\nStudy ID\n\n\nIncome\nOverall income\n\n\nSex\nSex\n\n\nAge\nAge\n\n\nAge Range\nAge given in ranges\n\n\nPolitical Affiliation\nPolitical Affiliation\n\n\nEducation\nWhat is your highest level of education?¬†\n\n\nethnicity\nWhat is your race?\n\n\nmarrital status\nWhat is your marital status?\n\n\nclimate change\nDo you believe that climate change is real and caused by people, real but not caused by people, or not real at all?\n\n\nTransformers\nHow many Transformers movies have you seen?¬†\n\n\nbooks\nHow many books, if any, have you read in the past year?\n\n\nghosts\nDo you believe in ghosts?\n\n\nspending\nIs federal funding of scientific research too high, too low, or about right?\n\n\nchoice\nIf you had to choose: would you rather be smart and sad, or dumb and happy?\n\n\nshower_pee\nDo you think it is acceptable or unacceptable to urinate in the shower?"
  }
]