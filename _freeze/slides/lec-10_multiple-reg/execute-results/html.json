{
  "hash": "d5e6351046cf99422d5c4e5d00f50e39",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 10: Multiple Regression\"\nsubtitle: \"Date: October 27, 2025\"\nfooter:  \"[course-website](https://dharaden.github.io/psyc640/)\"\nlogo: \"images/640_hex.png\"\nformat: \n  revealjs:\n    theme: clean.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    overview: false\n    scrollable: true\n    code-line-numbers: true\neditor: visual\nexecute:\n  echo: true\n  freeze: auto\n---\n\n## Today...\n\n<https://bsky.app/profile/andrew.heiss.phd/post/3ly6hqr3mtk2z>\n\n![](/images/p-values.jpg){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Don't know if I'm using all of these, but including theme here anyways\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\nlibrary(easystats)\nlibrary(patchwork)\n\n\n#Remove Scientific Notation \noptions(scipen=999)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Regression\n\n**3 main reasons for using regression:**\n\n1.  As a description (what is the average salary for men and women?)\n2.  As part of causal inference (Does being a woman result in a lower salary?)\n3.  For prediction (\"What happens if...\" questions)\n\n------------------------------------------------------------------------\n\n### Regression\n\nOverall, we are providing a model to give us a \"best guess\" on predicting our outcome\n\n$$ Y_i = b_0 + b_1X_i + e_i $$\n\n------------------------------------------------------------------------\n\n## Explaining Variance\n\n![](/images/predict_var.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Explaining Variance\n\n![](images/clipboard-2717803324.png)\n\n------------------------------------------------------------------------\n\n### Explaining Variance\n\n![](images/clipboard-3448148790.png)\n\n------------------------------------------------------------------------\n\n## Model Interpretation\n\nOnce we have a model, we will be able to interpret the coefficients. For a bivariate regression, this was fairly straightforward\n\nWe would look to the beta (effect size) and interpret it as: ***for every 1 unit increase in our X variable, there will be beta units increase in our Y variable.***\n\n------------------------------------------------------------------------\n\n## Regressions\n\nWe may want to include additional predictors into our model to best explain the variance in an outcome:\n\n$$ Y_i = b_0 + b_1X_{1i} + b_2X_{2i} + ... + b_nX_{ni}+ e_i $$\n\n------------------------------------------------------------------------\n\n### Explaining Variance\n\n![](images/clipboard-4102854469.png)\n\n------------------------------------------------------------------------\n\n## Fire Data Example\n\nWe have been contracted by the county to examine their Fire Department. We have been provided with the data below, and asked to examine what may be related to how expensive a fire costs.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# --- Step 1: Simulate the Data ---\nset.seed(123) # for reproducibility\nn <- 300 # number of fires\n\n# Create three distinct groups for fire size\nfire_sizes <- sample(c(\"Small\", \"Medium\", \"Large\"), n, replace = TRUE, prob = c(0.4, 0.3, 0.3))\n\n# Simulate our variables based on fire size\nfire_data <- tibble(size = factor(fire_sizes, levels = c(\"Small\", \"Medium\", \"Large\"))) %>%\n  mutate(\n    # The bigger the fire, the more trucks are sent.\n    num_trucks = case_when(\n      size == \"Small\"  ~ round(rnorm(n(), 2, 0.5)),\n      size == \"Medium\" ~ round(rnorm(n(), 5, 1)),\n      size == \"Large\"  ~ round(rnorm(n(), 9, 1.5))\n    ),\n    # For a given size, more trucks -> less damage (the true effect)\n    # But bigger size -> more damage (the confounding effect)\n    damage_amount = case_when(\n      size == \"Small\"  ~ 20 - 2 * num_trucks + rnorm(n(), 0, 5),\n      size == \"Medium\" ~ 80 - 3 * num_trucks + rnorm(n(), 0, 8),\n      size == \"Large\"  ~ 150 - 4 * num_trucks + rnorm(n(), 0, 12)\n    )\n  ) %>%\n  # ensure no negative values\n  filter(num_trucks > 0, damage_amount > 0)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(fire_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 3\n$ size          <fct> Small, Medium, Large, Medium, Medium, Small, Large, Medi…\n$ num_trucks    <dbl> 2, 6, 10, 6, 6, 2, 11, 5, 6, 9, 6, 10, 10, 6, 2, 6, 2, 2…\n$ damage_amount <dbl> 17.65717, 50.53150, 126.92287, 69.08090, 69.22461, 18.92…\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Fire Data: Relationship\n\nLet's start by examining the relationship between \\# of firetrucks and the damage of the fire\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(fire_data, aes(x = num_trucks, y = damage_amount)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n  labs(\n    title = \"Plot 1: Fire Trucks and Damage\",\n    x = \"Number of Fire Trucks\",\n    y = \"Damage Amount (in $1000s)\"\n  ) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n#### Bivariate relationship\n\nThis relationship can also be represented by a correlation, or a regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(fire_data$num_trucks, fire_data$damage_amount)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  fire_data$num_trucks and fire_data$damage_amount\nt = 32.093, df = 298, p-value < 0.00000000000000022\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8524507 0.9037853\nsample estimates:\n      cor \n0.8806778 \n```\n\n\n:::\n\n```{.r .cell-code}\n## OR\nfire.lm1 <- lm(damage_amount ~ num_trucks, data = fire_data)\nsummary(fire.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = damage_amount ~ num_trucks, data = fire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-64.534 -10.946  -3.153   9.694  67.540 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(>|t|)    \n(Intercept)   0.1458     2.2072   0.066               0.947    \nnum_trucks   11.6731     0.3637  32.093 <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.15 on 298 degrees of freedom\nMultiple R-squared:  0.7756,\tAdjusted R-squared:  0.7748 \nF-statistic:  1030 on 1 and 298 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n#### Bivariate relationship\n\nBased on the visualization, the correlation and the regression, what would we conclude from this analysis?\n\n------------------------------------------------------------------------\n\n#### Bivariate relationship\n\nBased on the visualization, the correlation and the regression, what would we conclude from this analysis?\n\n> A linear regression was used to examine the impact of number of trucks on the scene and the amount of damage that was done by a fire. The number of trucks positively impacted the damage done by the fire (*b* = 11.67, *p* \\< .001), suggesting that as more trucks are present, the fire does more damage.\n\nWould we be able to say that \\# trucks *causes* the damage? Therefore, our suggestion to the county would be to send less trucks to each of the fires. Case closed\n\n------------------------------------------------------------------------\n\n### Fire Data: Multivariate Relationship\n\nThere is a third variable that we haven't incorporated. Let's take that information into account when we are looking at the visualization:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Plot 2\nfire_data %>% \n  ggplot(aes(x = num_trucks, y = damage_amount, color = size)) +\n    geom_point(alpha = 0.7) +\n    scale_color_manual(values = c(\"Small\" = \"green\", \n                                  \"Medium\" =   \"orange\", \n                                  \"Large\" = \"red\")) +\n    labs(\n      title = \"Plot 2: Firetrucks & Damage by Size\",\n      x = \"Number of Fire Trucks\",\n      y = \"Damage Amount (in $1000s)\",\n      color = \"Fire Size\"\n    ) +\n    theme_bw()\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n#### Fire Data: Multivariate Relationship\n\nThat seems to make more sense. Let's add in the lines of best fit too\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| code-fold: true\n\n# Plot 3: The \"Controlled\" Relationship (Simpson's Paradox)\nfire_data %>% \n  ggplot(aes(x = num_trucks, y = damage_amount, color = size)) +\n    geom_point(alpha = 0.5) +\n    # Fit a line FOR EACH GROUP to show the true relationship\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(\n      title = \"Plot 3: The Controlled Relationship\",\n      x = \"Number of Fire Trucks\",\n      y = \"Damage Amount (in $1000s)\",\n      color = \"Fire Size\"\n    ) +\n    theme_bw()\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n#### Fire Data: Multivariate Relationship\n\nLet's see what the multiple regression brings us\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfire.lm2 <- lm(damage_amount ~ num_trucks + size,\n               data = fire_data)\nsummary(fire.lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = damage_amount ~ num_trucks + size, data = fire_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.7451  -4.6995  -0.2433   4.4801  29.3847 \n\nCoefficients:\n            Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)  22.5340     1.1616  19.399 < 0.0000000000000002 ***\nnum_trucks   -3.4136     0.4328  -7.886   0.0000000000000604 ***\nsizeMedium   59.5122     1.8224  32.656 < 0.0000000000000002 ***\nsizeLarge   122.3535     3.2873  37.220 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.431 on 296 degrees of freedom\nMultiple R-squared:  0.961,\tAdjusted R-squared:  0.9606 \nF-statistic:  2430 on 3 and 296 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\nNow we can write it up\n\n------------------------------------------------------------------------\n\n### Fire Data: Formal Writeup\n\n\"The current set of analyses sought to examine the influence of the number of firetrucks on the scene and the amount of damage that a fire caused, controlling for the size of the fire. The number of firetrucks present were regressed on the damage amount (in \\\\\\$1,000s) and the size of the fire. The overall multiple regression was statistically significant ( $R^2$ = .96, *p* \\< .001), and the two variables (Number of Trucks and Size of the Fire) accounted for 96% of the variance in damage done. Each of the two independent variables also had a statistically significant effect on damage (*p's* \\< .001). The number of trucks was negatively related to the amount of damage done (*b* = -3.41), meaning that for each additional truck that was on the scene, there was a \\$3,410 reduction in damage, controlling for the size of the fire. Additionally, the size of the fire increased the amount of damage at Medium (*b =* 59.51) and Large (*b =*122.35).\"\n\n------------------------------------------------------------------------\n\n## Reporting Standardized or Unstandardized?\n\n**INTERPRET *b***:\n\n-   When the variables are measured in a meaningful metric\n\n-   To develop intervention or policy implications\n\n-   To compare effects across samples or studies\n\n**INTERPRET *β***:\n\n-   When the variables are not measured in a meaningful metric\n\n-   To compare the relative effects of different predictors in the same sample\n\n------------------------------------------------------------------------\n\n## Goldilocks Problem\n\nModels that are underfit, overfit or just-right\n\n![](images/clipboard-699917906.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n## Another Example: Computer time & Frustration\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Step 1: Simulate the Data \nn <- 150 # Number of students\n\n# Simulate total daily computer use in hours\ncomputer_use <- rnorm(n, mean = 6, sd = 1.5)\n\n# Simulate hours spent on stats homework, now as a whole number\nstats_homework <- round(0.7 * computer_use + rnorm(n, 0, 1))\n# Ensure no negative values after rounding\nstats_homework[stats_homework < 0] <- 0\nstats_homework[stats_homework > computer_use] <- 1\n\n# Simulate frustration level (driven mostly by stats homework)\n# Scale of 1-100\nfrustration <- 10 + (2 * computer_use) + (8 * stats_homework) + rnorm(n, 0, 10)\n\n# Create a dataframe and clean up any impossible values\nstudent_data <- tibble(\n  frustration = frustration,\n  computer_use = computer_use,\n  stats_homework = stats_homework\n) %>%\n  filter(frustration > 0, computer_use > 0)\n\n# Bin the 'stats_homework' variable\nstudent_data <- student_data %>%\n  mutate(\n    stats_homework_bin = cut(stats_homework,\n                           breaks = quantile(stats_homework, probs = seq(0, 1, by = 1/3)),\n                           include.lowest = TRUE,\n                           labels = c(\"Low\", \"Medium\", \"High\"))\n  )\n```\n:::\n\n\nWe have collected data on graduate students and their weekly frustration levels. Data that were also collected included the amount of time they were spending on their computer as well as the amount of statistics homework that they had.\n\n------------------------------------------------------------------------\n\n### Frustration Model\n\nTaking a bivariate look at things, we might have an initial model like this:\n\n$$\nFrustration=b_0 + b_1Comp.Hours + e_i\n$$\n\n------------------------------------------------------------------------\n\n### Frustration Model\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- student_data %>%\n  ggplot(aes(x = computer_use, y = frustration)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"darkorange\") +\n  labs(\n    title = \"Frustration & Computer Use\",\n    subtitle = \"Linear Fit\",\n    x = \"Daily Computer Use (Hours)\",\n    y = \"Frustration Level (1-100)\"\n  ) +\n  theme_minimal()\n\np2 <- student_data %>%\n  ggplot(aes(x = computer_use, y = frustration)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"loess\",\n              se = FALSE,\n              color = \"darkorange\") +\n  labs(\n    title = \"Frustration & Computer Use\",\n    subtitle = \"Loess Fit\",\n    x = \"Daily Computer Use (Hours)\",\n    y = \"Frustration Level (1-100)\"\n  ) +\n  theme_minimal()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Side Quest: Model Assumptions\n\n1.  **Linearity** - A linear relationship exists between predictors and outcome\n2.  **Multicollinearity** - The variables are minimally related to one another (VIF)\n3.  **Independence of Observations** - Each observation in the model is independent of one another\n4.  **Homoscedasticity of Residuals** - Residuals have constant variance across all points of the model\n5.  **Multivariate Normality** - Residuals of the model are normally distributed (QQ Plots)\n\nAll of these are checked when using `check_model()` within the `easystats` library\n\n------------------------------------------------------------------------\n\n### Frustration Model: lm()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrus.lm1 <- lm(frustration ~ computer_use, data = student_data)\nsummary(frus.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = frustration ~ computer_use, data = student_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.546  -7.090  -0.833   6.922  39.571 \n\nCoefficients:\n             Estimate Std. Error t value            Pr(>|t|)    \n(Intercept)    9.3538     4.3697   2.141              0.0339 *  \ncomputer_use   7.4389     0.7171  10.373 <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.16 on 148 degrees of freedom\nMultiple R-squared:  0.421,\tAdjusted R-squared:  0.4171 \nF-statistic: 107.6 on 1 and 148 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Frustration Model: Multivariate\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(student_data, aes(x = computer_use, y = frustration, color = stats_homework_bin)) +\n  geom_point(alpha = 0.8, size = 2) +\n  labs(\n    title = \"Frustration & Computer Use by Stats\",\n    x = \"Daily Computer Use (Hours)\",\n    y = \"Frustration Level (1-100)\",\n    color = \"Stats HW (Hours)\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Frustration Model: Multivariate\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nstudent_data %>% \n  ggplot(aes(x = computer_use, y = frustration, \n             color = stats_homework_bin)) +\n    geom_point(alpha = 0.5) +\n    # Fit a line FOR EACH GROUP to show the true relationship\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(\n      title = \"Frustration & Computer Use by Stats\",\n      x = \"Daily Computer Use (Hours)\",\n      y = \"Frustration Level (1-100)\",\n      color = \"Stats HW (Hours)\"\n    ) +\n    theme_bw()\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Frustration Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfrus.lm2 <- lm(frustration ~ computer_use + stats_homework,\n               data = student_data)\nsummary(frus.lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = frustration ~ computer_use + stats_homework, data = student_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-27.6099  -6.5164   0.1487   6.5067  30.7120 \n\nCoefficients:\n               Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)      11.800      3.524   3.349              0.00103 ** \ncomputer_use      1.861      0.844   2.205              0.02900 *  \nstats_homework    7.702      0.851   9.050 0.000000000000000792 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.779 on 147 degrees of freedom\nMultiple R-squared:  0.6282,\tAdjusted R-squared:  0.6231 \nF-statistic: 124.2 on 2 and 147 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Comparing Models\n\nMaybe we would like to test to see if including the Stats Homework variable improved the model\n\nSince the first regression is *nested* within the second, we can run an ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(frus.lm1, frus.lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: frustration ~ computer_use\nModel 2: frustration ~ computer_use + stats_homework\n  Res.Df   RSS Df Sum of Sq      F                Pr(>F)    \n1    148 21892                                              \n2    147 14059  1    7833.5 81.907 0.0000000000000007916 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n| Statistic | Meaning | Interpretation |\n|----|----|----|\n| `Res.Df` (Residual Degrees of Freedom) | Remaining degrees of freedom after estimating parameters | 148 for Model 1, 147 for Model 2 (one more parameter estimated) |\n| `RSS` (Residual Sum of Squares) | Total unexplained variance by the model | Decreases substantially from 24,468 → 13,620 with the new predictor, showing improved fit |\n| `Df` (Difference in df) | Number of parameters added | 1 (adding `stats_homework`) |\n| `Sum of Sq` (Difference in RSS) | Variance explained by the added predictor | 10,848 units of variance explained by `stats_homework` |\n| `F` | F-statistic testing whether this variance reduction is significant | 117.07 — very large, meaning substantial improvement |\n| `Pr(>F)` | p-value associated with F |  |\n\n------------------------------------------------------------------------\n\n## Model Assumptions: Frustration\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(frus.lm2)\n```\n\n::: {.cell-output-display}\n![](lec-10_multiple-reg_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Model Assumptions\n\n1.  **Linearity** - A linear relationship exists between predictors and outcome\n    1.  Apply Transformation (square root or log); Drop the variable\n2.  **Multicollinearity** - The variables are minimally related to one another (VIF)\n    1.  Remove variable; different type of regression (lasso, partial least squares)\n3.  **Independence of Observations** - Each observation in the model is independent of one another\n    1.  Dummy coding, lags; Use MLM\n4.  **Homoscedasticity of Residuals** - Residuals have constant variance across all points of the model\n    1.  Apply Transformation (square root or log);\n5.  **Multivariate Normality** - Residuals of the model are normally distributed (QQ Plots)\n    1.  Check for outliers; Apply Transformation (square root or log)\n\n------------------------------------------------------------------------\n\n# \n",
    "supporting": [
      "lec-10_multiple-reg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}