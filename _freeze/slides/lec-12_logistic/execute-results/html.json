{
  "hash": "a8c8ffcbcbce78e27d4580912815ef90",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 12: Categorical & Logistic Regression\"\nsubtitle: \"Date: November 10, 2025\"\nfooter:  \"[course-website](https://dharaden.github.io/psyc640/)\"\nlogo: \"images/640_hex.png\"\nformat: \n  revealjs:\n    theme: clean.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    overview: false\n    scrollable: true\n    code-line-numbers: true\neditor: visual\nexecute:\n  echo: true\n  freeze: auto\n---\n\n## Today...\n\n-   Some helpful tools (autosave & new library)\n\n-   Regression Review\n\n-   Categorical Predictors Review\n\n-   Logistic Regression\n\n-   Model Diagnostics\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\nlibrary(lm.beta)\nlibrary(easystats)\nlibrary(sjPlot)\n\n\n#Remove Scientific Notation \noptions(scipen=999)\n\n#Import CAH Data\ncah_data <- import(here(\"files\", \"data\", \n                        \"CAH.csv\")) %>% \n  mutate(across(where(is.character), ~na_if(., \"\")))\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Autosave\n\n**Tools \\>\\> Global Options \\>\\> Code \\>\\> Saving**\n\n![](images/clipboard-747997202.png)\n\n------------------------------------------------------------------------\n\n## New Library: `genzplyr`\n\n![](images/clipboard-1232526481.png)\n\n> dplyr but make it bussin fr fr no cap\n\n[genzplyr üíÖ](https://hadley.github.io/genzplyr/){target=\"_blank\"}\n\n------------------------------------------------------------------------\n\nRegression does a vibe check on the data. lowkey draw a line through the points.\n\n------------------------------------------------------------------------\n\n## Regression\n\n***What is the equation for a regression??***\n\n------------------------------------------------------------------------\n\n## Regression\n\n$$ Y_i = b_0 + b_1X_{1i} + b_2X_{2i} + ... + b_nX_{ni}+ e_i $$\n\n------------------------------------------------------------------------\n\n## Regression\n\n***How do we interpret the regression coefficients (Intercepts & slopes)?***\n\n------------------------------------------------------------------------\n\n## Regression\n\n[**INTERCEPT:**]{.underline} When all predictor variables are set to 0, our expected value (predicted $\\hat{Y}$) will be this value.\n\n[**SLOPES:**]{.underline} For every 1 unit change in our $X_n$ variable, there will be beta (b or $\\beta$) units increase in our Y (outcome) variable, [***holding all other variables constant***]{.underline}***.***\n\n------------------------------------------------------------------------\n\n### Explaining Variance\n\n![](images/clipboard-3448148790.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Explaining Variance\n\n![](images/clipboard-4102854469.png){fig-align=\"center\"}\n\n# What do we do with categorical variables as predictors?\n\n![](images/clipboard-1169136778.jpeg){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n## Categorical Predictors = factors\n\nTypically identified by a grouping variable that may be a `character`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(cah_data$political_affiliation)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n chr [1:1000] \"Democrat\" \"Democrat\" \"Independent\" \"Republican\" \"Democrat\" ...\n```\n\n\n:::\n:::\n\n\nNeed to change the variable from `character` to `factor` which will assign a number to each group\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncah_data <- cah_data %>%\n  mutate(\n    pol = as.factor(political_affiliation),\n    ghosts = as.factor(ghosts)\n    )\n\nglimpse(cah_data$pol)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Factor w/ 3 levels \"Democrat\",\"Independent\",..: 1 1 2 3 1 1 2 3 3 1 ...\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Dummy Coding (replacing factors)\n\nNumerical placeholders used to represent categorical variables\n\nTaking a categorical variable with $k$ levels (e.g., `Democratic`, `Independent`, `Republican`) into $k-1$ binary variables.\n\n| political_affiliation | *becomes* | Ind (binary1) | Rep (binary2) |\n|-----------------------|-----------|---------------|---------------|\n| Democrat              | --\\>      | 0             | 0             |\n| Independent           | --\\>      | 1             | 0             |\n| Republican            | --\\>      | 0             | 1             |\n| ...                   |           | ...           | ...           |\n\n------------------------------------------------------------------------\n\n### Dummy Coding\n\nFor the variable with $k$ levels, we use $k-1$ binary variables...why not use all of them?\n\n::: incremental\n-   Including all three variables would result in perfect multicollinearity. All Democrats would be related to other Democrats and unrelated to everything else\n\n-   By including 2 binary variables, we are able to obtain all information about group membership\n:::\n\n------------------------------------------------------------------------\n\n### Dummy Coding\n\nThe group that has 0's for all the binary variables is the **reference group**\n\nFor interpretation, we will make our statements in reference to this group\n\n| political_affiliation | *becomes* | Ind (binary1) | Rep (binary2) |\n|-----------------------|-----------|---------------|---------------|\n| Democrat              | --\\>      | 0             | 0             |\n| Independent           | --\\>      | 1             | 0             |\n| Republican            | --\\>      | 0             | 1             |\n| ...                   |           | ...           | ...           |\n\n------------------------------------------------------------------------\n\n## Categorical Regression\n\nGoing back to our Transformers dataset, let's see how our political affiliation variable can predict \\# of transformers movies\n\nUsually you have to create the separate dummy variables, but not in R. As long as your predictor is set as a `factor`, R will automatically dummy code the variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat1 <- lm(transformers ~ pol,\n           data = cah_data)\n```\n:::\n\n\nYou can also double check the dummy/contrast coding\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(cah_data$pol)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Independent Republican\nDemocrat              0          0\nIndependent           1          0\nRepublican            0          1\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Interpretation\n\nWe are shown the different levels of our predictor variable, but you will not see a predictor for the reference group...this is the intercept!\n\nEvery interpretation is ALWAYS in reference to the reference group\n\nGo to next slide for a pretty table\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(cat1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = transformers ~ pol, data = cah_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3447 -1.1804 -0.3447  0.8196  3.8367 \n\nCoefficients:\n               Estimate Std. Error t value            Pr(>|t|)    \n(Intercept)     1.18039    0.09399  12.559 <0.0000000000000002 ***\npolIndependent  0.16434    0.12349   1.331               0.184    \npolRepublican  -0.01713    0.14257  -0.120               0.904    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.501 on 799 degrees of freedom\n  (198 observations deleted due to missingness)\nMultiple R-squared:  0.003244,\tAdjusted R-squared:  0.0007487 \nF-statistic:   1.3 on 2 and 799 DF,  p-value: 0.2731\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Interpretation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(cat1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">transformers</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.00&nbsp;&ndash;&nbsp;1.36</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol [Independent]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.08&nbsp;&ndash;&nbsp;0.41</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.184</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol [Republican]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.30&nbsp;&ndash;&nbsp;0.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.904</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">802</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.003 / 0.001</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Interpretation (text)\n\nA linear regression investigated the relationship between political affiliation and number of transformers movies watched. Democrats showed a significant difference from 0 (b = 1.18, *p* \\< .001), but there was not a significant difference between Democrats and Independents (*p* = .18) or Democrats and Republicans (*p* = .90). The findings suggest that there are no significant differences between groups.\n\n::: callout-note\nHow does this sound?\n:::\n\n------------------------------------------------------------------------\n\n### Changing the Reference Group\n\nMaybe we want to compare to a specific group\n\nWe need to then update the reference group\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncah_data$pol2 <- relevel(cah_data$pol, ref = \"Independent\")\ncat2 <- lm(transformers ~ pol2,\n           data = cah_data)\nsummary(cat2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = transformers ~ pol2, data = cah_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3447 -1.1804 -0.3447  0.8196  3.8367 \n\nCoefficients:\n               Estimate Std. Error t value            Pr(>|t|)    \n(Intercept)     1.34473    0.08011  16.786 <0.0000000000000002 ***\npol2Democrat   -0.16434    0.12349  -1.331               0.184    \npol2Republican -0.18146    0.13383  -1.356               0.175    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.501 on 799 degrees of freedom\n  (198 observations deleted due to missingness)\nMultiple R-squared:  0.003244,\tAdjusted R-squared:  0.0007487 \nF-statistic:   1.3 on 2 and 799 DF,  p-value: 0.2731\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### `lm()` or `aov()` ?\n\nWe have the same setup between a linear model and a one-way ANOVA.\n\n$$\nOutcome_{continuous} = Predictor_{categorical} + error\n$$\n\nWhy would we pick one over another?\n\n-   If we have a reason to have a reference group ‚Äì\\> **Regression**\n\n    -   Maybe we have a control group\n\n-   If we just expect a difference somewhere ‚Äì\\> **ANOVA**\n\n    -   When you are predicting \\# movies from political affiliation\n\n------------------------------------------------------------------------\n\n# Everything is a linear model {.center}\n\n![](images/clipboard-3428257228.gif)\n\n# Break ‚òïüçµü•ê\n\n------------------------------------------------------------------------\n\n## Categories in Action (last time)\n\n**Goal:** Gain greater familiarity with dummy coding and categorical predictors\n\n**Scenario:** We are researchers examining the impact of a new intervention on reducing the vocalization \"6Ô∏è‚É£7Ô∏è‚É£\" in the youths. We have done classroom observations to collect data on how many times students say \"6Ô∏è‚É£7Ô∏è‚É£\" after receiving the intervention. Youths have been randomly assigned to one of 3 groups, and we need to determine which had the biggest impact.\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsix_seven <- import(here(\"files\", \"data\", \n                         \"cat_reg_complete.xlsx\")) %>% \n  janitor::clean_names()\n\nsix_seven %>% \n  slice_sample(n=5) %>% \n  tab_df()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:italic; font-weight:normal; padding:0.2cm; border-bottom:1px solid black; text-align:left; \">id</th>\n<th style=\"border-top: double; text-align:center; font-style:italic; font-weight:normal; padding:0.2cm; border-bottom:1px solid black; \">school</th>\n<th style=\"border-top: double; text-align:center; font-style:italic; font-weight:normal; padding:0.2cm; border-bottom:1px solid black; \">group</th>\n<th style=\"border-top: double; text-align:center; font-style:italic; font-weight:normal; padding:0.2cm; border-bottom:1px solid black; \">pre_score</th>\n<th style=\"border-top: double; text-align:center; font-style:italic; font-weight:normal; padding:0.2cm; border-bottom:1px solid black; \">post_score</th>\n<th style=\"border-top: double; text-align:center; font-style:italic; font-weight:normal; padding:0.2cm; border-bottom:1px solid black; \">age</th>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">101</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">B</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">Green</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">8</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">12</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">210</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">A</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">Green</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">9</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">206</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">A</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">Green</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">17</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">112</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">B</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">Orange</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; \">16</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; border-bottom: double; \">105</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; border-bottom: double; \">B</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; border-bottom: double; \">Orange</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; border-bottom: double; \">16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; border-bottom: double; \">16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center; border-bottom: double; \">14</td>\n</tr>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Run the Regression with complete data\n\n::: callout-note\nDr. Haraden needs to write the equation on the board üßë‚Äçüè´ Calculate the expected value for each group\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(post_score ~ group, data = six_seven)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = post_score ~ group, data = six_seven)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.000 -2.375  0.000  1.500  7.000 \n\nCoefficients:\n            Estimate Std. Error t value         Pr(>|t|)    \n(Intercept)  11.5000     0.9487  12.122 0.00000000000197 ***\ngroupOrange   1.5000     1.3416   1.118           0.2734    \ngroupYellow   3.0000     1.3416   2.236           0.0338 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3 on 27 degrees of freedom\nMultiple R-squared:  0.1562,\tAdjusted R-squared:  0.09375 \nF-statistic:   2.5 on 2 and 27 DF,  p-value: 0.1009\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Now what are the means for each group?\n\n------------------------------------------------------------------------\n\n### Now what are the means for each group?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsix_seven %>% \n  group_by(group) %>% \n  summarize(\n    post_avg = mean(post_score)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 √ó 2\n  group  post_avg\n  <chr>     <dbl>\n1 Green      11.5\n2 Orange     13  \n3 Yellow     14.5\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Using R\n\nImport dataset, include age and pre-scores to see how that changes interpretation\n\n::: callout-warning\nDr. Haraden is going to start opening up R and doing a follow-along thing. You have been warned\n:::\n\n# Everything is a linear model\n\n![](/images/reg_precious.gif)\n\n# Introducing Generalized Linear Model\n\n------------------------------------------------------------------------\n\n## 6Ô∏è‚É£7Ô∏è‚É£ Status\n\nIn our last example, we were able to see how these categorical variables could predict a continuous variable. This is perfect for linear regression.\n\n*What if we want to see if students have \"recovered\" from* 6Ô∏è‚É£7Ô∏è‚É£?\n\nWe would then ask: \"Which participants dropped below the clinical threshold for 6Ô∏è‚É£7Ô∏è‚É£ at follow-up? Now, our outcome is either recovered or not recovered.‚Äù\n\n------------------------------------------------------------------------\n\n## Recovery Status\n\nNow we have a binary outcome; Yes/No recovery\n\nWhat happens when we fit a linear regression? What are the chances of someone with a pre-score of 12 recovering by the follow-up?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsix_seven <- import(here(\"files\", \"data\", \n                       \"cat_reg_complete.xlsx\")) %>% \n  janitor::clean_names() %>% \n  # 1 = recovered; 0 = not recovered\n  mutate(recover = if_else(post_score > 14, 0, 1))\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### Recovery Status\n\n::::: columns\n::: {.column width=\"40%\"}\nThat doesn't look right... üòë\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsix_seven %>% \n  ggplot(aes(pre_score, recover)) +\n  geom_jitter(width = 0, height = 0.05, \n              alpha = 0.5) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(\n    title = \"Pre-Score Predicting Recovery\"\n  )\n```\n\n::: {.cell-output-display}\n![](lec-12_logistic_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n:::\n:::::\n\n------------------------------------------------------------------------\n\n## Binary Outcomes in Regression\n\n-   A simple line is not going to appropriately capture the data\n\n    -   Plus, it definitely doesn't make it a normal distribution! We only have 2 scores in our predictor variable...\n\n**Introducing Logistic Regression üåü**\n\n-   Using a logistic function we are able to better capture the data and get a \"likelihood\" or \"probability\" of an outcome\n\n------------------------------------------------------------------------\n\n## Probability to Odds to Log-Odds\n\n**Probability (*p*)**: The chance of an event happening. Ranges from 0 to 1\n\n**Odds**: The ratio of the probability of an event happening to it *not* happening.\n\n-   $Odds = \\frac{p}{1-p}$\n\n-   Ranges from 0 to ‚àû. An odds of 4 means the event is 4 times more likely to happen than not.\n\n**Log-Odds (logit)**: The natural log of the odds\n\n-   $Logit(p) = ln(\\frac{p}{1-p})$\n\n-   Ranges from -‚àû to +‚àû\n\n::: callout-important\nThis step transforms our bounded outcome variable (0/1) to an unbound one!\n:::\n\n------------------------------------------------------------------------\n\n## Generalized Linear Model (GLM)\n\nA generalization of a linear model (duh) that is used when the response variable has a non-normal error distribution\n\nMost commonly used when there is a binary (0-1) or count variable as the outcome (we will focus on the binary)\n\nUltimately, we are trying to identify the ***probability*** of the outcome taking the value 1 (\"success\") that is being modeled in relation to the predictor variables\n\n------------------------------------------------------------------------\n\n### GLM: Logistic Regression\n\n$$\ntransformation(p_i)=\\beta_0+\\beta_1x_{1,i} + \\beta_2x_{2,i} + \\cdots+\\beta_lx_{k,i}\n$$\n\nWe have to apply a transformation to the left side so that it can take variables beyond just 0 & 1\n\nA common transformation is the $logit\\ transformation$\n\n$$\n\\log_{e}\\left( \\frac{p_i}{1-p_i} \\right) = \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\cdots + \\beta_k x_{k,i}\n$$\n\n------------------------------------------------------------------------\n\n## Recovering from 6Ô∏è‚É£7Ô∏è‚É£\n\nNow we have a tool to figure this out, let's see if the pre-score can predict recovery!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Using glm() instead of lm()\nrec_glm <- glm(recover ~ pre_score, \n           data = six_seven, \n           ## This is new\n           ##Tells the model we are doing logistic regression with a binary outcome\n           family = \"binomial\")\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### GLM - 6Ô∏è‚É£7Ô∏è‚É£ Data Interpretation\n\n::: callout-note\nInterpretation is still the same as linear regression, ***except*** we are dealing with [**log-odds** of the outcome.]{.underline} What does that mean??\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rec_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = recover ~ pre_score, family = \"binomial\", data = six_seven)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)  20.1873     7.0700   2.855  0.00430 **\npre_score    -1.2002     0.4268  -2.812  0.00492 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.191  on 29  degrees of freedom\nResidual deviance: 18.216  on 28  degrees of freedom\nAIC: 22.216\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### GLM - 6Ô∏è‚É£7Ô∏è‚É£ Data Interpretation (tables)\n\nWe want to be able to interpret these coefficients more easily so we put them into **Odds Ratios**\n\n`sjPlot` is always coming in with the good tables\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(rec_glm)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">recover</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">585099560.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">10397.58&nbsp;&ndash;&nbsp;36877368326354064.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.004</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pre score</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.10&nbsp;&ndash;&nbsp;0.58</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.005</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">30</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Tjur</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.562</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Odds Ratios (OR)\n\n**OR \\> 1:** The predictor increases the odds of the outcome. (e.g., OR of 2.5 means the odds of believing in ghosts are 2.5 times higher).\n\n**OR \\< 1:** The predictor decreases the odds of the outcome. (e.g., OR of 0.4 means the odds of believing in ghosts are 60% lower).\n\n**OR = 1:** The predictor has no effect on the odds of the outcome.\n\n------------------------------------------------------------------------\n\n## Visualization\n\nExtract the model implied probabilities for each individual\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprobs <- broom::augment(rec_glm, type.predict = \"response\")\n```\n:::\n\n\nPlotting the predicted probabilities\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprobs %>% \nggplot(aes(pre_score, .fitted)) +\n  geom_line(color = \"blue\", linewidth = 0.5) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(\n    title = \"Predicted Probability of Recovery from 6-7 by Pre-Score\",\n    x = \"Pre-Score\",\n    y = \"Predicted Probability of Recovery\"\n  ) +\n  ylim(0, 1) + # Keep the y-axis bounded at 0 and 1\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](lec-12_logistic_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Logistic Regression: Summary\n\n| **Feature** | **Linear Regression** | **Logistic Regression** |\n|:-----------------------|:-----------------------|:-----------------------|\n| Outcome Variable | Continuous | Categorical (Binary) |\n| Equation | $Y=Œ≤_0+Œ≤_1X$ | $ln‚Å°(\\frac{p}{1-p})=Œ≤_0+Œ≤_1X$ |\n| Key Interpretation | $\\beta_1$ is the change in the mean of Y | $\\exp(\\beta_1)$ is the odds ratio |\n| R Function | `lm()` | `glm(..., family=\"binomial\")` |\n\n# Break ‚òïüçµü•ê\n\n------------------------------------------------------------------------\n\n## Next Up...\n\n**Follow along to apply these methods to a new dataset!**\n\nPredicting the probability of believing in ghosts. Hopefully we have time to go through this example üëª\n",
    "supporting": [
      "lec-12_logistic_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}